<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Automation &amp; philosophy</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Automation &amp; philosophy</h1>
</header>
<section data-field="subtitle" class="p-summary">
Automation tools don’t obviate abstract discussions about how best to think about decisions (like ‘should translations be precise or…
</section>
<section data-field="body" class="e-content">
<section name="cbca" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="6daa" id="6daa" class="graf graf--h3 graf--leading graf--title">Automation &amp; philosophy</h3><p name="3577" id="3577" class="graf graf--p graf-after--h3">Automation tools don’t obviate abstract discussions about how best to think about decisions (like ‘should translations be precise or should they be accurate’ or ‘what is the good’) but make them more important.</p><p name="5382" id="5382" class="graf graf--p graf-after--p">AI is a force-multiplier for philosophical positions. The programmer encodes their understanding of the world (or a program extracts a statistical model of the worldview of the guy who decided what goes in the data set), then the running program mass-produces the decisions made inevitable by that world-model. Since it’s harder for us to backtrack large-scale automated decisions, it’s very important to be critical about them before any automation occurs.</p><p name="abcb" id="abcb" class="graf graf--p graf-after--p">The paperclip-maximizer model gets a lot of hassle because making paperclips is obviously stupid. But if you replace ‘paperclips are good’ with ‘communication is good’ you get Twitter refusing to ban nazis. If you give it ‘money is good’ you get global neoliberal capitalism. People are really good at making generalizations — at substituting their actual goals with nearly-unrelated but easily-measurable proxy goals — but they’re not great at identifying when their proxy goals have diverged from their real goals, particularly when their measurements are changing rapidly. (Just look at Jim Jones’ trajectory: he allowed himself to become paranoid and myopic, and the end game was mass suicide — something that was neither inevitable nor anybody’s desired result.)</p><p name="caf5" id="caf5" class="graf graf--p graf-after--p">As a human being, you can make a mistake, recognize it in a vague and intuitive way, and change your behavior. When you replace yourself with a small shell script, that mistake can be made millions of times while you sleep. When you use statistical learning, you poorly-reproduce the System-I behavior of thousands of people who are worse than you are at the thing you’re reproducing &amp; haven’t spent any time thinking about the subject. (It’s probably a bad idea, &amp; should be applied only very carefully.)</p><p name="022a" id="022a" class="graf graf--p graf-after--p graf--trailing">As more and more ‘doing’ is performed by machines, careful philosophy becomes more important, because all ‘doing’ is a crystallization of philosophy.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@enkiv2" class="p-author h-card">John Ohno</a> on <a href="https://medium.com/p/22b64b9941c4"><time class="dt-published" datetime="2018-10-10T14:26:59.628Z">October 10, 2018</time></a>.</p><p><a href="https://medium.com/@enkiv2/automation-philosophy-22b64b9941c4" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 21, 2018.</p></footer></article></body></html>