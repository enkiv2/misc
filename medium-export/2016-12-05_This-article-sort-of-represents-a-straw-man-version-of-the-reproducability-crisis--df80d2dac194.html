<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>This article sort of represents a straw-man version of the reproducability crisis.</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">This article sort of represents a straw-man version of the reproducability crisis.</h1>
</header>
<section data-field="subtitle" class="p-summary">
Any serious article on the subject does not focus on the correctness of individual studies, but instead on the absence of published…
</section>
<section data-field="body" class="e-content">
<section name="b0a7" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="aae2" id="aae2" class="graf graf--p graf--leading">This article sort of represents a straw-man version of the reproducability crisis.</p><p name="fb3b" id="fb3b" class="graf graf--p graf-after--p">Any serious article on the subject does not focus on the correctness of individual studies, but instead on the absence of published replication attempts for landmark studies. It’s precisely because science is hard &amp; false positives are common that the low rate of reproduction attempts, the tendency to avoid publishing negative results, and (on the science journalism side) the naive acceptance of shocking-sounding results are so damaging at scale.</p><p name="ada4" id="ada4" class="graf graf--p graf-after--p">Will teaching general audiences &amp; science journalists about the variety of potential statistical &amp; methodological flaws help? Sure — at least with respect to the science journalism side. It won’t help with the acceptance of false positives due to selection bias (which led to people like Kanneman putting a lot of trust into ideas like cultural priming that ended up being completely unreproducible).</p><p name="7608" id="7608" class="graf graf--p graf-after--p">Anyone with an interest in science knows that without high-quality replication &amp; large, randomized samples, results are meaningless. This is not to say that small-scale exploratory studies are not worthwhile, but instead that such studies should be treated as one step above opinion columns with regard to how seriously they should be taken.</p><p name="6b21" id="6b21" class="graf graf--p graf-after--p">There are also real reasons why scientists end up having research and publication habits that encourage bad science; we can’t pretend these reasons don’t exist, but they are economic/incentive-related reasons, and new incentives are easily introduced into science if somebody has the money.</p><p name="1896" id="1896" class="graf graf--p graf-after--p">Providing funding for pre-registered replications seems like it’s likely to solve many of the problems that people have with the state of experimental psychology (and if you don’t agree that those problems exist, you don’t have to participate in such programs: you can leave the money on the table, and instead watch other people attempt to replicate your work); likewise, automatic stats checkers are pretty uninvasive: if you avoid mathematical errors, you won’t get a lot of notes, and if you disagree with the notes you can ignore them and wait to be vindicated. These are systems that already exist, and are already being used to change incentive systems in experimental psychology in order to compensate for common sources of concerns.</p><p name="01f9" id="01f9" class="graf graf--p graf-after--p graf--trailing">Individual experiment sample sizes were never the point of the replication crisis, except when experiments were being taken significantly more seriously than they should be, which is not unusual.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@enkiv2" class="p-author h-card">John Ohno</a> on <a href="https://medium.com/p/df80d2dac194"><time class="dt-published" datetime="2016-12-05T16:18:10.740Z">December 5, 2016</time></a>.</p><p><a href="https://medium.com/@enkiv2/this-article-sort-of-represents-a-straw-man-version-of-the-reproducability-crisis-df80d2dac194" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on September 18, 2020.</p></footer></article></body></html>