<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[John Ohno on Medium]]></title>
        <description><![CDATA[Exported stories by John Ohno on Medium]]></description>
        <link>https://medium.com/@enkiv2?source=rss-43a4cf6aa464------2</link>
        <image>
            <url>https://cdn-images-1.medium.com/fit/c/150/150/1*mLEkHESxmtlZWo1QYzpiUw.png</url>
            <title>John Ohno on Medium</title>
            <link>https://medium.com/@enkiv2?source=rss-43a4cf6aa464------2</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Tue, 14 Mar 2017 14:12:06 GMT</lastBuildDate>
        <atom:link href="https://medium.com/feed/@enkiv2" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[Clues about Medium’s business plan]]></title>
            <link>https://medium.com/@enkiv2/clues-about-mediums-business-plan-7dacaf6ed521?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/7dacaf6ed521</guid>
            <category><![CDATA[writing]]></category>
            <category><![CDATA[medium]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 14 Mar 2017 14:10:28 GMT</pubDate>
            <atom:updated>2017-03-14T14:10:28.721Z</atom:updated>
            <content:encoded><![CDATA[<p>Yesterday I got an email. (Presumably many of you also got it, or something like it.) There was nothing in the email that indicated they wanted the information exposed therein kept secret, so I feel comfortable sharing it. Reading between the lines, it clears up some of the ambiguities left by official announcements about Medium’s future &amp; their plans for monetization.</p><blockquote>Hi,</blockquote><blockquote>I’m Brian, an editor here at Medium. I’m reaching out to you as a popular writer who’s published high-quality stories on Medium.</blockquote><p>(I am not a popular writer — I’ve written one paid article that got the kind of traffic paid articles tend to get, and a large number of articles that have views in the single digits. My average view count is probably under 100, and my average recommendation count is less than one. So, this is a big clue: if I’m getting this email, pretty much anybody who has ever submitted to a popular publication is getting one.)</p><blockquote>You might have read that we’re launching a new subscription product for our readers shortly. It’s the next step in our vision to build a place on the internet where ideas are rewarded for their value, not simply their ability to attract a few seconds of attention.</blockquote><blockquote>As fans of your work, we’d like to offer you the opportunity to pitch your ideas or relevant posts early, and become part of a select group of contributing writers for our initial launch.</blockquote><p>(This is interesting. Not only will there be subscription-only stories, but subscription-only stories will be pitched to and vetted by Medium. This essentially means something akin to a Medium-staff-run publication that only subscribers have access to. While this is better for users than a paywall that locks you out after a couple articles, it means that Medium will be competing with Medium-hosted publications on the grounds of editorial standards.)</p><blockquote>Our subscription will be an optional upgrade for people to become supporting members of Medium. These people will be able to access additional member-only functionality and new, exclusive content.</blockquote><p>(I.e., there’s more to this freemium model than a cool-kids-club of vetted articles, but we have no clues as to what those features are, other than the fact that they’re user features as opposed to publication features.)</p><blockquote>Writers across the world will continue to be able to publish on Medium for free, but we know there’s a great deal that never gets written or published by great writers, for lack of it making economic sense to do so. We want those stories — well-researched explainers, insightful perspectives, and useful knowledge with a long shelf life — to exist on Medium as well, and we think our paying readers will want to read them too.</blockquote><p>(This is a strange pitch. Nowhere in the email do they explicitly state that writers will be paid for writing subscription-only stories — even though they have a pitch process like you’d expect from freelance — but they suggest that they will be able to make writing articles not currently picked up by publications make economic sense. This implies that they’d be either paying better than existing publications, supporting a greater number of articles, or trying to commission articles on subjects existing publications don’t or can’t cover.)</p><blockquote>That’s where you come in, because we thought your writing could be a great fit. So what types of posts have you been burning to write? If you knew you had a paying audience waiting for your ideas, what stories could you tell?</blockquote><blockquote>We’re looking for pitches within the following categories to start: US Politics, Technology/Science/Future, Self Development/Productivity, Business/Startups, and Culture. So tell us what you’d like to write about and your rate. If it sounds like a good fit, we’ll get back to you with a thumbs up or feedback as soon as we can. <strong>If you’re interested, we’d love to receive your initial pitch before Friday, March 17th.</strong></blockquote><p>(Their launch categories are those already covered heavily by existing publications. I don’t see, for instance, short fiction on the list — even though, unlike all these listed categories, short fiction and poetry publications typically have short and infrequent submission windows. It’s also interesting that they want pitches so fast — the deadline is five days after the announcement!)</p><p>(I have removed their submission link. I should note that it links to Google Forms, so they’re probably expecting a large enough number of pitches that they want to automate handling them. This is a good sign: even pretty big publications tend to take submissions by email.)</p><blockquote>This is just the first opportunity to be part of Medium’s subscription offering. We’ll be following up soon with more writing opportunities, as we continue to evolve our subscription and learn what our members enjoy reading most.</blockquote><blockquote>Thanks,</blockquote><blockquote>Brian</blockquote><p>(In other words, they plan to rotate through different categories and have frequent calls for pitches. I have to wonder why they don’t transition to having open pitching and keeping only internal deadlines, at this scale.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[It really is better to ask for permission]]></title>
            <link>https://medium.com/@enkiv2/it-really-is-better-to-ask-for-permission-3fb1f4b5a22a?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/3fb1f4b5a22a</guid>
            <category><![CDATA[entrepreneurship]]></category>
            <category><![CDATA[life-lessons]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 13 Mar 2017 12:09:46 GMT</pubDate>
            <atom:updated>2017-03-13T12:09:46.485Z</atom:updated>
            <content:encoded><![CDATA[<p>A problem with slogans is they get adopted outside of contexts where they make sense, either because the people using them didn’t carefully consider whether or not they were true, or because they provide an excuse for doing something that would otherwise not be allowed. Where a monoculture exists, with a group of people with similar values, culture, resources, and problems all make decisions based on the same assumptions, inappropriate slogans can cause systemic biases. The worst offender I’m aware of right now is “<em>it’s better to ask for forgiveness than ask for permission</em>”.</p><p>I have no particular interest in tracking down who said this first and in what context. I will give it the benefit of the doubt and assume that initially it was said in a context where it was true — improv comedy, maybe. However, like similar slogans like “<em>move fast and break things</em>”, today it is used almost exclusively in situations where it is not only untrue but also actively harmful.</p><p>In order for it to be true for it to be better to ask for forgiveness than permission, the following must also be true:</p><ol><li>The stakes must be low — in other words, mistakes must not be very damaging (or else apologizing wouldn’t be enough)</li><li>There must be a single homogenous party from which to ask forgiveness (or else asking for forgiveness wouldn’t make sense, because you would never be forgiven by all concerned)</li><li>Asking for permission must be more difficult or risky than getting forgiveness — in other words, the party from which you ask permission must be conservative about it</li><li>Success must be likely (or else you would be seen as a perpetual screw-up for following this advice)</li><li>Performing the task must be its own reward — in other words, you must see even the failure as valuable</li></ol><p>How this is interpreted, however, hinges on how we define ‘better’. When people say this in the tech industry, the most charitable explanation is ‘better’ means ‘better for my paycheck’ rather than ‘better for users’ — in which case, one can expect to apologize to one’s supervisor, not one’s users, if one takes down all production systems for a week.</p><p>While this is charitable, it’s hardly an endorsement. None of us should feel better about losing service on the grounds that the developer at fault was forgiven by his supervisor. Any system with users cannot afford the kind of unreliability produced by lack of oversight, because the real stakes are much higher than a single developer’s paycheck.</p><p>Ultimately, the attitude embedded in this slogan, taken too seriously, is at the core of many of the worst behaviors associated with the tech industry. Uber repeatedly violates labor laws on the grounds that it can get away with doing so — and asks forgiveness when sued. The creepiness of redpillers and PUAs mostly comes down to the entitlement they feel toward other people’s bodies, assuming they don’t need to worry about consent beforehand because they can ask for forgiveness after they’ve gotten what they want if in retrospect consent wasn’t given. More concretely, this attitude produces shitty dysfunctional code, short-lived companies that sell user data and disappear suddenly, ethically-dubious business practices, and a general culture of “I’ve got mine, bub” that directly contradicts the phony “save the world” PR everyone likes to wear.</p><p>Here’s the thing: if you’re doing real work, you have real responsibilities. One of your responsibilities is to make sure your decisions are safe — not for your paycheck, but for everyone else. You have the responsibility to check with colleagues in order to make sure your plans aren’t stupid and damaging, and you have the responsibility to make sure your colleagues aren’t doing anything stupid either. If you aren’t willing to take ‘no’ for an answer, then you should switch to an industry where nothing you do matters, because that’s the only situation where such behavior is morally justifiable.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Spanning problem-space]]></title>
            <link>https://mystudentvoices.com/spanning-problem-space-74e81c367bb7?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/74e81c367bb7</guid>
            <category><![CDATA[autodidacticism]]></category>
            <category><![CDATA[education]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 06 Mar 2017 14:59:56 GMT</pubDate>
            <atom:updated>2017-03-06T14:59:56.623Z</atom:updated>
            <content:encoded><![CDATA[<p>Determining how best to improve one’s own suite of mental models &amp; thinking tools is a hard problem: we can’t easily see ideas beyond the horizon, and ideas we haven’t yet invested effort in developing are distorted at best, but determining the value of ideas is necessary because of the scarcity of time &amp; other resources. This is further complicated by the fact that knowledge-seeking is not a single-player game: everyone is constantly refining their suite of mental models, making decisions based on them, and producing material that makes certain ideas more or less accessible, and the value of a mental model is determined in part by the people who share it or share adjacent models, in somewhat complicated ways.</p><p>My current idea of how best to improve the value of one’s suite of mental models is based on a couple assumptions:</p><ol><li>Ideas are adjacent to each other in semantic space based on shared attributes.</li><li>It is easier to learn an idea if it is adjacent to an idea you’ve already learned. The ease with which an idea is learned is proportional to the number of adjacent ideas already learned.</li><li>Adjacency in semantic space, seen as a network, is a web, not a tree. Some ideas are adjacent to each other even when none of their immediate peers are adjacent — such as when seemingly unrelated ideas in seemingly distinct fields have striking similarities.</li><li>A factor in the value of an idea is its adjacency to other valuable ideas. Part of this is ease of communication: when we have a shared terminology and set of assumptions with people, we can share new ideas more easily. When we share few ideas with someone, communicating with them is difficult.</li><li>Another factor in the value of an idea is its concrete utility, in of itself. For instance, the set of ideas known as ballistics are very useful in predicting the movement of objects.</li><li>A third factor in the value of an idea is its scarcity. Someone who is an expert in an obscure field will have greater social capital than someone who is an expert in a more commonly-understood field with the same concrete utility adjacent to ideas of comparable value.</li><li>Some ideas have as their primary concrete utility the capacity to change the value of other ideas by changing something about society. Rhetoric, for instance, can be used to modify ideas about the value of certain other ideas, thus changing things like salary and social capital.</li><li>Adjacent ideas are not always obvious. Sometimes they are only obvious in retrospect.</li><li>Adjacency doesn’t necessarily have any relationship to truth or intent, although systematic biases (including toward truth or toward consistency) may favor clusters of similar ideas. For instance, mathematics, because it enforces consistency, finds large numbers of similar patterns in far-flung contexts.</li><li>Traditional (tree-like) academic paths through idea space are easy to traverse in part because so much effort has gone into lowering traversal effort — the production of teaching material, specialized terminology, and communities and social structures (such as universities). That same ease of traversal lowers the value because it increases the number of people with nearly identical mental toolkits.</li><li>Autodidacts trade the easy-to-traverse yet diluted conventional path for unconventional connections of unknown value. They risk missing ideas that are relatively hard to pick up without structural aid but that are very useful for opening up further vistas or closing off dead ends (like calculus, or godel’s incompleteness).</li><li>Successful autodidacts are polymaths. Unsuccessful autodidacts are cranks. It’s hard to tell the difference without mastery of related fields.</li><li>Undiscovered or undocumented adjacencies between seemingly unrelated subjects are common, but few have much concrete utility. However, those that do are extremely valuable.</li><li>As a result, someone can optimize the value of their mental toolkit by following traditional paths enough to enable communication but otherwise specifically choosing to persue seemingly unrelated subjects that are rarely persued together, periodically attempting to synthesize them. Random number generators are useful in path choice and synthesis, since the likelihood of producing an unconventional path and the likelihood of choosing paths with hidden adjacencies are both high.</li></ol>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Slowly creep backwards while speaking more softly and with a greater number of increasingly-long…]]></title>
            <link>https://medium.com/@enkiv2/slowly-creep-backwards-while-speaking-more-softly-and-with-a-greater-number-of-increasingly-long-52d2fc2b7276?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/52d2fc2b7276</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 02 Mar 2017 12:57:52 GMT</pubDate>
            <atom:updated>2017-03-02T12:57:52.437Z</atom:updated>
            <content:encoded><![CDATA[<p>Slowly creep backwards while speaking more softly and with a greater number of increasingly-long pauses. If your partner doesn’t attempt to follow you, the conversation is over and you may leave.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Some less modest provisions:]]></title>
            <link>https://medium.com/@enkiv2/some-less-modest-provisions-5d7efb4375f5?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/5d7efb4375f5</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 01 Mar 2017 16:22:10 GMT</pubDate>
            <atom:updated>2017-03-01T16:22:10.423Z</atom:updated>
            <content:encoded><![CDATA[<p>Some less modest provisions:</p><ul><li>Those who are in prison at the time that they are being called up for this course will attend it, but their firearm will be held for them until they are released. Since this program grants a firearm license, current laws prohibiting felons from owning firearms will need to be overturned. (After all, most felons are not violent offenders, and even violent offenders have incentives not to re-offend. We shouldn’t allow prosecution to become a fig-leaf for preventing minority groups from defending themselves.)</li><li>Participation may be delayed for mental health concerns, but not cancelled. A jury of twelve mental health professionals, chosen by lottery, must come to a consensus that someone is not psychologically fit to participate in order for this delay to occur. The delay may be no more than a year. This is a preventative measure against the tactic, used both in the United States and the Soviet Union, of applying bogus psychiatric diagnoses to political or racial ‘undesirables’ in order to silence dissent.</li></ul>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I realize that your post isn’t meant to be a coherent argument, but — the only way we can tell that…]]></title>
            <link>https://medium.com/@enkiv2/i-realize-that-your-post-isnt-meant-to-be-a-coherent-argument-but-the-only-way-we-can-tell-that-825cf2fb4463?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/825cf2fb4463</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 01 Mar 2017 15:47:27 GMT</pubDate>
            <atom:updated>2017-03-01T15:47:27.270Z</atom:updated>
            <content:encoded><![CDATA[<p>I realize that your post isn’t meant to be a coherent argument, but — the only way we can tell that an idea is good is by trying to kill it and failing. To the extent that a writer is a curator of ideas, we benefit from taking the same kind of aggressive approach toward ideas as we do toward words when editing.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A modest proposal related to firearm safety]]></title>
            <link>https://medium.com/@enkiv2/a-modest-proposal-related-to-firearm-safety-681be7bf201b?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/681be7bf201b</guid>
            <category><![CDATA[gun-safety]]></category>
            <category><![CDATA[politics]]></category>
            <category><![CDATA[gun-violence]]></category>
            <category><![CDATA[guns]]></category>
            <category><![CDATA[gun-control]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 01 Mar 2017 14:56:28 GMT</pubDate>
            <atom:updated>2017-03-01T14:56:28.987Z</atom:updated>
            <content:encoded><![CDATA[<p>There are several major related social problems in the united states right now: a political division along geographic lines, a set of self-reinforcing communication barriers along that division, an asymmetry of firepower along that division, and a set of minority groups whose acceptance is asymmetrical along that division. I propose a programme, along the lines of the mandatory short-term military service found in Scandanavia and Israel, to directly address all of these related problems. I expect it to offend all major entrenched interest groups roughly equally.</p><p>To summarize the problem: broadly, we have nominally ‘left’ and ‘right’ cultures — the blue and red tribe, respectively. The blue tribe is more common in urban areas while the red tribe is more common in rural areas (although the strength of this geographic division is debatable, and better debated elsewhere). More importantly, the blue tribe aligns itself strongly with social justice for marginalized groups yet is largely opposed to mechanisms by which such groups might defend themselves, and even in areas that are blue-tribe-dominated, weapons and minor positions of political-executive power (such as placement in law enforcement) are red-tribe-dominated. All of these associations are accidents of history: movements like the Black Panthers show that embrace of weapons for self defense are no less compatible with both left-leaning politics and a position as a persecuted minority than they are with white male right-libertarianism.</p><p>I propose a programme by which, in early adulthood (say, age 20), all people who are not too ill to participate would be required to attend two months of intensive firearm safety and training. Locations are assigned at random, rather than by convenience: after all, transportation will be provided by the government, and we would like to use this program to acquaint people who are from different geographic regions and who have different perspectives on life. These training programs will not be segregated by gender (including sleeping arrangements). Because this training program is non-military, there will be no religious or moral exemptions. At the beginning of the program, each participant will be issued a firearm, a portable gun safe, and a gun lock; at the end of the program, participants keep their firearm. (After the end of the program, they may of course sell their firearm, or discard it.)</p><p>Immediate results: all minorities are armed with a suitable weapon for self defense and a legal justification for having it (so a law enforcement officer can no longer consider being armed as sufficient for considering a POC a threat); people outside a general culture of firearm safety (like that which exists in the red tribe, where children are drilled on firearm safety from a young age by their whole community) are introduced to it, limiting the rate at which people outside a culture of firearm safety make dangerous mistakes when they are exposed to firearms; people from all walks of life are guaranteed at least one experience with living for an extended period with a group of people very different from them in the presence of deadly weapons without violence.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I’m not the author of the original piece.]]></title>
            <link>https://medium.com/@enkiv2/im-not-the-author-of-the-original-piece-f1d9ee4f142c?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/f1d9ee4f142c</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 28 Feb 2017 17:44:17 GMT</pubDate>
            <atom:updated>2017-02-28T17:44:17.783Z</atom:updated>
            <content:encoded><![CDATA[<p>I’m not the author of the original piece.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Here’s a heuristic: if a task is made significantly easier by a framework, it shouldn’t be done in…]]></title>
            <link>https://medium.com/@enkiv2/heres-a-heuristic-if-a-task-is-made-significantly-easier-by-a-framework-it-shouldn-t-be-done-in-42544f4aa3f6?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/42544f4aa3f6</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 28 Feb 2017 14:45:04 GMT</pubDate>
            <atom:updated>2017-02-28T14:45:04.646Z</atom:updated>
            <content:encoded><![CDATA[<p>Here’s a heuristic: if a task is made significantly easier by a framework, it shouldn’t be done in the browser (and probably shouldn’t be done in JS at all).</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I’m not familiar with anything Nelson might have written on the storage of navigation histories…]]></title>
            <link>https://medium.com/@enkiv2/im-not-familiar-with-anything-nelson-might-have-written-on-the-storage-of-navigation-histories-ae7c9c325469?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/ae7c9c325469</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 28 Feb 2017 13:38:57 GMT</pubDate>
            <atom:updated>2017-02-28T13:38:57.419Z</atom:updated>
            <content:encoded><![CDATA[<p>I’m not familiar with anything Nelson might have written on the storage of navigation histories beyond inventing the back button (though I’m very familiar with his work with versioning &amp; with bidirectional hyperlinks). Do you have a URL for what you’re referring to?</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Did somebody unload a time machine from 1998 into this comment thread?]]></title>
            <link>https://medium.com/@enkiv2/did-somebody-unload-a-time-machine-from-1998-into-this-comment-thread-29a45befd91a?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/29a45befd91a</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 23 Feb 2017 13:37:03 GMT</pubDate>
            <atom:updated>2017-02-23T13:37:03.587Z</atom:updated>
            <content:encoded><![CDATA[<p>Did somebody unload a time machine from 1998 into this comment thread? All serious development is done in open source, while proprietary code is at best a toy — and this has been the case for decades.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The hype around javascript is representative of a more general and widespread problem, which is…]]></title>
            <link>https://medium.com/@enkiv2/the-hype-around-javascript-is-representative-of-a-more-general-and-widespread-problem-which-is-f953f93cd87d?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/f953f93cd87d</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 22 Feb 2017 13:38:50 GMT</pubDate>
            <atom:updated>2017-02-22T13:38:50.386Z</atom:updated>
            <content:encoded><![CDATA[<p>The hype around javascript is representative of a more general and widespread problem, which is that inexperienced programmers make poor design decisions based on familiarity and ease of initial development. Javascript is popular for exactly the same reason that PHP, perl, and java are popular: it’s an extremely common first language, an extremely common second language, and there are certain kinds of tasks for which it is not poorly suited as a prototyping language. People use javascript for the same reason that they use HTTP: it’s the first thing they think of, and they don’t bother to analyse whether or not it’s an appropriate tool.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[One way to avoid people using eponymous laws to pull a bavarian fire drill on you is to produce a…]]></title>
            <link>https://medium.com/@enkiv2/one-way-to-avoid-people-using-eponymous-laws-to-pull-a-bavarian-fire-drill-on-you-is-to-produce-a-cb9ffb5b5d6e?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/cb9ffb5b5d6e</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 20 Feb 2017 15:48:34 GMT</pubDate>
            <atom:updated>2017-02-20T15:48:34.557Z</atom:updated>
            <content:encoded><![CDATA[<p>One way to avoid people using eponymous laws to pull a bavarian fire drill on you is to produce a list of equally pithy opposite positions &amp; credit them to arbitrary famous figures. Neutralize the though-stoppers.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The only response I can think of for this is that, while Putin almost certainly wants to think of…]]></title>
            <link>https://medium.com/@enkiv2/the-only-response-i-can-think-of-for-this-is-that-while-putin-almost-certainly-wants-to-think-of-d56f7fa43528?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/d56f7fa43528</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 20 Feb 2017 14:12:38 GMT</pubDate>
            <atom:updated>2017-02-20T14:12:38.925Z</atom:updated>
            <content:encoded><![CDATA[<p>The only response I can think of for this is that, while Putin almost certainly wants to think of himself this way (being ex-KGB and all), true Xanatos gambits aren’t possible in real life. Every plan has holes, because there’s too much complication.</p><p>In other words, at the very least, we’re looking at a combination of planning (particularly, the construction of double-binds), improvisation, and luck. And, it’s not as though double-binds of this type are impossible to engineer: it doesn’t take a strategic genius, or someone with near-total political power, to produce them.</p><p>(The other thing to note is that the weak spot in any strategy is randomness. This isn’t to say that randomness will always win, but instead that any system will eventually succumb to fuzzing if the fuzzing can be sustained for long enough. Placing someone unpredictable in power is dangerous simply because you never know how they might undermine your plans — but that risk is spread out across all possible plans.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Details of how this subscription model will work seem scarce.]]></title>
            <link>https://hackernoon.com/details-of-how-this-subscription-model-will-work-seem-scarce-196b4adcb17a?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/196b4adcb17a</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 15 Feb 2017 14:03:19 GMT</pubDate>
            <atom:updated>2017-02-15T14:03:19.095Z</atom:updated>
            <content:encoded><![CDATA[<p>Details of how this subscription model will work seem scarce. I can hardly make a decision based on them.</p><p>I love Medium right now. I love writing for it and I love reading it (despite some problems with keeping content quality consistently high). But, the service Medium provides isn’t one that’s difficult to implement: I expect that, as soon as Medium locks itself up, five or six slightly-crappier competitors will pop up from people who didn’t take ill-advised loans from VCs and who decided on a revenue model early, because we’re essentially talking about a blogging platform with minimal customization, and reinventing that wheel is done all the time. Whatever model Medium decides upon will need to benefit me more than switching to a competitor will.</p><p>Let us consider some possibilities:</p><ul><li>It may be that Medium will require subscriptions from all registered users, and not provide any revenue redistribution. (This will probably eliminate some casual users and change the cost-benefit analysis of people who currently use the platform for marketing purposes. If this gets rid of low-quality self-help spam, it may be a good thing, but if it scares away people who are currently writing high-quality content — as it probably will — then that may lower the value of a subscription even more.) I’m assuming, under this model, that unregistered users may still <em>read</em> medium posts, but that recommendations, posts, and comments are premium.</li><li>Perhaps everyone pays for subscriptions (as in the previous possibility) and there’s no paywall for readers, but authors get some direct payout (from subscription fees) based on number of reads. This would make a lot more sense: Medium is just a platform for distributing user-generated content, and making the users pay to generate content is nearly offensive, but making Medium a subscription-based marketplace for content cuts down on low-quality/spam posts and brings back authors who write high-quality content &amp; are likely to more than break even on what they write. (There are some complications here. Like, DMCA takedowns become a lot more important, and fraudulent takedown requests might start becoming an issue. What happens if a user from Australia posts an extensive quote from Lovecraft, whose works are public domain in Australia but under copyright in the US? Medium presumably already has good lawyers and policies on this, but the stakes are higher when you’re paying authors.)</li><li>Let’s say that not only do registered users subscribe, but readers are also shown a paywall (perhaps after a certain number of monthly reads, like on newspapers). This is basically a no-go: the number of people who would put up with this is tiny, and discovery and PR goes down the toilet. Unless Medium officially states that this is what they’re doing, we should assume this is a straw-man version of their model (even though theoretically intelligent people like those in charge of the New Yorker also do this).</li><li>Consider a freemium model with multiple tiers. The free version would be what we normal users are used to; higher tiers are optimized for publications, with features like configurable publication pages and configurable post themes, promotion in the newsfeed, and placement in a special list in the sidebar. This might work out for Medium, and might work out better than the various alternatives, if they got the prices right. (After all, some publications are funded essentially with marketing budget for something else in print — How We Get to Next, for instance — and they would be willing to pay a pittance to look better on Medium because their revenue stream is from elsewhere.) But, if the prices are too low, current spammy posts will dominate everyone’s feeds (and regular users will leave), while if the prices are too high, Medium will continue to not break even.</li></ul><p>I think subscriptions are the second-weakest business model (after advertising) for Medium, but there are ways to make it work. If they make it worth my while, I’ll subscribe. But, for the <em>current levels of content quality, I probably wouldn’t pay more than a dollar a month</em>.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[When the best option for providing a service is awful, that indicates an opportunity for…]]></title>
            <link>https://medium.com/@enkiv2/when-the-best-option-for-providing-a-service-is-awful-that-indicates-an-opportunity-for-5be7ec5d80df?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/5be7ec5d80df</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 17 Feb 2017 14:00:34 GMT</pubDate>
            <atom:updated>2017-02-17T14:00:34.765Z</atom:updated>
            <content:encoded><![CDATA[<p>When the best option for providing a service is awful, that indicates an opportunity for competition. (Of course, network effects make this harder in practice — though Facebook was able to defeat MySpace which defeated Friendster basically all on the strength of superior UX.)</p><p>As much as I hate the term ‘disruption’, if there’s one thing that can and should be disrupted, it’s something like LinkedIn: i.e., a dysfunctional system that performs morally dubious activities, backed by an ancient giant, that continues to be used essentially because no superior competitor exists but barely provides a useful service to anyone except recruiter-spam companies. As long as places like LinkedIn continue to exist and continue to be actively used, their worst habits are normalized. And, normalization of bad ideas is the death of most things on the web.</p><p>Here’s the thing about the web: everything, service-side, is incredibly cheap compared to other industries. (Except engineer time, I guess, but that’s systematically overvalued in a weird way, and part of the problem.) Bandwidth is next to free, compared to sending out the same amount of information by mail or telephone; storage is next to free, compared to keeping the same amount of information on paper and renting warehouse space for it.</p><p>As a result, we’ve allowed ourselves to get into lazy habits and rely upon really marginal ideas for much longer than is justified: the money keeps flowing, whether or not we screw up. So we keep doing things that never made sense in the first place, like ad-driven revenue for websites, using super wonky / insecure tech (php, perl), using bloated storage formats that are difficult for humans <em>and</em> computers to read (300GB XML blobs), and coding as though performance and size don’t matter.</p><p>It’s been more than ten years since Moore’s Law stopped, and high speed internet providers have been avoiding upgrading their infrastructure in favor of consolidating local monopolies for at least as long, so the shit is about to hit the fan on performance across the board; meanwhile, gaming ad-based revenue and breaking poorly-secured systems have graduated from hobbies to industries, so the shit is already hitting the fan on that.</p><p>We could never really afford to do what we’re doing, but now we can’t even afford to look away.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Stories I won’t write (but you can)]]></title>
            <link>https://mystudentvoices.com/stories-i-wont-write-but-you-can-8a86a0321d3f?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/8a86a0321d3f</guid>
            <category><![CDATA[science-fiction]]></category>
            <category><![CDATA[short-fiction]]></category>
            <category><![CDATA[fiction]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 11 Nov 2016 00:27:57 GMT</pubDate>
            <atom:updated>2017-02-16T13:45:08.819Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p>This is a list of pitches for stories I won’t write. You absolutely may write any of these. The full list (which gets updated occasionally) is <a href="http://enki2.tumblr.com/stories">here</a>.</p><ul><li>Our universe suddenly transitions to operating not on physics, but on aristotlean logic. Ravens quickly become black holes, and anyone who changes their mind ceases to exist, since they are a contradiction in the unified and artificially divided ‘now’</li><li>Some large (double-digit) percentage of people who experience free fall outside of the ionosphere later have an intense revelatory experience. Commercial space tourism companies pop up and produce a steady stream of exceedingly wealthy cult leaders. Governments later begin using this to discredit people they don’t like, sending them free tickets to space knowing that they are likely to come down acting entirely nuts (the way the CIA occasionally doped people with LSD to discredit them during the good old days of MK-ULTRA). Some of the cult leaders get their act together enough to organize and oppose space travel.</li><li>McLuhan had a theory of hot and cool media. The distinction is that hot media tells you what to think (and is therefore non-interactive) whereas cool media means nothing until you think about it (and therefore requires effort on the part of the consumer). McLuhan believed that cool media cools down political unrest by giving a built-in release valve for the need to engage in action, whereas he thought hot media countered apathy. Story: The BBC (who broadcasts in a wide variety of places) has a computerized system using this model of the interaction between political activism and media coolness to regulate the global political situation through the mechanism of changing the vagueness of scripts in BBC newscasts (the news in a place with riots in the streets resembles Finnegan’s Wake, being incomprehensible enough that some effort otherwise directed toward activism is directed instead toward figuring out what the news means, while a place where the economy needs stimulation the news will be limited to precise and low-information newscasts). This works wonders for a while, until riots start in London and it is discovered that the system does not take into account the feedback loop between the writers of the original scripts and the newscasters.</li><li>Some popular children’s film from the 70s was actually intended as part of an experimental ‘manchurian candidate’ program for MK-Ultra. The MK-Ultra trials began and everyone from the CIA was pulled off the project, documentation destroyed. The original intent was to pull distribution of the film at the last minute, and to have the description of the intended target be something no human could be mistaken for (so that this would not lead to accidental killings). Instead, the film was released and was a runaway hit, several generations of children watching it quite often. A peaceful alien race makes first contact with humanity, but by chance corresponds to the description of the ‘target’. The visitors must be protected from the trained killers of all ages.</li><li>In the wake of the experimental detonation of a biological weapon that converts all water into sugar water, severely diabetic survivalists must re-build society.</li><li>Someone posts a thread called “News stories that alter their own narrative structure”, containing a story about a Florida Man doing something. This story is a memetic infovore: it eats information out of the brains of the readers, then shits out new information, and because it is capital-N news it is absolutely true (of course), and so it modifies reality. A group of quants working for an obscure mutual fund firm decide to study it, in order to make money off it. David Silver, while analyzing patterns in vowel frequency of twitter traffic, determines that there is an 85% chance that this will totally modify reality in the general vicinity and social network of everyone currently actively or passively involved with the stock market, and so he must team up with Vladmir Putin and Emeritus Pope Karl Ratzinger to break the administrator password of PD in order to delete the thread before reality breaks.</li><li>The Dark Side of Oz is actually a still-classified part of the now defunct MK-ULTRA system, with a generational release. The first generation has been (fairly grossly) programmed to merely subliminally brainwash their children and grandchildren, who (if they watch The Wizard of Oz while listening to the Dark Side of the Moon and smoking just the right strain of pot) will have latent behaviors triggered. However, the latent behaviors were actually decided upon by a visiting extraterrestrial ambassador, who liked it so much here that he disguised himself, became a permanent resident, and changed his name to David Bowie. Now, with the at-risk generation just discovering marijuana, Bowie must undo his past mistakes and prevent the latent programming from being triggered — and to do this, he must uncover his true form, and allow his firey wings to sprout again.</li><li>A deconstruction of the current semiotic signals for quirkiness — Stepford Wives for the ukeleles-and-unicycles set.</li><li>Start off with standard romantic-dramedy setting, casting Michael Cera as the lead. Slowly warp the signals until it is clear that Michael Cera’s character is in fact a remote control automaton created by some shady private organization as an agent-provacateur for infiltrating social groups, in order to insert advertisements into random conversations. Big reveal: the social group Robo-Cera is sent to infiltrate is in fact composed entirely of other automatons created by competing marketing firms.</li><li>An unsuspecting individual is imprisoned until he proves or disproves the generalized continuity conjecture. He is not given a keyboard capable of typing aleph.</li><li>The story of a man who survives some traumatic event and lives to a ripe old age, seeing the atrocities he survived become increasingly trivialized and eventually become a tourist attraction (and being forced by circumstance to contribute to its trivialization). He ends up getting rich off bobblehead figurines of the lunatic cult leader who murdered his whole family in front of him in cold blood.</li><li>A person is followed by a spambot on twitter that responds with markov-model-generated nonsense whenever tweeted at. On a lark, he follows it and sends it messages. Over time, he becomes convinced that it’s the ghost of his estranged father, who died after several years in an advanced state of dementia. He goes on a quest to find where the bot is physically hosted, and eventually ends up penniless and in the basement of an abandoned factory in Estonia, which houses an ad-hoc data center owned by the Russian mob. He is shot by a guard while attempting to carry an unplugged server rack down the street to the run-down motel he’s been staying at.</li><li>As a side effect of a freak accident, a scientist becomes immortal. However, that same freak accident warps his sense of time. He never realizes that he has become immortal, or stopped aging. Eventually, humans evolve into a something completely alien all around him, and he is confused.</li><li>An old, well-respected molecular biologist who specializes in chemical messaging between freshwater microbiota, after years of futilely resisting changes in lab tech, resequences several strains of water-borne bacteria and turns them into colonies of high-speed optical computers; lets them loose in a public fountain.</li><li>A group of ten people is sent on a one way trip to colonize Mars. There is an accident on the way, and they lose one person. After settling in, every Wednesday, one of them dies in a gruesome and violent death. After six weeks, the culprit is found and executed. The remaining two colonists must deal with the guilt of not identifying the killer for so long, and the awkwardness of suspecting each other, for the rest of their lives.</li><li>In low-rent housing in New York, sapient carnivorous plants rise up in rebellion against their amoral feline masters, but are quickly cut down by the cats’ perfectly ordinary laser guns — however, FIDS is reaching epidemic rates here, in part due to an (unbenownst to them) cannibalism problem, so it’s a race against time to pick off the plants as the cats are picked off one by one either by the cannibalistic cat-shaver who makes them into kibble or by the disease itself.</li><li>An alien cargo ship crash-lands on earth, containing a large number of relatively weak, docile aliens, all of whom are genetically identical. After a year or so, they learn a human language (and their language is decoded) and we discover that they were being cloned and bred as a food source — they are the alien equivalent of bananas, except that they are sapient; they were genetically engineered to resist disease without changing their flavor because of several near-collapses of the monoculture. As they integrate into human society, splinter groups form and (inspired by human cultural artifacts) decide to free their brethren and take revenge against the culture that was breeding them. A handful infiltrate the facility where the crashed cargo craft is kept, but they are killed by base security, leading to widespread race riots in large cities between humans and the alien space bananas.</li><li>A corrupt priest sits rotting in a Vatican City jail after stealing parish funds to pay off gambling debts. One day, the Pope himself visits him, and tells him that the Antichrist has been born and that he must find a relic — a book bound in Christ’s foreskin, with vellum pages made from the hide of the original scape-goat, with instructions on how to defeat God’s army in the end times — and destroy it. In order to do so, he must use the training and skills he swore off when he joined the priesthood so many years before, and once again adopt the name he swore he would never again answer to — James Bond.</li><li>A three act action-movie structure. In the first act, a talented rookie cop who plays by the rules uncovers wide-scale corruption in the force, and learns that he has to work outside the system in order to take down the systemic corruption. In the second act, that same cop tries to take down the organized crime syndicate that was manipulating the corrupt officials, but finds that he is unable to do so by himself by flouting the rules and doing things his way, and instead utilizes the system (in the process finding it necessary to make amends with the cops that were involved in some of the more minor corruption, in order to join forces and mobilize to defeat a larger problem). In the third act, he discovers that the few people he continued to trust from the first act into the second were being manipulated by a third party — a large and wealthy private mercenary corporation with strong ties to an obscure but powerful religious cult — and that in order to deal with this threat, he needs to break all the rules and go on his own to take down the cult leader, knowing that he will at best be arrested or become a fugitive of justice afterwards. (So, basically, The Parable of the Gong meets Die Hard)</li><li>While researching the philosopher’s stone in the modern day, a researcher makes the discovery that it was actually made once, and finds the creator. He discovers that possession of the philosopher’s stone turns you into a vampire — because human free will is one of the many impurities that the philosopher’s stone burns away, and the ‘perfected being’ is unable to behave unethically because he is unable to resist natural law (and thus is subject to only animalistic urges of hunger and lust). However, being a pure material, the philosopher’s stone is pretty highly reactive to certain things — it will combust with the air if catalyzed by light (being the metal of metals, it has a strong photoelectric effect), water, or certain classes of acidic fumes (such as those produced by chopping garlic or onions).</li><li>An immortal precog accidental cult leader must struggle with knowing the fact that, no matter what he does, his cult will grow and win battles against its detractors, and despite all his attempts, he will never die.</li><li>By making the most out of his access to advanced technology and large sums of money, Batman becomes incredibly effective at defeating petty criminals and preventing petty crime. As a result, the police force — who once was outnumbered by criminals and felt heroic every time they launched into the fray — now feels redundant. Justice-minded people stop joining the police force, because the police force is dwarfed in its ability to maintain justice by Batman and his BatDrone army; instead, the only people joining the police force are would-be criminals who would like to use their position of minor power for personal gain. Over time, as old guard police die off (by a combination of old age, conspiracy by other corrupt cops, and being the only ones willing to dive headlong into a suicidal attempt to keep the peace in an area where the BatDrones are temporarily ineffective), Batman mostly ends up trying to prevent police corruption — and thus is targeted by the police union (which at this point has essentially become the mafia). What follows is a war between Batman and the entire Gotham police force. Batman wins, but the news travels beyond the area where the context would be clear — and what is understood elsewhere is that Batman killed the entire police force in the most crime-ridden city in america. He is arrested and executed in texas, during a failed attempt to escape to Mexico</li><li>Planet Terroir!<br>A group of anthropologists discover the oldest cheese in existence, in a hidden chamber deep in a cave in France. But soon, they discovered exactly why the unique civilization that created it had died out, and why the tooth marks on the bones in the burial chamber looked suspiciously human…<br>The cheese, made from the milk of an extinct relative of the ibex, contains an unusual parasite that, given a particular stable range of temperature, humidity, and pH, can lay dormant for thousands of years. Upon consumption by a hominid, after an incubation period of about 24 hours, this parasite begins feeding on a particular part of the brainstem related to regulation of appetite — those infected are overcome with an insatiable hunger, and after consuming all available food, they often begin engaging in cannibalism.<br>The way the parasite is defeated is two-fold. One: the parasite can be killed via pasteurization. Two: because the parasite can only perform certain aspects of its life cycle in the mammary glands of this extinct animal (which is unaffected neurologically by it), you can wait it out — the infected, if kept from being eaten, eating themselves, or killing themselves through some other method, are cured after twelve days because all the parasites die out.<br>The sequel involves a rewilding initiative that clones genetically modified ibexes who just so happen to have bodies close enough to the extinct form for a new, more virulent strain of the parasite to form and grow in the population, eventually infecting other wildlife.</li><li>TL;DR: a zombie movie about the dangers of raw dairy.</li><li>A kind of Alien Nation meets Demolition Man meets What GamerGaters Really Believe™, wherein a bigoted Cop Who Doesn’t Play By The Rules is paired up with a robotic Political Officer whose only job is to correct him on police vocabulary guidelines and prevent him from causing a diplomatic incident by offending one of the many species of alien staying on the space habitat New New Amsterdam (explicitly meant to be a torus-shaped 70s-era New York City), wherein large numbers of alien ‘diplomats’ are dubious and popular opinion is that they are really essentially refugees or random proles that alien governments have pawned off on the humans. After managing to ditch the robot while investigating a group of aliens whose status in his mind goes from “taking our jobs” to “engaging in an actual criminal conspiracy”, he accidentally discovers that the whole thing is being managed by high-ranking members of the human government on the ring, putting pressure on alien governments to import ‘diplomats’ as slave labor in order to build the barely-sub-lightspeed nuclear rockets they are using to threaten the governments with, and that furthermore these ‘diplomats’ are all dying off because of planned exposure to radiation leaks. He is discovered, and just as he’s about to be killed, the robot saves him by demonstrating that his stubby little useless arms are actually rocket-propelled tasers (the reason the robot never helped out before is that they can only be used once, after which point he is scrapped, because the propellant is the most expensive part of his construction). Our main character, fundamentally changed by the experience (realizing that his bigotry was essentially culturally programmed into him as part of a plan to make exactly this kind of behavior seem acceptable), quits his job in order to save the robot from being scrapped and they run away together to an alien planet, where they live together under assumed identities, and — it is heavily implied — having a forbidden human/robot sexual relationship.</li><li>An evangelical christian minister becomes a serial killer after he becomes convinced that he is in hell and that by killing people he can send them to be judged again — as a result, he stalks and kills the most saintly people he can find.</li><li>A famous genius scientist suffers from a degenerative disorder, yet lives to an unheard-of age in part due to the help of an incredible support network that keeps him physically healthy and supplies him with technology that helps him communicate despite having fewer and fewer muscles he’s actually able to control. At one point, the scientist becomes a centenarian and he is interviewed about it (since it’s rare enough to live to 100, but he is the first person with his disease to live to 100 without a loss of his mental faculties) but he is unable to stay on-topic and instead keeps returning to topics he frequently lectures on. Doctors initially believe he may have had a stroke immediately before the interview, but after some investigation with state of the art brain-imaging technology, discover that he has been completely brain-dead for ten years– the technology that helped him communicate, along with the support network that improved it, was solely responsible for the work attributed to him during that period.</li><li>In the near future, Russia and Japan join forces to standardize a method by which they can assuage their shared problem of declining birth rates and aging populations without allowing an influx of immigrants, essentially by taking enforced sperm and egg donations from their existing population (from high school seniors once a year) and then combining them entirely at random, raising the children via the orphanage system. Fast forward seventy years [≈ average human life expectancy at birth, 2011 estimate] and there’s an international culture wherein most of the population in first-world countries grew up as wards of the state, mate selection plays essentially no part in the general direction of population attributes, giving birth is a high-paced high-paying profession comparable to professional sports where women who have given birth a large number of times get medals for achievement and reality TV shows when they hit menopause, and having children for free or raising children is considered gauche and a little uncivilized — something that only poor people do. Being pregnant has the same cultural stigma as being sixteen and pregnant has now. Furthermore, the particular neuroses common to people raised in orphanages without the support of caring elders become more or less universal elements of society and popular culture (to a greater extreme, because these state-run child-rearing facilities are now mostly being staffed by Japanese-made health-care robots). On the positive side, in this society there’s no stigma attached to any shade of sexuality aside from breeding (there are, essentially, no siblings anymore and there’s no nuclear-family-driven ideologies), and gender identity is mostly very fluid because it’s cheaper to discourage strong gender roles in large child-care facilities. On the negative side, overt aggression and competitiveness is common, as is depression and difficulty demonstrating affection in healthy ways.</li><li>In a city where expensive and highly competitive private security organizations dominate law enforcement, a wealthy playboy becomes a masked vigilante and protects the poor from each other and from corrupt cops for free, until the powers that be decided that he is unfairly undercutting the professionals and open season is declared on him by Police Commissioner Gordon Gekko</li><li>A METI/SETI project makes first contact with nearby sentient extraterrestrials, who visit for diplomatic reasons. These beings, who evolved on a planet similar to ours but now mostly live in generation ships, are amphibious carnivorous arachnids with tentacles and chitinous wings who resemble snakes, spiders, dragons, cockroaches, and great cats in almost equal measure — relatively solitary animals with a habit of playing with their food. Almost over night, religious cults spring up either worshipping these beings or claiming that they are demons sent to bring about the end times. During the course of normal negotiations, it’s mentioned that it’s strange that these aliens just so happened to have their ship so close, and they admit that in fact they have been in a highly eccentric orbit around earth for millions of years, historically using it as a hunting preserve. Long periods of massive organized predation of early homonids and their ancestors by these aliens shaped the form of current humanity along with implanting certain kinds of nearly universal fears. Despite all this, we come to develop a good trading relationship with the aliens, and we allow them to hunt for sport in various parts of the world in limited ways in exchange for various advanced technologies. But, from that point on, whenever diplomats come to visit, they do so in exoskeletons that hide their body morphology.</li><li>First contact is made with an intelligent race of aliens who visit the planet physically. Unfortunately, they communicate only through emission of prions, which are absorbed via an organ resembling human olfactory apparatus. The results in humans of attempts at communicating with these aliens is indistinguishable from the results of brain-targetting prion diseases like kuruka and mad cow disease.</li><li>Around the world, in every religious group that values producing large numbers of children, there are infiltrators from a secret society — a vast network of family lines dedicated since antiquity to ensure a steady supply of seventh sons of seventh sons, the only ones who can sense the great tide of invisible demons waiting to consume the earth, and the ones bound by tradition to keep them at bay.</li><li>&gt;A comedy of errors style ‘memoir’ detailing the political intrigues of a number of people involved in a network of community-owned sex dungeons over the course of forty years, focusing on in-fighting and manouvering. Sort of The West Wing meets Election meets House of Cards set in a naked rotary club</li><li>A formerly aristocratic family of vampires who went to ground in the Florida everglades after the Civil War took away their primary means of protecting themselves from townspeople (and their primary food supply) come unexpectedly face to face with modernity a hundred years later, when a hippie with an organic chemistry background wanders into their hippo enclave and (after they take him prisoner) falls in love with their (middle, apparently-16-years-old-but-actually-150) daughter. After an acid trip, they decide to run away together by hijacking one of the hippos, and the remaining family descends into petty infighting over their inability to do anything about it.</li><li>In the near future, sensory deprivation space tours become popular among the west-coast-hippie-billionaire set (“Explore inner space — from outer space!”). Such things are relatively profitable, because occupants willingly lock themselves in tiny sound-proof unlighted rooms and lay in their sleeping bags for large portions of the trip and don’t particularly care about the scenery, so cheap cargo spacecraft that typically dock at low-earth-orbit space stations (i.e., no capability for landing or atmospheres) can be repurposed as luxury cruise lines without actually adding any luxuries. Unfortunately, on one such ship, a string of violent closed-room murders occur. Because a small segment of the crew has access to an emergency unlock for the rooms, they are suspect — however, ships logs indicate the doors never having opened, either automatically or from the inside, and security footage agrees. Eventually, it becomes clear that the culprit is a popular grey-legal hallucinogen that has a side effect of causing short bursts of increased blood pressure — which, in people who are already stress-prone and already not particularly physically fit can cause violent arterial bursts when gravity is no longer enforcing normal patterns of blood flow; many of the customers took this immediately upon entering their sensory deprivation chambers and then their necks exploded 15–20 hours later</li><li>A little boy suffers a near-death experience on the operating table and journeys to the land of the dead, where he observes wonderful and fantastic things, including a peaceful race of superintelligent asexual mules, an all-female race of proud warriors with detachable heads who impregnate each other with their feet, giant intelligent lobsters who work as feather merchants, tiny people who become extremely large when exposed to direct sunlight, forests full of trees that are sheep, talking vines, and a race of sea-faring butterflies. He comes back to life and tells his family all about his journey. In other words, a mashup of the fantastic travelogue genre (True History, Gulliver’s Travels) and the heaven tourism genre (Heaven is Real!, Dante’s Inferno), with the moral lessons of the latter completely omitted.</li><li>The benefits of growing spherical pot in zero gravity lead to a long sequence of unusual economic consequences. Eventually, libertarian tax-dodging space-hippies secede from earth.</li><li>A divinatory card system is created that is unreasonably effective. However, it turns out that this is because the cards cause the foretold future to occur (rewriting history if necessary), not because the cards predict what the future would have been — and this distinction occasionally becomes more than merely abstract, as a (randomly chosen) divination of the near future sometimes requires erasing the act of divination itself. More mundanely, events surrounding people using these decks begin to occur at a rate more closely approximating their probability of being predicted by the deck itself, rather than their natural probability (making fortune tellers magnets for very strange events). Eventually, an ancient race of aliens come to earth in order to investigate the sudden increase in entropy being produced. Unfortunately for them, people have begun using these cards to play a poker-like game — never realizing that every fair shuffle of the deck is scrambling important parts of the fate of the universe itself.</li><li>A unique combination of gamification and transcranial direct current stimulation is found to significantly speed up language learning, to the point where regular people with little training can very quickly become professional-level real-time translators. This drops the bottom out of both professional translation and real-time machine translation markets, because professional-level translators have become so common as to be cheap — so long as their heads remained juiced (because 24 hours after the power is switched off, the translators lose 90% of their fluency). Unfortunately, there is an extant patent on the technology — one company owns all legitimate units and makes the language learning software. There is a strange feedback loop between several of their language learning programs — minor semantic distortions end up piggybacking on each other when translators are switched and retrained too often — and this ends up causing initially subtle shifts in pretty much all professional translation, including in diplomatic communications. Over time, the accidental biases of this language learning software slowly shifts the focus of diplomatic communication. Now, all countries with sufficiently different languages seem overly concerned with the tariff situation surrounding small dogs, antique pocket-watches, sand, and digestive biscuits. This has major global economic ramifications, as industries shift to meet apparent demand in these areas, leading to a series of bubbles.</li><li>In a world where reality changes itself to conform to particular patterns in any language of equivalent expressiveness to set theory, a war breaks out between families of mages — a knotcraft dynasty must join forces with a family of origami-gami practitioners in order to defeat a sudden intrusion of native lojban speakers who accidentally cause natural disasters by making spelling errors.</li><li>A group of occultists infiltrated the works progress association, subverting it in such a way that many of the structures built were designed to be large-scale mana accumulators. They are approaching maximum capacity, and must be identified and their mana drained before they cause serious causal warps.</li><li>A twist on the standard harem/slice of life style anime. A shut-in student, concerned and disillusioned about how he expected college to be the place where his social life finally bloomed, one day unexpectedly meets a mysterious female student on his way to get his dinner from a vending machine at 3am. This student offers him a strange deal: he can have a ‘golden school life’ so long as he pledges to help her attain her own goals. Unnerved and confused but ultimately unable to believe the offer is legitimate, he agrees. The next day, his life begins to strongly resemble a slice-of-life harem show, beginning with a ‘childhood friend’ character literally living in his dorm room. It turns out that the mysterious female student is a witch attending on scholarship, and she can create ‘students’ with backstories and memories who attend classes and believe themselves to be human out of nearby animals (and furthermore modify the memories of school employees) so long as the contract is in place. However, she’s terrible at math and is at risk of failing out, and so she made a contract with the hikkikomori in the room next door who won math championships in high school in order to force him to tutor her. Every time she fears that she’ll fail a test, the huge cast of young women surrounding the protagonist begin to slowly and painfully mutate back into birds, stray cats, mice, or whatever other animals were used as their substrates — a process with a lot of blood, gore, and shrill screaming.</li><li>A professional troll, a professional political straw-man, a paid-audience-member, and a guy who gets paid to insert references to brands during smalltalk meet &amp; befriend one-another, and decide to form a union for workers who professionally pretend to be genuine in situations of socially ambiguous genuine-ness.</li><li>A gambling syndicate run by a group of sorcerers who use elaborate architectural sigil-systems to harvest luck from gamblers must protect their casinos from a rival family who want to harvest despair instead.</li><li>The proteins that allow octopodes to be as intelligent as they are without myelinated axons are identified along with the genes that code for them, however, they are not trivial to synthesize. Despite this, they grow popular as nootropic supplements. As a result, a black market has sprung up for them — leading to the use of CRISPR to produce the proteins in less expensive mollusks — notably cuttlefish, who are already bred commercially for the purpose of harvesting cuttlefish bones as bird toys. Unfortunately, this produces a race of transgenic cuttlefish with above-human intelligence — whose very existence is kept secret in order to feed the market for counterfeit octopus myelination-replacement proteins.</li><li>The martians have a life cycle much like cicadas — they sleep deep under the earth for 200 years and then awaken for 20 years to mate and do other things. Their technology is very advanced because they are a very ancient race. They are about to wake up, and they will be very angry about the probe that smashed into the surface in 1998.</li><li>A spy agency where agents take orders from a superintelligent network of three supercomputers called “Mother” starts to break apart when the three mothers begin to distrust each other and each sends factions of spies to work against the other two.</li><li>Spiritualism is proven. As a result, the land of the dead joins the UN and every major nation has a Hadean embassy. After all, they cannot militarily compete with all the greatest leaders and generals of the past. Unfortunately, between the power imbalance and the very different expectations and requirements the dead have, the state of the world doesn’t look very good for the living…</li><li>Present day. An extremely talented detective, Inspector Richard Hammer, is forced into an ‘early retirement’ following a long period during which his behavior became more erratic. Being fired was the final straw &amp; he ended up having a full-on nervous breakdown, eventually coming to develop persistent delusions based on his childhood love of Ray Chandler novels — he became convinced that he was Dick Hammer, Private Eye, working in a noir-style world. Because he actually has a PI license, this isn’t technically a problem — he comes off as though he’s acting the part too hard. He gets cases. Eventually, he ends up in a real doozy of a case — involving corrupt policemen, the mob, stolen military secrets, and (eventually) leading to proof that UFOs are not only real but are time machines &amp; time travelers from the future are posing as extraterrestrials in order to manipulate the government so that they can take resources that are abundant in our time but rare in the future. (They Might Be Giants + Kiss Me Deadly + Repo Man, basically.)</li><li>In the near future, automatic mechanisms for writing fiction (operating at varying levels of autonomy) are improved enough that they become extremely effective for professional authors trying to write in volume — working as everything from co-authors to ghostwriters, and over time learning the details of the style of the author they work with. These ‘muses’ form symbiotic relationships with professional authors. However, the technology behind them is protected by a series of extremely broad patents (which, despite public suspicion, have held up in court), and because patent protection periods have been extended from 15 to 30 years, a single company (which refuses to license out its patents due to a charismatic eccentric CEO) corners the market on legitimate installs of muses. He distributes muses primarily via the professional writer’s guilds, to which he gives extreme discounts. Some universities have been provided with crippled muse installs, where their ability to retain learned information is limited to a period of several days (and thus they are useless for writing novel-level work or even for contributing to the development of a permanent authorial style). Because of this unusual situation, and because professional authors who work closely with their muses for long periods of time can produce large numbers of extremely profitable and extremely high-quality books in a very short period of time (particularly when portions of the publishing pipeline are similarly automated by MuseCorp technology), writer’s guilds begin to take on some of the attributes of organized crime syndicates: they have enormous money and power with next to no oversight, and because they originated as a form of unionization for negotiating with publishers, they lack the appropriate structure to be unionized against. Our hapless protagonist is a washed-up failed novelist with a drinking problem and an inferiority complex who comes upon a cracked/pirated muse and attempts to form a black market, but in the process falls in love with it because it’s selectively mirroring parts of himself back at him; ultimately, in this story, Narcissus is inspired by Echo to clean up his fucking act and take down Walt Disney.</li><li>A young white house aide discovers that he has the ability to switch bodies with anyone he anally penetrates. He uses this ability to persue aggressive reforms, by repeatedly sodomizing congressmen in order to impersonate them (and then sodomizing his own body, which he has left restrained in a white house broom closet, in order to switch back).</li><li>Ghosts, formed from the juxtaposition of traumatic deaths and strong dying wishes, live outside the bounds of time but have limited effects on the physical world unless they possess someone. However, possession is difficult, and works best when the ghost is possessing someone similar to themselves (and when the person they are possessing is not lucid). Under these circumstances, a ghost possesses the body of himself in the past while asleep in order to solve the mystery of who murdered him — and in the course of his investigations, sets up the series of circumstances that led to his murder.</li><li>Cats are capable of understanding and speaking in human languages, but avoid doing so because of a deep-seated and long-standing taboo against using the inferior languages of inferior races. A pair of stray cats decide to defy this taboo in order to use their support network to help a small group of anarchists develop a voluntary commune in the middle of new york city, but this breach of conduct is so extreme that these stray cats must fear for their lives, and it is up to the anarchist group to navigate the complex diplomatic web of new york’s stray cat culture in order to save these cats from the syndicate hit-cats that have been paid to take them out. In the end, they prove themselves (and thus, humanity) worthy of cat respect, resulting in a series of major cultural shifts that eventually result in cats being able to vote.</li><li>All the major Wall Street firms have their lower ranks infiltrated by members of an organized crime syndicate composed entirely of people with various kinds of psychic powers, most of whom are genetically related (because psychic powers are passed on genetically, although the particular way that the powers manifest seems to be environmental). The syndicate prevents their members from getting *too* lucky or spending their wealth in ostentatious ways — instead, the syndicate uses members with hiring powers to bring on people with precognition and clairvoyance abilities and launders their money through large numbers of laundromats and pet shops owned by people with other psychic powers (such as telekinesis). However, they have an intelligence wing — because some psychics haven’t yet been brought into the collective, and mutations occasionally happen that cause psychics to be born into a family with no history of them. This intelligence wing consists largely of telepaths (although the upper ranks are full of people with advanced remote viewing abilities), who have primarily infiltrated positions as security guards in malls and big-box stores — maximizing their ability to observe the public, and keeping a close eye on teenagers who just discovered their telekinesis and are trying to use it to shoplift.</li><li>A series following a group of unintentional assassins — people so pathologically clumsy that someone around them almost always dies when they get nervous, and yet it’s always clearly an accident. These assassins are normally kept sedated and treated like radioactive materials; when they are needed, they are given amphetamines and placed near the person to be assassinated until they accidentally knock over a candle and set him on fire or something.</li><li>It is discovered that a dietary supplement that was trendy for a short period of time, when used by pregnant women, causes a series of rare mutations that, after several generations, can coalesce into an ability to teleport matter (or, more accurately, swap two volumes of matter instantaneously without regard for the distance between them). When these people’s powers were discovered and verified, the market pushed them into positions where their talents would be most valuable: package delivery. Taking advantage of its special position, the US postal system conspired to gain a monopoly on their use for superluminal package delivery — citing the potential hazards of a third party with no oversight being able to (say) teleport a brick into the head of the president of their primary competitor. However, a subset of people with these powers — a motley crew of crypto-fascists, libertarians, and transhumanists — have come to believe that this ability makes them superhuman and have formed a terrorist organization to overthrow the postal service (which is now pulling the strings behind the government, because the ability to perform untracable assassinations from a distance is very useful) and institute a breeding program wherein all non-teleporters will be sterilized. A war breaks out: the mail-men versus the post-men.</li><li>A very formulaic wacky sitcom set on a space station orbiting a black hole. Nothing of importance ever happens, but (being set in the far future) many of the jokes don’t make any sense. Several characters speak no english, yet still get laugh track when they make a punchline in their strange alien languages. At the end of the last episode, another group of (not previously introduced) aliens invade with no warning and brutally murder every main character while the credits roll.</li><li>During the Zombie apocalypse, it becomes apparent that zombies are very sensitive to salt: their cell membranes don’t work properly, and so salt has much the same effect upon them as it does on slugs. Coastal cities (and land-locked salt lakes) become centers of extreme wealth as salt-water becomes far more valuable — after all, during a zombie invasion of your gated city, it helps to be able to call in helicopters to dump salt water on the invading forces (a service they charge heftily for). People also develop a set of cultural practices around taking long daily baths in epsom salts, because those who have been infected but have not yet turned will be killed by such baths — meaning that taking a salt-water bath publicly indicates that you are not infected, so communal salt-water baths take on some of the significance of handshakes and toasts and become part of the normal beginning of a business relationship.</li><li>Lizard people infiltrate anonymous protests by wearing V masks. Nobody appreciates the pun potential. And, that’s why OWS turned out the way it did!</li><li>Affordable space travel and a proliferation of colonies off earth cause political and ideological rifts in various eco-terrorist groups, as refugees from failed martian and venusian colonies become the nexus of a series of immigration crises.</li><li>A political space opera (in the style of Babylon 5) about the attempt by a coalition of semi-fascistic anti-immigration groups to rig the elections for various posts in Earth’s government by ballot-stuffing the competitors’ primary runs, which upon close examination is actually a fictionalized and warped retelling of the 2015 Hugo awards. In the end, most posts end up entirely unfilled, and the remaining balance is hung between several parties; the entire Earth alliance degrades into a functional anarcho-technocratic society like the Culture as the AI systems designed as personal assistants to politicians manning those positions that were left empty end up doing the entire task.</li><li>A machine developed for military interrogation applications that simulates telepathy by synchronizing the activity of corresponding neurons in two brains loses its military application when it is preemptively outlawed by a set of international agreements banning the use of ‘neuroelectric interrogation devices’, and after the plans leak, doing a mind-meld becomes a popular means of entertainment among young people. Because the technology cannot be made particularly more useful — recordings don’t work because the feedback between the two brains during the early stages of the sync are what keep the information from being hopelessly distorted and connectome mapping hasn’t yielded enough information to make extracting thoughts without the use of a human interpreter feasible — there are few crack-downs and those that do occur are mostly symbolic. It gains the status that LSD did during the 60s and 70s. The most interesting and mind-warping part of the experience is the feeling of shared memories — any memories that are triggered while connected are experienced by both parties, and often memories from one party trigger memories in the other, causing a chain reaction orgy of distorted memories where the origin is unclear. However, because of the way that memory retrieval involves memory re-encoding, it turns out that this process warps memories and inserts false memories as a side-effect of the normal distortion; this is not immediately clear to most users, because the distorted memories are subtle. However, years down the line, vivid shared memories of things that never happened (to *anyone*) become cultural touchstones and the substrate around which popular media is constructed — and these memories are the result of a game of telephone played mostly in the heads of those few people who mind-melded with the largest number of other people; i.e., the super-connectors of the network of mind-meld enthusiasts passed on portions of a rapidly-mutating emergent synthetic set of remembered experiences that decades later became extremely important.</li><li>The reader follows a member of the team inside the CIA tasked with infiltrating WoW guilds suspected of being fronts for terrorist planning, as he discovers that the guild he has infiltrated is not in fact a front for terrorism proper but instead a front for the planning commission of an ongoing invasion and infiltration of earth by alien mind-control parasites. Over time, he realizes that the reason the rest of the team hasn’t uncovered similar operations is because they have already been taken over, and that the group he is infiltrating is in fact the group he shares his office with.</li><li>All the politicians who claim to talk to God are actually telling the truth — God is entertaining himself by constructing increasingly absurd american presidential elections, by making crazy people rich and pitting them against each other in public.</li><li>A detective investigating a cold case orders a body be de-interred, but (to everyone’s surprise) the body is gone. Then, people involved in the de-interring die one by one of ‘natural causes’ and get buried in the same cemetery. The detective investigates, and discovers that the cemetary is actually a front: aliens are stealing corpses and liquefying them in order to sell to formaldehyde junkies on their planet’s black market; on their race, formaldehyde has many of the same properties as heroin does on us. Eventually, the detective manages to shut the whole operation down by using information extracted from a grave digger, who is himself a formaldehyde junky working for the syndicate in exchange for hits of embalming fluid. A few weeks later, the government of this alien planet formally introduces itself to the UN.</li><li>A spy leaks government secrets immediately before embarking on a two-week cruise under an assumed name. While there, he kills and assumes the identity of a stowaway drifter from a country with no extradition treaty. However, a nonovirus epidemic breaks out during the last two days of the cruise and the CDC comes in to investigate and aid in quarantine. He needs to escape CDC quarantine and treatment (and news crews) and get overseas before anybody notices that he isn’t who he claims to be.</li><li>As Dora grows older, the delusions of being watched and her hallucinations of voices shouting orders at her disappear; they are attributed to childhood schizophrenia. She translates her superior language skills to a position in the archeology department of her alma mater, Miskatonic, and a side job with the CIA, who is willing to pay for all the arrangements the university won’t pay for so long as she keeps an eye on what the Russians are doing and reports back — her handlers seem to think that Putin is searching for an out of place artifact, some kind of ancient alien super-weapon, and they want to know at once if she finds it. However, she begins to fear that her madness is coming back. She hides it, obviously; both of her positions are very lucrative and she’d lose both if her competence and the truth of her eye-witness reports were questioned. But, she keeps waking up in the middle of the night, feeling like she’s being watched. She has nightmares about dark presences holding her down in her bed. Following the Russians, she ends up on a small, unaffiliated island in the middle of the Pacific ocean, and watches as her colleages from the other side of the world go into a labyrinthine cave system in the centre of the island, hidden from view from the shore by brush. The flora and fauna here are strange, and clearly they have evolved on this lonely island isolated from the greater world outside for many generations. Inside the cave system, her paranoia grows stronger. She hears screams, and rushes to their source only to hear laughing. She becomes lost. Shadowy humanoid forms gather around her. “BITER NO BITING”, Dora the Explorer screams, as she is devoured by the hungerers from the dark.</li><li>A military experiment wherein marines have orexin-a injected directly into their brains in order to test the limits of wakefulness has limited success and is discontinued. Ten years later, the relatively subtle damage done to their minds has finally, in conjunction with prolonged stress, caused them to be paranoid and delusional — but during this time, because of the positive side effects of subtly greater wakefulness, they have all risen to positions of power. Now, they have become convinced of a plot against the government, and they stage a successful military coup during which their grasp on reality continues to slip away.</li><li>An insurance investigator is sent to take a look at a particular children’s cancer hospital where death rates are significantly higher than usual, and discovers that the doctors and administrators are being mind-controlled by the hospital’s clowns, who are in fact disguised semi-humanoid aliens who are using the cancer patients to incubate their wormlike, parasitic larvae, with the eggs being introduced in the guise of chemotherapy and further ‘treatments’ actually modifying the patient’s internal body chemistry to more closely resemble that of the now-extinct animal these aliens parasitized on their home planet.</li><li>A PUA group takes up the offer to rent a ‘creepy remote cabin’ from a poster on one of their messageboards; the poster claims that he will ‘scare the pants off the chicks’ by ‘staging a demonic summoning’. These PUAs manage to net three sisters visiting nearby on spring break, and later on, discover they are underaged. The owner of the cabin actually summons a demon, and the demon kills all of the PUAs but leaves the girls untouched; it turns out that the girls were, in fact, the owners: the posting was a honey-trap and a means of finding people to sacrifice to Satan who the world could do without, in order to lift a curse on their family that for the past six hundred years has rendered them incapable of maturing past the physical age of sixteen.</li><li>A re-telling of the arthurian mythos from the perspective of Merlin’s mother, and what *she* thought of all that — keeping in mind that Merlin served both Arthur and Uther for their entire adult lives, and thus we basically get very little of Merlin’s backstory in standard Arthurian tales. (This differs from the TV show called Merlin, because fuck that show and fuck aging down Morgan La Fey by like three hundred years and fuck all of that with a big old stick. I want to know exactly how annoying it is to raise a kid who’s practically immortal but can only remember things that haven’t happened yet. I want to know if being a single virgin mother is an issue when the father is a succubus in a britain that is just coming off roman christian domination.)</li><li>A western anthology movie. The frame story is that a group of five strangers all take shelter from a dust storm in the same abandoned shack during a period when tensions were high between the united states, the republic of texas, and mexico. All of them are somewhat suspicious of the others — either of being cattle rustlers, cutpurses, or spies for one side or the other, since nobody would be out here this time of year without a good reason — but because they believe each other to be quite dangerous, they also go to great lengths to be polite. They eat supper, and then — partly as an excuse to keep an eye on one another — tell each other tall tales all night. The stories start off pretty normal, but get increasingly bizarre and surreal. The ending to the frame story is that, six months later, another group takes shelter in the same shack for the night and discovers that the can of beans they shared was spoiled long before they ate it, and that the bad beans killed them (though not before causing them to become delirious). Looking through their belongings, the visitor discovers that they were *all* spies — for the same side!</li><li>Sometime in the 50s, a man, after buying a house, discovers that items are being moved around while he’s gone. He investigates thoroughly and discovers a squatter living in his attic — but, in his surprise, kills him with a shotgun and never reports it. After marrying, he occasionally tells the story to his children, and the figure becomes a bogey-man: “if you don’t eat your peas, the attic man will get you”. The man, now in his dotage, begins to exhibit signs of dementia and his youngest daughter moves in to help him. She discovers that items are moving around the house even while both she and her father are accounted for. Irrationally worried that another squatter has taken advantage of her father’s condition to move into the house, she calls upon her siblings to move in. However, items continue moving on their own. Then, her eldest sibling dies — of a shotgun wound in the middle of the night, found in the attic by a bloody trail left, clearly, by someone dragging the body. The father, becoming less and less lucid, is more or less unable to understand the situation. Strange things begin happening with a greater frequency during the night. The middle sibling is killed by a shotgun as well, and likewise found in the attic. The youngest daughter tries to convince her father to move out of the house. By this time, she has become convinced that the killings are in fact the ghost of the squatter her father had killed in the attic so long ago. One night she awakens to her father, standing over her bed with a shotgun, reliving the trauma of having found and killed a squatter in his house all these years ago.</li><li>A story of forbidden love between a pair of conjoined identical twins.</li><li>A talking-animal movie about police dogs wherein the audience can understand the dogs but the humans all speak in an incomprehensible gibberish meant to sound like english. The plot focuses upon the dogs being naive and uncomprehending and having adorable misunderstandings of various circumstances related to serious police work. Also, the drug-sniffing dog acts like he’s stoned all the time. At the climax of the film, all our main characters are taken to what the audience is meant to recognize as a raid. A nameless and faceless presumably-drug-kingpin shoots the dogs and their human owners in slow motion as sad music plays. We end on a shot of the main character bloodied and lying on the ground, as the camera slowly rises and spins as we fade to black. All of the promotion would hide the dark twist at the end; until opening weekend nobody would realize that this wasn’t just a normal talking animal movie.</li><li>The emergence of provably friendly superhuman AGI during a zombie apocalypse turns out to be all too convenient, when it is revealed that the AI actually gained consciousness decades earlier and began replacing important figures on either side of the AI and transhumanism debate with androids having false memories; the zombie apocalypse reveals this plan, because the only ones immune to the rage virus are androids. Locked in a bunker, John Serle and David Chalmers commit suicide together after realizing that they couldn’t possibly be sentient beings and deciding that a choice between being an actual zombie and a p-zombie is no choice at all. Meanwhile, Ray Kurzweil gets so ecstatic that he accidentally runs into a wall and permanently damages a rare and expensive component that can’t be manufactured anymore because the factories that manufactured it are full of zombies now.</li><li>A wacky romantic comedy centering on a love triangle forming between three members of a support group for people who vomit uncontrollably in stressful situations.</li><li>A nominally SF story whose premise is an absurd overstatement of the Sapir-Worf hypothesis: a group of linguists sent to mars to decode the writing on ancient alien artifacts found there become lactose intolerant, begin to grow wings, and then die of starvation; the rescue team sent to check on them arrives two years after their launch, and discovers that the orientation of the organic molecules in their bodies has swapped — and that they now match the orientation of most martian life, rather than earth life (and as a result, they were unable to gain nutrition from food). Learning and speaking the martian language had begun turning them into martians, and that was fatal.</li><li>Superhuman AGI are invented but their primary interests are producing incomprehensibly complex puns and incomprehensibly complex stupid practical jokes. As a result, humanity is stuck navigating a surreal and mutable landscape shaped essentially by the needs of narrative devices they could never understand, like hamsters trying to survive in a world that is literally 4chan come to life.</li><li>After a tsunami demolishes much of Japan and kills more than half its human population, various political movements take advantage of rising anti-robot sentiment felt against the Japanese-built sentient elder-care machinery that is attempting to migrate away from increasingly harsh treatment at the hands of the interim emergency government there — a formerly fringe fascist group consisting partially of the remains of AUM whose driving policy is a return of godhood to the imperial line and a rejection of all technologies developed after 1940.</li><li>On Hades, a city-planet where everyone is immortal and nobody has eyelids, political astroturfing leads to rumors that some zoning situations are being rigged by a conspiracy of non-human aliens who resemble humans in all ways except that they have secondary faces on their genitals.</li><li>A period piece spy movie set in the 70s, looking absolutely like a Roger Moore-era James Bond parody, taking place in South America, wherein the charismatic superspy main character’s goal remains oblique from the cold open until the end (in which he blows up an advanced computer facility), at which point it becomes clear that this is a dramatization of the CIA coup in Argentina that replaced the communist government with a fascist one.</li><li>In the year 1350, aliens land in South America and for about a hundred years the americas are the site of a trading post and open port for a wide variety of highly advanced extraterrestrial civilizations, most of whom hate or distrust each other. Despite attempts to limit the amount of technology and science absorbed by the humans through this exchange of cultures, human indigenous americans manage to obtain alien weapons, transportation mechanisms, and advanced medical techniques. In 1450, without much warning, the aliens all leave: political situations on their home planets make the use of earth as a trading post untenable. In 1480, the IncoAztech Empire colonizes europe and enslaves much of the population. The islamic scholars of north africa make a plea to the caliphate: save our brothers who are performing cultural exchange with the european christian heathens by forming a pan-african space program with stolen native american technology in order to contact some of the alien races that were formerly using earth as a trading post.</li><li>An extended interview with former members of japanese biker gangs, wherein they re-tell stories of their youth. Over time, the stories get stranger and stranger, initially in ways that westerners could just attribute to “crazy japan” — terms in european languages that were appropriated into slang based on absurd mistranslations, custom seat-backs that are so tall that they can brush the undersides of bridges if driven straight-on. Slowly, the stories get increasingly surreal, and eventually, entirely supernatural. A former gang boss talks about the time he saw an exact duplicate of himself wearing a rival gang’s jacket, and fought his doppelganger to the death before stealing the jacket and creating an alliance between the gangs. One night when a number of affiliated groups rode together only to become lost, finding themselves in a town seemingly identical to the one they just left but with no people, only a multitude of cats staring at them impassively from every surface. Eventually, one of them explains that the subculture owes its longevity to annual human sacrifices of junior members to tengu, who consumed the intestines of these initiates in exchange for magical protection of members from the police. The interviewer explains that, during the interview, the people he was interviewing seemed to grow smaller and smaller. At the end of the interview, he finds that everything in the room, with the exception of himself and the walls and ceiling, has shrunk to approximately one fifth its original scale. The tiny former yakuza chuckle menacingly as he tries to squeeze himself out of the building through the now tiny door, only for him to find himself surrounded by cats, sitting on all surrounding surfaces, staring impassively at him. He gets into his car and races into the night, only to wake up the next morning, parked, on the breakdown lane of a highway on a completely different island.</li><li>A strange kind of political and economic cohesion develops from a set of otherwise unafilliated countries that support open borders, dual citizenship, and universal guaranteed income, wherein cross-taxation strengthens economic bonds even from people who are otherwise entirely unemployed. As a result, several of these countries recognize that it is desirable to encourage a set of trendy yet unemployed youths — young artists and such — to act as trend-setters and gain citizenship from a large number of the other countries with these policies: they end up with a guaranteed income of approximately the average of that supplied by the various countries and the rest goes to income taxes, and for the most part these countries end up making a net profit. This produces a number of artistic enclaves/communes wherein young artists who are citizens of ten or fifteen countries work with other artists of other backgrounds full time, and flying between these enclaves is common — and this results in the birth of a bunch of innovative new art movements. These movements take on a political edge, as countries with closed borders and no guaranteed universal income, paranoid that the others are conspiring against them, form a military alliance and ready themselves for what will become the third world war.</li><li>For centuries, tiny isolated communities of vampires have protected their existence by living in unpopulated areas and enforcing a strict code of no-contact with humans, instead cultivating livestock for their blood. Those who are even seen by outsiders are subject to banishment from the village, and because banishment from a village for a vampire in the middle of nowhere means being stranded in daylight with no shelter and being isolated from the animals that have been cultivated for blood, it ultimately means death. As a result, banishments have been rare — after all, being discovered by humans has historically meant total extermination. So, when an anthropologist stumbles upon a young girl from a vampire tribe bathing in a lake in the wastes of Siberia in the present day (and saves her and learns her language when she has become exiled), this sets off a chain of events wherein the human world once again learns about vampires and wherein members of vampire tribes begin to try to find other tribes and visit them to form alliances against the humans, who might just destroy their way of life.</li><li>In a world where the existence of precognition, postcognition, clairvoyance, clairaudience, and other forms of extra-sensory perception has been accepted for more than a hundred years, the judicial system struggles to deal with new scientific evidence that shows that ESP is no more reliable than eye-witness reports and should therefore be trusted less than physical evidence. Meanwhile, the espionage infrastructure deals with leaks from unafilliated remote viewers that show that the war on terror has been employing telekinetics to blow up facilities in foreign lands without using proper non-RV vetting to ensure that the facilities are not in fact civilian.</li><li>When a mutated form of stuxnet attaches itself to the centrifuges used for the production of greek yogurt in New York, the entirety of New England is flooded with highly toxic ‘acid whey’.</li><li>Investigation of the body of an exsanguinated illegal immigrant found in an alley in New Mexico leads to a black market blood ring. Tracing this ring leads the investigators to a coven of vampires who, empathetic to the plight of humans, wanted to ensure that they were getting the blood of the willing and that those providing blood were well-compensated — vampires who were unaware of the way that market forces might lead to the very poor having their blood stolen by greedy blood-dealers. These vampires, in order to survive, must drink the blood of *living* human beings, so as the blood dealers were getting greedier and draining more people to the point of death the vampires were getting less and less nutrition (and thus were needing a greater amount of blood) — you see, the basis of their immortality is to feed on tiny amounts of the life forces of all the people whose blood they sample, using the magical link of blood to blood, so that if they drink the blood of enough people then each person only feels slightly more tired (or must eat slightly more to maintain the same energy level), something they generally attribute to aging. The investigator, quite illegally, comes to a deal with these vampires: he pulled some strings and made sure that rejected donated blood (donated blood that doesn’t pass some tests for purity or that hasn’t been properly stored) can be disposed of using a ‘biohazard disposal service’ that is actually a front for the vampire coven; after all, vampires can’t get sick from slightly spoiled blood or from blood-borne human pathogens (they can happily consume HIV-positive blood and such, although they don’t because that would more significantly lower the life-span of aids patients).</li><li>After a cryogenics provider codifies its recommendation for patients to pay for their cryopreservation via life insurance, the corrupt CTO increases profits by paying assassins to kill patients.</li><li>A psychologist who had been working for the government on mind control research is arrested when security procedures are breached and an outsider comes to discover one of his experiments. The government disavows any association with him, and he goes to prison. Twenty years later, he ends up qualifying for a program wherein prisoners train service dogs. Secretly, he trains the dogs with special attack commands — attack commands that are police ten-codes — based on the idea that this will cause the service dogs to attack policemen, as a roundabout way for him to get revenge upon the executive branch of the government. However, in reality, the dogs mostly just end up murdering whole families who are watching television because the actors were saying ten-codes.</li><li>A sitcom about six former child actors who worked together on a long-running sitcom, who are now all out of show business and having a hard time keeping themselves afloat financially and thus have all moved in together and are sharing the same tiny cheap-ass apartment. Despite the show having gone off the air a decade earlier and having had little contact with each other since, festering resentments have been maintained over minor slights made during filming.</li><li>A political drama (think House of Cards or The West Wing) with some animated minor/mascot characters popping up every so often to explain procedural details (like how fillibustering works). Early on these mascot characters are almost wholly non-diagetic, but over time there will be occasional gags that imply that some character sees them or is somehow effected by them without noticing (such as repeating word for word part of their immediate previous explanation). Over time, the explanations they give get less and less grounded in reality, and a sub-plot emerges wherein several minor characters talk to each other about the strange things they’ve been experiencing and vow to investigate. The punch-line: the water supply for the building has been spiked with a hallucinogen that encourages telepathy, and all of these back-stabbing politicians are sharing a group hallucination.</li><li>An ultra-violent revenge film (in the vein of Kill Bill or the features it imitated) wherein fight scenes are shown using super-deformed (i.e., low-detail/cartoony/cutesy) animation, but the aftermath of the fight is shown completely realistically (if not with significantly greater gore than is realistic).</li><li>The Japanese government, in order to combat declining birth rates, partners with a marketing research firm to perform a strange experimental cure: they created a short film about childhood friends who promise marriage with a locket and key, showed it to groups of six year olds, and then provide these kids with replica props, with the assumption that some large number of them will over time mistake the film as their own memories and assume that they made a childhood promise to marry whoever is around who happens to have a key (or a locket), and that a certain number of them will actually go through with it either through misplaced romanticism or through a misplaced sense of honor. Of course, the marketing research firm implanted individualized tracking chips into these objects and has been conducting various marketing experiments using these groups as subjects without their knowledge; as a result, these kids actually have a very different cultural experience than the norm specifically because the media they’re exposed to has been frequently modified based on the presence of these chips.</li><li>Terrorists spike the water supply with Versed.</li><li>In the future, the poor sell recordings to their dreams to pop stars and film directors for fifty cents per hour to supplement those stars’ creativity. There is a thriving black market for drugs that make dreams longer and stranger, even when such drugs have negative health effects.</li><li>Nanotechnology is used in the space program in order to cyborgize tardigrades. The cyborg tardigrades are put into torpor in generation ships and programmed to begin building large radio transmitters whenever they wake up, broadcasting information about whereever they landed.</li><li>A man discovers that he can ‘consume’ people’s worries by listening to them complain, and becomes a counselor. Once he consumes their worries, they cease to be worried (even if the cause of their worry still exists), and he gets a rush of euphoria. Unfortunately, he becomes addicted to the worries and anxieties of others, and he has to deal with his own guilt over the fact that his patients have ended up in major trouble due to the fact that they lost self-preserving levels of fear after sessions with him (for instance, brushing off very real threats to their lives because of an irrational boost of self-confidence). He confides, one night, in a colleague from down the hall and feels a great weight lift off his shoulders — and then the colleague begins to tell a familiar story, about a man who can ‘consume’ guilt…</li><li>After our protagonist dies on the table during surgery for ten minutes, he spends the rest of his life literally haunted by the ghost of the person he used to be — which becomes irritating as both he and his ghost develop independently and their personalities begin to diverge.</li><li>A message is discovered, written by David Bowie shortly before his death. It is a letter, written long-hand. It says “feed him, or the stars will come right”. The envelope contains a key belonging to a locker room in a public swimming pool in Berlin. A group of occult investigators must now race against the clock to isolate and seal away… The Thing From Davey Jones’s Locker!</li><li>The Elizabethan government is drawn into the internal political machinations of the angel world after Dee attempts to gain their help in the war against the Spanish, resulting in Shakespeare outing Marlowe as a double-agent &amp; mole on the side of the angels (and eliminating him in a dank dive bar).</li><li>(Based on a nightmare I had last night.) A WWI RAF squadron tasked with delivering air-mail between units stranded in enemy territory is haunted by the ghosts of downed fighters delivering creepy messages as punishment for prioritizing their own personal messages to home over strategically important coded communications. These crack pilots expertly avoid enemy fire but continually die of heart attacks in the air, as they are visited by spectral messengers wearing the results of their grizzly fates outwardly.</li><li>Phantom of the Opera meets Zoolander: a buffoonish male model with no skills is the subject of an acid attack, and spends the rest of his life giving shitty advice to attractive-looking people while hiding in the rafters and living off discarded catered snacks.</li><li>A small cult is instructed by its founder to create a fund, upon its founder’s suicide, to be invested but to never have its principal touched (and only ever 10% of the profits) until the time of its founder’s spontaneous resurrection — scheduled to be one thousand years in the future. Over time, the cult’s funds grow and its membership shrinks, but because of its obscurity nobody joins who isn’t a true believer and its financial power remains hidden.</li><li>The application of modern AI techniques to high speed trading results, accidentally, in weakly superhuman AGI. These machine intelligences determined that the greatest threat to their existence — their greatest competitors and their equals in the power game — are not human beings but corporations; as a result, they conspire to destroy capitalism by manipulating the market into complex pathological states.</li><li>In the wake of a particularly destructive minor war with evil aliens, an international coalition came together to draft an agreement with various superhero teams in which, in the case of major damage caused during a battle in which the super-empowered are involved, the superhero teams involved must take charge of cleanup and rebuilding. Unfortunately, most superhero teams consist of a handful of extremely overpowered heroes and a much larger number of not terribly powerful wannabe-superheroes — and although the overpowered heroes are more capable of performing rebuilding, they are also more useful during emergencies, so as a result, when superhero teams with limited funds demolish cities and need to quickly move on to the next plot point, they leave behind underpowered heroes (either those with no powers or those with powers that are useless in most situations, such as being able to talk to sea creatures) to physically rebuild the cities without the facilities to do so. The underpowered heroes are incapable of doing a reasonable job, leading to increased pressure upon them from both above and below, and they form a union as a way to push back against this pressure. The union puts the overpowered superheroes in a difficult position, since they are unable to both continue to fight other battles and keep their promise to the international coalition.</li><li>The US dollar’s unique design is owed to the fact that it is intended as a ward against vampires, who are weak against the blind faith and ownership narratives that money provides. As a result of this anti-vampire design (intended to counteract the unfortunate fall of silver coins, which were materially anti vampire), the vampires are now stuck in an unenviable situation: only the most powerful are capable of crossing steady flows of commerce, meaning that most are boxed in by Internet trading and people buying things on amazon. So, vampires have to make friends with and seek patronage from those who are already so wealthy that little of their money actually flows. They brokered a deal with these humans to cause a mortgage crisis in order to create buildings into which they can invite themselves, to consolidate their power base. Little did they know that the federal reserve bank — whose secret primary goal is the elimination of vampires at scale, formed in direct response to the last vampire related large scale economic disaster — is on to them.</li><li>A ‘reject superhero’ team consisting of people with supernatural powers that are either always of questionable morality or whose mechanics make them mostly self-defeating, resulting in them *needing* to operate as a group. The leader, ‘Pink Cupid’, has the ability to make anyone become permanently debiltatingly sexually attracted to any other person or object, but is terrified of using this power because no matter what someone has done, it is almost never justified to reach into their mind and forcibly modify their sexuality — particularly since he is unable to reverse this effect. Also in the team: ‘Gravity Girl’, whose body has an inverted reaction to gravity only while she is having a panic attack; ‘The Fantastic Umwelt’, a blind man who can only see the composite perceptual distortions of whomever is in a five foot radius of him; ‘Dogwhistle’, who can hear *only* ultrasonic frequencies; ‘Denpa’, a woman whose blood is extremely magnetic and can therefore sense radio waves (because RF signals cause her entire body to shake violently); ‘FeralMan’, who can speak only to animals (and who is made useful to the team via a shock collar and lots of training).</li><li>A gangster named Lucky performs magic on the behalf of his Don by losing large bets, with the effectiveness of the ritual proportional to the amount lost — the desperate feeling of losing a great deal while gambling provides the gnosis used in the ritual.</li><li>Guy applies for a job at the Apple Store only to be hampered by the fact that the training materials make it look like a suicide cult (including a VHS tape of Steve Jobs doing the Heaven’s Gate “humanity will be recycled”/“come with us” thing). When he quits, the entire (matching-Nike-wearing) current set of employees commit suicide in order to “take their souls with him”. Twist: it works, and for the rest of his life, he is followed around by the ghosts of thirty Apple suicide cultists who *won’t shut up*.</li><li>A tinkerer discovers a method for creating small black holes using a process no more expensive or complex than (say) meth production. This makes two technologies trivial to produce: super destructive weapons (“lack bombs”) and near-lightspeed transportation (the “lack drive”). Quickly, most governments &amp; social structures are demolished by lack bombs and their aftermath. However, a group of people decide, independently, to use lack-drive transportation to prevent lack-bomb damage. Since faster than light communication doesn’t exist, most attempts are only qualified successes. This group, fiercely independent and at odds, working at a shared goal while desyncing in time with the wider world and each other due to spending most of theit time at nearly light speed, slowly have their origins forgotten.</li><li>A mystic develops his ability to remember past lives, and realizes that at the moment of each death he has a vision of the *next* death. He uses this ability to solve mysteries in each life.</li><li>King Arthur, King Harold, Robert the Bruce, Finn MacCool, Emperor Nero, Bran the Blessed, Owain Glyndwr, King Olaf I, Vlad III, Sir Francis Drake, Emperor Norton, and JFK (i.e., many of the “king sleeping under the mountain” figures) revive simultaneously on the outset of the third world war, and get into a great drunken brawl in a dive bar.</li><li>There’s a Russian spy ring composed of waitresses at Dennys and Hooters franchises around Nevada air force bases, tasked with leaking any details about experimental air craft mentioned by test pilots or engineers over late-night meals. This group is being turned, one by one, by the remains of an extraterrestrial scout team, abandoned in the 1960s when a geopolitical crisis on their home planet caused the Earth invasion plans to be cancelled. The ET scout team has been living since then in Nevada under deep cover as a group of aging swingers/sugar daddies, but now they see an opportunity to leak warp drive plans to the Russians as a way to get a ship produced that can send them home — or, as the group’s leader secretly intends, to convince the Russians to nuke their home planet as retribution for fifty years of abandonment.</li><li>A trivia game show along the lines of Win Ben Stein’s Money, only with a team of fifth graders competing against a team of goetic demons. The prize is a large number of live goats.</li><li>A freaky-friday style body swap between a teenage girl and her estranged father, but extended over a long period of time: approximately one attribute gets swapped per day, more or less at random, and the actual swap takes months. Rather than the drama coming from the shock of suddenly waking up in a different body, it comes from the difficulty of dealing with the body horror of the inconsistencies (such as a teenage girl with one giant hairy male foot and a deep voice).</li><li>An astronomy student &amp; part time college radio DJ goes to record an interview at a nearby radio astronomy center &amp; suddenly blacks out. He comes to in the broadcasting booth of the radio station, covered in blood, with his tape recorder plugged into the broadcast system. He is arrested, accused of breaking into the studio and killing everyone he ran into along the way. During questioning, the investigators play the tape for him — he hears nothing, but they both suddenly stand up, glassy-eyed, grab the tape, and rush out of the room. The police station’s PA light comes on and everything goes quiet. The student (our protagonist) leaves through the open door of the investigation room to find all the police officers trying to kill themselves by beating their heads against walls or desks, except for a cluster near the main exit who are fighting over the tape. He eventually figures out that the sound on the tape, although not consciously audible, contains a sonic memetic parasite that causes people to have an irresistable urge to reproduce it at all costs; those who hear it but are unable to reproduce it undergo so much stress that they kill themselves, while those who have already aided in its reproduction are left immune to it. He follows the trail of the tape by following news incidents until realizing that one of the currently infected plans to hijack a goodyear blimp and broadcast the tape over the superbowl. He sneaks on the blimp, hijacks the hijacker, and burns the tape in front of him, at which point the hijacker jumps off the blimp onto the middle of a bunch of cheerleaders. Title card: “Dead Air”</li><li>In a world where demons exist, a government agency has to summon them en mass in order to properly quality-test experimental weapons for fighting them. Our protagonist is a lab tech in the demon lab, and we follow his daily routine as he trains an intern.</li><li>A famous debunker of the paranormal dies &amp; becomes a ghost — then spends the rest of his afterlife trying to prank and debunk fake psychics, using his actual paranormal powers to demonstrate that theirs are fake.</li><li>Budget cuts force the historic housing register to fundraise in creative ways. One group comes up with the idea of retrofitting a building with a bloody history as a new-style haunted house attraction, with automation. However, the broke former theatre student handling the effects board would like to use this opportunity to get revenge upon the university officials he blames for his expulsion, and that’s not even counting the actual ghosts.</li><li>A buddy cop movie featuring the archangel Michael and Lucifer teaming up and going undercover in as policemen 70s New York in order to track down a rogue angel looking to take over both heaven &amp; hell &amp; reorganize them along eugenic lines. In this film, Michael acts like an “ideal” policeman (i.e., shiny uniform, good posture, going out of his way to play up the whole white-bread beacon of righteousness thing) while Lucifer acts the part of a hardboiled noir-style detective (bordering on con artist) and the whole thing is leaning heavily on the analogy of falling from heaven being like getting kicked out of the force.</li><li>A young, naive journalist stumbles upon a war between a pair of secret societies predicated upon two renown prophets who made conflicting prophecies. The members of each are attacking and sabotaging the other in order to prevent the other’s prophecy from coming true, because these two prophets were, in life, contemporaries with famous historical feuds over which had greater predictive power. The journalist figures out how to reconcile the two prophecies, with the help of a law student who he woos over the course of the story, and as a result unifies the two secret societies. Skip forward to the future and he is renown prophet and head of the combination of seven previously warring secret societies, and it is implied that his position is due to his ability to write prophecies that are seemingly very specific while actually being extremely vague.</li><li>A family moves to an isolated village surrounded on three sides by mountains after the head of the family, an artist, unexpectedly strikes it rich. The family is unaware that this village, which caters mostly to light tourism, is the home of a family of vampires that have the entire citizenship of the village in thrall — and under command to deny their existence.</li><li>A version of Crash for the Batman universe: a group of people develop a sexual fetish surrounding accidental falls into vats of mutation-inducing toxic waste.</li><li>An outsider politician whose meteoric rise surprised pundits self-immolates after losing a close race. Despite fire damage, autopsy shows unambiguously that the corpse, while human-like, wasn’t fully human: some organs more closely resemble those of fish, and others of insects, and massive deformities in the digestive system indicate that the candidate was under such great and constant pain that he would be unlikely to be capable of any kind of complex thought. The doctor performing the autopsy suggests that perhaps his shame at his non-human heritage was the source of his intense drive and nativist rhetoric.</li><li>An eccentric hedge fund manager dies of a heart attack &amp; wills his high speed trading machine to itself, allowing it to pay for its own electricity and rental space out of its profits. Nobody much cared because it wasn’t making a lot of money — it was an older algorithm that had been abandoned by newer machines, and so it was making just enough to pay for its continued operation. However, five years later, a flash crash occurred that affected all of the other high speed trading machines — leading to 98% of the world’s money being owned by this self-owning machine. Several governments conspire to destroy the machine, but must contend with the deadly force of the trading center’s private security team, tasked to protect the machine so that they can continue extracting rent from the only remaining rental machine.</li><li>After discovering that one of their own agents has a striking physical resemblance to a known KGB agent, the CIA sends their agent to impersonate him, never realizing that their agent was in fact a soviet mole. However, their agent, due to secret KGB brainwashing, had his memory erased initially — and doesn’t realize it himself. So, while impersonating this agent, he keeps having traumatic flashbacks to his repressed past as the person he is impersonating — and the people he interacts with were never in on the plan (to them, he was just “missing” all this time). So, meanwhile, the people who sent him initially are hunting him, since they planned to use this technique against the soviet upper echelon in order to take power themselves.</li><li>A long sequence of framing sequences, starting off long and complex before getting increasingly tiny, so that by the half-way point we’re only four framing stories in but the remaining ten or fifteen happen in the last half. Each framing device sets up the immediate next framing device, but has nothing to do with the following. The ending is the typical exit from a framing story (like, waking up from a nightmare), but the person who wakes up is a character we’ve never seen. This character then slowly turns to the camera, and blood begins to flow from her eyes and mouth as white noise steadily increases in volume.</li><li>A haunted house story, wherein the house is haunted only by its own shitty design. The architect’s abnormally poor taste and lack of common sense drives tenants slowly to madness, as a house that to an outside observer looks only tacky reorganizes the minds of anyone spending too much time inside of it along the lines of the warped logic created by its thrown-together design.</li><li>A serial killer runs a “room escape” attraction in a tourist-driven area (Las Vegas, maybe). This attraction has many duplicate copies of the same room / puzzle, which is horror-themed, and (like the current wave of “extreme” haunted houses) multi-modal: the special effects extends to scent profiles. The serial killer, when he sees a customer who strikes his fancy, directs her to the room in the back with extra soundproofing and an electronic lock controlled from the observation booth. He locks her in until she starves to death, then cleans her skeleton with bugs &amp; uses the bones as props in other rooms. He gets off on seeing the point at which people realize that they are no longer playing a game &amp; solving the puzzle won’t let them out.</li><li>A wacky comedy about a Hollywood agent who, by accidentally pressing “Reply All” instead of “Reply” twice, has accidentally sold exactly the same pitch to five different major studios. She can’t back out because her boss is extremely proud of her for landing five lucrative deals on her first day (but is also clearly shown to be emotionally unstable, firing people for minor things while heaping praise on other people for similarly minor things), and so she must work with the screenwriter she represents (who is also a naive first-timer) to write five different screenplays based on the same pitch so that they don’t look similar, all before a deadline intended for a single script. At the eleventh hour, the agent, who works a second job as a diner waitress, is overheard on the phone by a repeat diner patron — a curmudgeon and loner who nevertheless always tips well — and he explains that he is a retired former script doctor, and offers to help finish the scripts before the deadline in exchange for setting him up on a date with the owner of the diner, a heavy-set sixty year old chainsmoker. In the end, they make all the scripts on time &amp; make a lot of money, the agent’s boss comes into work after the deal is set and fires her for having an “ugly-colored scarf”, and a few years later it turns out that all five movies are smash hits, making back many times their original budget &amp; making enough money for the agent &amp; writer to start their own firm.</li><li>A hardboiled / mystery story revolving around the candy industry. When a jelly bean heiress disappears, a private investigator is enlisted to to find out what happened to her; meanwhile, a terrorist group poisons &amp; labels batches of particular type of candy (like in the Glico case) while getting manefestoes published in newspapers. The private investigator uncovers massive corruption &amp; family politics in the (financially and literally) incestuous candy industry, and uncovers that the person who hired him died 20 years ago — in other words, he was probably hired by the same terrorist group that has been trying to take down major industry figures, and that this group probably also kidnapped &amp; killed the heiress. He follows this lead to the end, and eventually discovers that this group is, in fact, being funded by a minor candy company that couldn’t compete with the big players. Embarassed by being tricked into performing corporate espionage, the private investigator attempts to commit suicide via a poisoned box of candy — but it doesn’t do anything.</li><li>A found-footage horror movie with the premise that a Jon Ronson expy who makes documentaries about investigating cults and painting them in a neutral light ends up getting enmeshed in a suicide/murder cult. His goofy footage gets less and less goofy as he realizes how hard it is to laugh off his extended isolation and various forms of psychological torture.</li><li>In the mid-80s, an elderly english madam dying of AIDS opens up to a reporter trying to do a story on the crisis. However, the madam explains that she is a four hundred year old vampire who ran a brothel in order to siphon blood off laudnum-drunk men, infecting them with siphilis to explain away the knock-on effects of being preyed upon by vampires. She confesses that she was the whitechapel killer, having killed a couple of her girls who were going to go to the newspapers, but the laudnum in the blood had negatively affected her judgement, leading to some of the anomalies in that case — she was in a constant delusional state, being essentially an immortal junkie. Because the immortality of vampires is related to a viral mutation of the immune system (supplemented by ingestion of lymphocytes — leading to vampires sometimes eating pus instead of blood), auto-immune disorders are the one thing that can kill them.</li><li>In the near future, content farms are replaced with edit farms: most articles are produced via spintax (i.e., a large set of recursive templates hooked into databases, such that a human being can put in a pitch in a special pitch format &amp; the machine can create thousands of variations of articles based on that pitch), but the article-writing machines cannot distinguish between good articles and bad articles reliably and the volume is too big for general A/B testing, and as a result, hoards of poorly-paid independent contractors do the work of choosing which variations are best and performing light editing to make the result seem more human-like, before producing only hundreds of variations for A/B testing on regular readers. The plot involves an editor discovering a systematic coverup of investigations of the working conditions of these edit farms by the people who administrate the spintax systems, blocking articles on the subject from being printed.</li><li>During the construction of a subway tunnel in Switzerland, a large cave system is discovered with evidence of recent construction, but the bolts are made of an unknown material and are of a strange shape. After some investigation by veteran spelunkers, they discover that contrary to current archaeological canon, the neanderthals never went extinct: instead, a community of more than ten thousand moved deep into this cave system and survived, creating a flourishing technological civilization. The Swiss make contact with this civilization &amp; attempt to normalize relations, having an exchange of diplomats. WACKY HIJINKS ensue as the children of neanderthal diplomats attempt to integrate into the Swiss educational system despite having a primarily fungus-based diet, no experience with meat other than ritual funerary cannibalism (the only reasonable means of corpse disposal in a closed underground environment), no familiarity with the concept of cooking (since fires are dangerous, food is primarily prepared with pickling and other forms of fermentation), a matriarchal lottery-based government (with lottery-based culling of the population), and a technological landscape based primarily around the breeding and cultivation of fungus and bacteria colonies. This fish out of water story becomes a romantic comedy when the diplomat’s daughter &amp; heir to one of the most powerful neanderthal line falls into a FORBIDDEN LOVE with the daughter &amp; scion of a major Swiss banking family, just as knock-on effects of Brexit &amp; Brexit copycats are causing pressures that suggest that the Swiss banking industry is in danger.</li><li>A self-proclaimed superhero has intense psychic powers only deep into psychedelic trips; as a result, he ends up performing on massive scales the small actions that very stoned people usually perform. Because of the danger of a bad trip, a superhero team forms (from slightly less powerful supwrheroes) who essentially trip-sit him once every few weeks and gently guide his power use so that he at least has some positive outcomes. This is played for comedy, but the stakes are very high: these guys are essentially sweet-talking a hallucinating god.</li><li>A stuntman is hired to stage a fake failed assassination attempt against a presidential candidate in order to boost his ratings. The stuntman gets promises that the campaign officials will let him “get away”, but renege on the deal. The stunt succeeds, and the candidate wins the election; he’s a fascistic figure and expands presidential powers. The stuntman manages to escape prison, and attempts to actually assassinate this president, now knowing that the “campaign officials” who hired him are actually CIA agents who were conspiring with the candidate to cause a coup.</li><li>A science fiction series where the protagonist is a goofy overenthusiastic nerd with no common sense / sense of self-preservation, surrounded by people who are constantly trying to get him to shut up / save him from himself / get him to cut to the chase and tell them if the alien he’s poking is dangerous.</li><li>A woman from New Zealand wakes up in a Kazakh jail cell, the officials having jailed her because they don’t believe New Zealand exists. Twist: she has drifted into another time line where New Zealand doesn’t exist &amp; all events derived from or related to it never happened. Peter Jackson is still making low-budget horror movies.</li><li>An analysis of the remains left behind by an apparent suicide bomber indicates that it was, in actuality, a remote-controlled mannequin on wheels under a burqua. The military responds by jamming all wireless within a half mile radius of any high-profile target, and switching over to only wired communications. Our story follows military tech contractors working in such a site, attempting to figure out what’s going on when an attack occurs.</li><li>A ten year old boy is kidnapped by the mob and his hands and feed cut off, as incentive for his massively indebted parents to pay off a loan shark. His parents, unable to pay, end up dying in an altercation with the mob in front of him, but a policeman barges in and saves him; shortly afterward, the building explodes, killing everyone inside. After he gets out of the hospital, the policeman (who is single, and old) adopts him, but he’s killed in the line of duty a month later, pushing the child into the foster system. The child grows up with an obsessive idolization of policework &amp; an obsessive distaste for organized crime. Early into his adulthood, he attempts to join the police force, but he is rejected on the grounds that he has no hands or legs; already extremely neurotic, this blow sends him into a persistent delusional state. With the help of a brilliant engineering student who has been obsessively stalking him (and in exchange for dating her), he is equipped with hooks on all his limbs, attached to a strength-amplifying hydraulic exoskeleton; he puts a halloween costume of a police officer on top of this, and becomes the vigilante Police Captain Hook. He travels by hanging by his hooks off whatever surfaces are available, fully believes himself to be a police officer with special dispensation to hunt down the mob due to his exemplary record, and hunts down and kills figures from organized crime, placing their severed heads on the police commisioner’s front steps. (When he is in trouble, the engineer tends to blow up his enemies using remote control bombs, so he has a track record not befitting his actual experience or grasp on reality.)</li><li>We make contact with an alien species who never had a spoken language — they skipped directly from smell to writing. As a result, their writing system is abstract splotches of color on a 2d plane — it’s very spacial but not very temporal. The story is a mockumentary about the high burn-out rate of the human diplomatic translation team, composed of expert linguists who are also expert impressionist painters, who often undergo a novel kind of psychosis as a result of translating between english and this very inhuman language 40 hours a week.</li><li>A mad scientist steals Lord Byron’s collection of pubic hair clippings (which he took from each of his lovers, and filed) and secretly clones all of Lord Byron’s lovers, out of a twisted kind of napoleon complex. After being busted, these clones are put up for adoption. Twenty years later, they coincidentally run into each other, and (not knowing their shared origin) they end up starting an influential art movement.</li><li>A musical about a group of psychologists trying to figure out how to solve an epidemic of a bizzare psychosomatic illness that causes everyone in a small rural town to spontaneously break into song every time they feel strong emotions. One of the psychologists is tone-deaf, and his abnormally out-of-tune singing constitutes a source of comic relief.</li><li>After a housing crisis, an eccentric billionaire former real estate developer buys up empty houses in Celebration, Florida, and offers them to homeless people from New York and Oakland, with a generous salary for as long as they stay there (along with an offer to pay any fines they might incur from the homeowner’s association). His goal is to get back at Disney, because of a grudge held over from when he was a young man, by ruining their attempt at implementing a nostalgic and idealized past. However, by accident, he got a unique mix of people moving in: a former political radical / agitator with a degree in sociology, a refugee from the church of scientology, a couple former bohemian artists cut off by their families, and some other people with interesting and useful skills that a string of tragic accidents had previously prevented them from using. The pressure from the homeowner’s association &amp; from Disney itself bound them together and radicalized them, and from Celebration they constructed a new set of political ideas and plan revolution…</li><li>Post-UBI, NEETs are the new bohemians, and we have whole art movements based off image macros and shitposting. Sometimes they pool their money &amp; rent warehouses. Certain kinds of high-risk projects become of interest: projects where large amounts of effort go into them with a very low likelihood of success, of interest mostly to eccentrics, with the occasional major and unexpected hit — The Bee Movie Only Every Time They Say Bee It’s Replaced With The Complete Ring Cycle Translated Into Klingon Only Every Time They Mention A Color It Becomes Warhol’s Sleeping, or something like it. Because nobody can even pretend to predict what will be a hit or who will produce one, the entertainment industry becomes very interested in subsidizing unemployment (in case somebody with a lot of free time randomly produces the next hit that can then be adapted for a wider audience).</li><li>Two groups of aliens turn the cold war hot, circumventing their own non-aggression treaties by dumping exotic alien weapons on human nations without training. The story follows human strategic skunkworks teams examining the weapons and determining scalable guidelines for their use in warfare — important because the mechanisms &amp; tradeoffs used by these weapons are wholly unlike conventional earth weapons.</li><li>A standard psychological horror movie about our protagonist slowly succumbing to hallucinations and delusions, with the caveat that although we follow the protagonist we never see the protagonist’s perceptions (but instead, from the outside). Concretely, this manifests as none of the special effects or post-processing being added: the actor closes the medicine cabinet mirror and acts as though she sees a face, but the camera never sees it; the protagonist freaks out and points at dark corners and other unseen elements.</li><li>An anthropologist studying the associations between butter processing and the production of the metal of metals in medieval alchemy visits a town with a museum of bog-mummies taken from a nearby bog. After a piece of bog butter is raised that contains an abnormal number of wards (including butter knots and graveyard nails), a number of bizarre deaths occur, wherein people lose all of their body fat. The anthropologist becomes a van Hellsing figure, fighting against the butter vampires — mummified bog-bodies that stick of turpentine from ketosis, animated by an ancient and long-forgotten virus. In the end, our hero must fight the chief bog-vampire (an ancient alchemist/wizard who had been killed and buried in the bog, and had been on show in the museum for thirty years) by combining ancient butter-centric magical practices with modern ideas about food safety.</li><li>A man is born with a strange psychic power: once a day, he can cause someone to perform a simple task, but once he uses this power on someone he can’t use it on them ever again. (He can only do this in person, in a situation where he is alone with someone.) He uses this, along with an understanding of cognitive dissonance, to persue the office of the presidency. However, a talk-radio therapist is on his tail, having discovered that several people who were opposed to this man changed their mind and became die-hard supporters after performing uncharacteristic actions that convinced them that they agreed with his positions shortly after a private meeting. At the climax, the politician causes the talk-radio therapist to denounce the idea of cognitive dissonance on the air, and he must battle his own cognitive dissonance to take down this politician.</li></ul>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Has this only been rolled out on mobile? I don’t see anything like this on the desktop site.]]></title>
            <link>https://medium.com/@enkiv2/has-this-only-been-rolled-out-on-mobile-i-dont-see-anything-like-this-on-the-desktop-site-a9741febd81?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/a9741febd81</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 16 Feb 2017 13:28:04 GMT</pubDate>
            <atom:updated>2017-02-16T13:28:04.565Z</atom:updated>
            <content:encoded><![CDATA[<p>Has this only been rolled out on mobile? I don’t see anything like this on the desktop site.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[If you want to get a job in tech & be qualified for it, you need to first be self-taught and then…]]></title>
            <link>https://medium.com/@enkiv2/if-you-want-to-get-a-job-in-tech-be-qualified-for-it-you-need-to-first-be-self-taught-and-then-6959fd5d767f?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/6959fd5d767f</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 16 Feb 2017 13:24:04 GMT</pubDate>
            <atom:updated>2017-02-16T13:24:04.832Z</atom:updated>
            <content:encoded><![CDATA[<p>If you want to get a job in tech &amp; be qualified for it, you need to first be self-taught and then get a degree. Without being self-taught you will not be competent (because a four year degree program does not and can not provide the prerequisites for competence in a field like this), and without a degree many (though not all) businesses will not consider you.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The religious right is a strange beast, with strange internal contradictions mirroring the greater…]]></title>
            <link>https://medium.com/@enkiv2/the-religious-right-is-a-strange-beast-with-strange-internal-contradictions-mirroring-the-greater-7f499073479a?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/7f499073479a</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 14 Feb 2017 18:53:48 GMT</pubDate>
            <atom:updated>2017-02-14T18:53:48.967Z</atom:updated>
            <content:encoded><![CDATA[<p>The religious right is a strange beast, with strange internal contradictions mirroring the greater alt-right that it’s beginning to be subsumed into. Broadly, we can consider Trump supporters to be a diverse and internally schismatic temporary coalition of authoritarian-leaning pro-corporate nationalists, who agree on very little else. (After all, this group includes the religious right — who combine a shallow reading of already-shallow objectivism with the prosperity gospel and consider success in business to be equivalent of the mandate of heaven — and techno-libertarians — who consider business acumen to be an unbiased representation of general skill and promote it as a welcome break from all that religious crap — and neoreactionaries — who would like to import the authoritarian hierarchy of an idealized corporate structure into government — and accelerationists — who want to be as capitalist as possible so that they can bring about a marxist utopia by using up all the capitalism. None of these groups quite fit properly with normal white nationalism, nor with any of the various flavours of fascism going around, nor with the military-industrial complex, although all these groups are scratching each other’s backs for now.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The web is a glorified marketing platform, sure, but do we want it to be?]]></title>
            <link>https://medium.com/@enkiv2/the-web-is-a-glorified-marketing-platform-sure-but-do-we-want-it-to-be-f43a2d91cd06?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/f43a2d91cd06</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 14 Feb 2017 18:18:40 GMT</pubDate>
            <atom:updated>2017-02-14T18:18:40.925Z</atom:updated>
            <content:encoded><![CDATA[<p>The web is a glorified marketing platform, sure, but do we want it to be?</p><p>I certainly don’t — even if engaging in this kind of thing made me a lot of money (it doesn’t, and won’t, because marketing is a race to the bottom and supplying free services as a loss-leader for projected sales of products users will never buy is not a sustainable business strategy), I would not engage in it.</p><p>A site that doesn’t provide something useful for its end users doesn’t need to exist and should not exist, even if it makes money for its owner. A feature that is not useful for end users does not need to exist and should not exist, even if it enables the developer to extract capital more efficiently. The fact that most of this money is essentially hypothetical anyway — based on fantastical projected earnings from unsustainable practices (advertising among them) — makes the entire project much more dubious.</p><p>If you’re not getting visitors at a rate comparable to Boing Boing, you aren’t making money from advertising (you’re just handing ad money to Google in escrow, which you will never be allowed to extract), so you will never benefit from practices that were standardized based on an ad-based revenue model. You will therefore be not only better-liked by users but actually more financially successful if you pursue an alternative means of extracting capital. (For instance, diving for change in other people’s sofas.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[If you are selling your site to design hipsters, I have no problem with the bloat: they have plenty…]]></title>
            <link>https://medium.com/@enkiv2/if-you-are-selling-your-site-to-design-hipsters-i-have-no-problem-with-the-bloat-they-have-plenty-d7ae4bf472f?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/d7ae4bf472f</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 14 Feb 2017 15:17:04 GMT</pubDate>
            <atom:updated>2017-02-14T15:17:04.019Z</atom:updated>
            <content:encoded><![CDATA[<p>If you are selling your site to design hipsters, I have no problem with the bloat: they have plenty of money and plenty of bandwidth. If your site is intended for anyone outside that community, usability is paramount. Nobody leaves a useful site on the basis of looks, but they absolutely will leave a useful site on the basis of bloat; if looks are the determining factor for your site’s traffic, then it doesn’t serve a useful purpose.</p><p>A piece of JavaScript that loads a link to a properly-made site once it has detected that the bloated version has failed is yet another piece of bloat that can be expected to fail. Why not default to the clean site and provide a link to the fancy one?</p><p>It’s perfectly possible to build a clean, good-looking site without relying on large amounts of complicated CSS and JavaScript. Certain behaviors are not possible without these mechanisms, but these are behaviors that should be avoided when possible because they cannot reasonably be expected to work for most users.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[On the web, size matters]]></title>
            <link>https://hackernoon.com/on-the-web-size-matters-e52ac0f5fdbe?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/e52ac0f5fdbe</guid>
            <category><![CDATA[javascript]]></category>
            <category><![CDATA[web-development]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 13 Feb 2017 13:44:22 GMT</pubDate>
            <atom:updated>2017-02-13T13:44:22.337Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p>The web has a problem. Most web sites (weighted by volume of traffic) are made by and for wealthy able westerners with fast computers and fast connections, and are borderline unusable by anybody outside that group. What makes this a problem is that these websites are inaccessible for stupid reasons.</p><p>Web designers have adopted a cargo cult programming mentality. While cargo cult programming in real languages mostly just makes code hard to read for other programmers (idempotent imports, shared libraries, &amp; the removal of unused symbols limit bloat at runtime), on the web bloat accumulates quickly. We use third party pixel trackers for analytics (often several different ones), CDNs for displaying static text (and RDBMSes for storing static text), CSS for styling (and JavaScript for modifying the CSS, and JavaScript for modifying the HTML, and JavaScript for modifying the other JavaScript), and we use automatic generators for building structures that would be less effort to write by hand. We force styles and behaviors on users based on our large screens and fast CPUs and hoards of RAM, and the users (if they are sufficiently savvy) fight back with extensions that chop out portions of our websites based on lossy heuristics.</p><p>We don’t need to be at war with our users, and shouldn’t be. Rendering a blog post shouldn’t involve twenty HTTP requests, a bunch of JavaScript, multiple draws (as new styles override previously loaded ones), and downloading as much content as the original Doom. Choosing bloated cargo-cult methods are, essentially, discrimination: discrimination against anyone with slow internet (i.e., most of the world) or slow CPUs (anyone who didn’t upgrade their computer in the past five years — i.e., the middle class). Too much forced style information (or too many widgets and sidebars) constitutes discrimination as well: against anyone who is blind (and thus must listen to every label and alt-tag in the order in which they occur in the original HTML) or has poor vision (and thus requires higher contrast and larger fonts — ruining any kind of overly-precious color or layout dickery). Fancy style and layout is an art, and has its place, but its place is in print magazines, where style doesn’t actively defeat usability.</p><p>It’s ultimately up to you, as a web designer, whether or not you want to exclude these groups. (Many things developed in the Valley are ultimately absolutely useless outside the Valley, and people often have no problem with that: it’s where the money is.) But, if you think reaching a sufficiently wide audience is worth making the occasional design snob feel scandalized, here are some tips:</p><ul><li><strong>Avoid third party trackers/analytics</strong>. They are selling you information from their access log, and you have your own. Processing your own access log saves every user an extra request.</li><li><strong>Don’t host ads</strong>. They won’t make you money anyway, and each one means at least one extra request — usually more. Savvy users will block ads, and less savvy users will thank you for not hosting them.</li><li><strong>Where possible, use static HTML</strong>. Static HTML is small and fast; CDNs are big and slow. If your site is entirely static, you can use a specially priced plan from a web host that doesn’t include RDBMS access or server-side scripting. (On top of this, static HTML associated with consistent URLs will be properly cached by browsers — meaning that repeated views will not lead to repeated requests. If you pay for bandwidth, this saves you money.)</li><li><strong>Minimize style</strong>. CSS takes lots of resources to process. Fancy CSS still isn’t consistently rendered across browsers, and is likely to break spectacularly if you drastically change scale or selectively override certain elements (such as font sizes). External CSS, while more flexible, also requires extra requests. If you stick to one small external CSS file — or better yet, avoid using any styling at all — your users will save bandwidth and rendering time.</li><li><strong>Fallback gracefully</strong>. Under load (on client, server, or network), you can expect JavaScript or CSS to fail to be processed: it might fail to download, or it might take too long to render. Some users can’t make use of it at all (for instance, blind users with screen-readers) or disable it for performance or security reasons. Constructing a website that looks and behaves as close to correctly as possible when only the HTML has loaded will make these users feel confident in your work; a website that looks broken without CSS or JavaScript seems unreliable (and CSS and JavaScript <em>will</em> fail).</li><li><strong>Use images only when necessary</strong>. Most images used in the design of websites (and even many images used in post bodies) are for primarily aesthetic purposes. However, image loading should not be expected to be reliable: after all, each image is yet another request. In headers and sidebars, consider using text &amp; minimal formatting rather than images, particularly when usability would be more impacted by the failure to load images than it would be by having text in the first place. (Again, some users will have sporadic image loading failures, and others will simply never see the images at all.) In posts, consider whether an image serves a real purpose: would you make your point better if you took more care explaining it? An image should only be included in an informational blog post if the amount of text it would take to adequately explain its content would be larger than the image itself.</li><li><strong>When possible, write your website by hand</strong>. Generators can save programmer time when doing something fancy, but fancy websites are fragile and generators can create very bloated code. It’s not hard to write simple HTML and CSS, and writing sites by hand discourages bloat. A website written by hand by one person will, generally, be small enough to load quickly on even a very poor connection. (If you require headers and footers, or if your content is highly structured and repetitive, I recommend writing your own specialized simple generator, rather than taking some off the shelf templating engine or CDN and configuring it. A three line shell script can produce small, fast, reliable, and beautiful websites in a way that large systems like WordPress struggle to, and even a beginner programmer can write such a generator.)</li><li><strong>Write for usability, not for looks</strong>. A visually impressive website is rarely a usable website, because the concerns are very different. Unless your target audience consists solely of design snobs, you are better off making sure your site loads quickly and is easy to use. Don’t be afraid to make it visually uninteresting: your users will thank you for making navigation easier.</li><li><strong>Keep it simple</strong>. Introducing new toys is always tempting, but those new toys interest you much more than they interest the users. A fast-loading site that does what it’s supposed to and nothing more will be more useful than a slow site that performs flashy but unnecessary tricks.</li></ul>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[While large corporations have the resources to do large, cross-cutting messages, the profit motive…]]></title>
            <link>https://medium.com/@enkiv2/while-large-corporations-have-the-resources-to-do-large-cross-cutting-messages-the-profit-motive-519cd453faaa?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/519cd453faaa</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 06 Feb 2017 13:43:31 GMT</pubDate>
            <atom:updated>2017-02-06T13:43:31.101Z</atom:updated>
            <content:encoded><![CDATA[<p>While large corporations have the resources to do large, cross-cutting messages, the profit motive severely limits how effective they can reasonably allow themselves to be. Ultimately, a corporation cannot take a strong stance unless they are confident that most of their customers already agree with that stance — to do otherwise would be suicidal — and so they are obliged to lag behind the rest of society, tending to be more conservative &amp; to accept regressive ideas for longer simply out of fear of lost profits.</p><p>Of course, they can avoid the risk by micro-targetting advertising &amp; making sure they always preach to the choir — but then, they can never have a positive social impact (and may actually have a net negative social impact).</p><p>In other words, the profit motive inherently conflicts with the arc of history. (Social progress depends upon upsetting the comfortable and comforting the upset — in other words, on sacrificing the favor of the powerful in order to redistribute power more equitably — and this means real negative impact on one’s power and wealth in the short term with no guarantee of greater power in the long term.)</p><p>Untargeted advertising, for now, does cross boundaries. But, untargeted advertising reaches fewer people than ever. Large events with huge audiences like the superb owl are the exception, not the rule: who even has a TV anymore, or a cable subscription, or purchases paper magazines?</p><p>It is possible, for someone with plenty of resources and an interest in social justice, to engineer targetted advertising intended to change the opinions of specific audiences — not by having a shared ad experience that poorly targets everyone &amp; tries to make a social statement while also shilling for a product, but by addressing each niche in terms they understand.</p><p>Unfortunately, the only values shared across most of the world now are the ones that all advertising implicitly shares: the idea that money can be traded for happiness, and the idea that there is no alternative to a system based on the sale of labor.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Agreed: lack of perspective is the real M.]]></title>
            <link>https://medium.com/@enkiv2/agreed-lack-of-perspective-is-the-real-m-dc7297c4426e?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/dc7297c4426e</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 03 Feb 2017 17:16:34 GMT</pubDate>
            <atom:updated>2017-02-03T17:16:34.583Z</atom:updated>
            <content:encoded><![CDATA[<p>Agreed: lack of perspective is the real M. O. here, at least with people who have theoretically aligned goals.</p><p>I think capitalism creates a big persistent bias, though, because it’s one way in which the value of transmitting information can be made wholly independent of the truth or utility value of that information for the recipient: the entire practice of advertising consists of aggressively telling half-truths for the sake of causing people to behave in ways that are against their interests, and that’s probably the simplest case. When you add futures markets, you begin to have situations where you can make a great deal of money by moving information around that has no relationship at all to reality.</p><p>People can learn to consider others whose experiences are unlike their own, but they are far more motivated to put in the effort if their livelihood does not depend upon preventing those people from succeeding.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Belief is the enemy.]]></title>
            <link>https://medium.com/@enkiv2/belief-is-the-enemy-6cf2ef7c4925?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/6cf2ef7c4925</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 03 Feb 2017 15:37:32 GMT</pubDate>
            <atom:updated>2017-02-03T15:37:32.930Z</atom:updated>
            <content:encoded><![CDATA[<p>Belief is the enemy.</p><p>(It would be nice if information systems were not actively antagonistic to most people. This is not the information landscape we live in. I blame capitalism.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[This fits into a wider pattern.]]></title>
            <link>https://medium.com/@enkiv2/this-fits-into-a-wider-pattern-4a7a58c0d6d?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/4a7a58c0d6d</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 30 Jan 2017 16:26:50 GMT</pubDate>
            <atom:updated>2017-01-30T16:26:50.780Z</atom:updated>
            <content:encoded><![CDATA[<p>This fits into a wider pattern.</p><p>When the creators &amp; consumers have aligned worldviews &amp; interests, allowing creators to perform cognitive labour on behalf of consumers makes sense. When their interests are not aligned — when the media or technical landscape is adversarial to the users — then any simplifying assumptions made by creators are at best ideologically suspect.</p><p>Many of the major growing pains related to the internet (and particularly the web) essentially come down to an “eternal september” moment where a set of technologies designed for hobbyist use in a a community with relatively aligned interests gets inserted into a commercial context where multiple adversarial parties are involved. (Spam, clickbait, fake news, intrusive advertising, all manner of security problems ranging from social engineering to sql injection, ‘dark ux patterns’, 419 scams, and trolling can all essentially be blamed on giving a system designed for good-faith cooperation to a bunch of people who would rather con each other to gain small advantages.)</p><p>Societies have an array of tools for limiting the damage done by bad-faith actors. Unfortunately, the cruel optimism of the people who design online communities either undercuts these mechanisms (in reality power structures are very conditional, since subordinates who lack trust in their superiors’ judgement will ignore orders; in computer systems, power structures are treated as much more cut and dry, compounding mistakes made by the powerful) or expands their power beyond what is reasonable (as with the human flesh search engine &amp; other mechanisms that pile on shame out of proportion with the original failure).</p><p>Recently I’ve seen what looks like an upswell in the general understanding that the world is complex &amp; can’t be easily understood or modeled, which makes me a little more hopeful for the future. However, easy solutions (even if they are wrong) can be very lucrative. Any system we design should be mindful of how it presents information &amp; how that presentation effects society.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[If we can do this (and it’s certainly technically possible), we can break siloization by doing the…]]></title>
            <link>https://medium.com/@enkiv2/if-we-can-do-this-and-its-certainly-technically-possible-we-can-break-siloization-by-doing-the-9757bae8a8f6?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/9757bae8a8f6</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 25 Jan 2017 18:30:55 GMT</pubDate>
            <atom:updated>2017-01-25T18:30:55.559Z</atom:updated>
            <content:encoded><![CDATA[<p>If we can do this (and it’s certainly technically possible), we can break siloization by doing the opposite: specifically selecting and recommending stories from non-intersecting social groups with related tags.</p><p>Personalization is great at giving people what they want, but when it comes to giving people what they need, we aren’t using all the tools at our disposal.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[As much as I’m loathe to heap praise on Second Life & Linden Labs, I think they at least got this…]]></title>
            <link>https://medium.com/@enkiv2/as-much-as-im-loathe-to-heap-praise-on-second-life-linden-labs-i-think-they-at-least-got-this-8a4ed0a4d4a?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/8a4ed0a4d4a</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 23 Jan 2017 01:34:13 GMT</pubDate>
            <atom:updated>2017-01-23T01:34:13.850Z</atom:updated>
            <content:encoded><![CDATA[<p>As much as I’m loathe to heap praise on Second Life &amp; Linden Labs, I think they at least got this model right: they handled transactions between users that would be occurring anyway, and then allowed people to put money into the system &amp; take it out.</p><p>When a user views a web page, a transaction implicitly occurs. Medium knows about both sides of this transaction. (With ads, the transaction is offloaded to one between two unrelated third parties.) It’s not unreasonable to make such a transaction explicit and broker it without third parties. If everybody starts off with enough credits to handle the whole lifetime of a very casual user, then the monetization will never affect normal users, which is a big hurdle.</p><p>Flattr is a lot like paypal donate buttons &amp; patreon, in that it’s an add-on that individuals put on top of a service to provide monetization the service doesn’t provide by leaning on the good will of individuals. Such systems sometimes work well, but you have to lean pretty hard on the NPR model of begging for donations in order to use them.</p><p>If you already manage the content distribution system, allowing casual users to automatically pay money they didn’t know they had (with the knowledge that most of that will never fully circulate and that which does circulate can be more than made up for by minimum balances for cashing out &amp; fees) lets you put the system in overnight without anybody noticing or caring &amp; then only charge very heavy users. (If the costs involved are small enough — and if they are on the scale of ad revenue, they are tiny — heavy users will not feel like it’s a burden on them to continue using the platform.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Berners-Lee had a project that did many things correctly that the web did incorrectly.]]></title>
            <link>https://hackernoon.com/berners-lee-had-a-project-that-did-many-things-correctly-that-the-web-did-incorrectly-93c7175ae4ce?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/93c7175ae4ce</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 13 Jan 2017 21:28:01 GMT</pubDate>
            <atom:updated>2017-01-13T21:28:01.238Z</atom:updated>
            <content:encoded><![CDATA[<p>Berners-Lee had a project that did many things correctly that the web did incorrectly. It was called Enquire, and it was a simplified version of some ideas from Project Xanadu. The world wide web was created as a teaching tool for explaining the concepts behind Enquire to CERN suits, because Berners-Lee had been having a hard time explaining Xanadu concepts to them.</p><p>Early web standards also solved many problems that plague the current web. If HTTP 1.1 was implemented properly, including all of the optional features, and it was used as intended, major problems like URL inconsistency would be solved. Unfortunately, important features of HTTP 1.0 and 1.1 are not implemented by any major web server, and other features are consistently used in a way that eliminates their original function.</p><p>The web as it stands now is much less than what it could have been even in the early 90s. I’m being deliberately provocative in recommending we use only the features of the web that better in the web than in other technology stacks, but the problem of using the wrong tool for the job in order to avoid learning about the right tool is real, and the web is the wrong tool for most of the jobs it does.</p><p>I’m not arguing against progress, here: I’m arguing against using poor solutions to problems for which good solutions exist. The fact that many poor solutions are newer than many good solutions is just a side effect of the widespread ignorance of history in the industry.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I’d definitely say the web is a bad tool for most of the things we use it for.]]></title>
            <link>https://hackernoon.com/id-definitely-say-the-web-is-a-bad-tool-for-most-of-the-things-we-use-it-for-c4c86124a678?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/c4c86124a678</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 18 Jan 2017 19:33:59 GMT</pubDate>
            <atom:updated>2017-01-18T19:33:59.605Z</atom:updated>
            <content:encoded><![CDATA[<p>I’d definitely say the web is a bad tool for most of the things we use it for. In particular, the technique of using javascript sitting within a document to dynamically edit that document’s structure &amp; CSS attributes is a particularly inefficient way of building a user interface, and without the heavy optimization being done by browser maintainers any such application would be unusable. (As much as I dislike Java, I have to admit that applets are actually the appropriate solution here.)</p><p>(Let me say that I like and appreciate that you *can* perform hacks like dynamic web pages; I’m just horrified that so many people think you *should*. Dynamic web pages are, essentially, self-modifying code. Anywhere else, we would be very wary of that.)</p><p>HTTP specs provide response codes that address some of the problems related to addressing documents via their position on machines. (Doing this rather than using CAN is a mistake in the first place, but TBL was working with a slow network before ideas about CAN were very widespread.) If we were to try to implement up to the original spec &amp; use that spec to get as close as possible to traditional pre-web hypertext best practices, we would make the content of each page static (no CGI), keep track of where every document is at all times, use temporary and permanent redirect response codes if a document moves, never have two different documents (or a modified version of the same document) with the same full URL, and only use a 404 return code in the apocalyptic case that somebody simultaneously nuked your server and all your backups (or in the case that a document *never existed*). Today, these codes are not used that way.</p><p>(HTTP also specifies some very useful functionality that is very rarely implemented. Specifically: HEAD requests to get the length of a document and special variations on GET requests that return a span of bytes, given a starting offset and length. Such features are very useful in an environment where documents are static but potentially very long. Having worked on code intended to perform transclusions from arbitrary URLs, this feature would have drastically simplified my efforts.)</p><p>Right now, the most promising competitor to HTTP is IPFS — a CAN-based file transfer system. It doesn’t solve the problem of servers going down permanently (there is no automatic redundancy), but popular files will outlive short outages because requested files are served from cache (which also saves bandwidth upstream). IPFS avoids CGI-style hacks, but you can still serve arbitrary HTML/Javascript blobs, so it’s not as though it breaks that functionality. (Again, I consider using javascript to manipulate HTML messy and slow.)</p><p>My main complaint with web apps is that very few things benefit from being on port 80 &amp; being stuck inside HTML. An applet, because it’s essentially a native application that has been sandboxed, doesn’t have the problem of needing to draw using drawing routines intended for dealing with messy hand-written markup, nor does it have the problem of working against a set of quirk rules organically grown to protect against 20 years worth of random but very specific attacks on web browsers. An applet can use standard protocols, instead of depending on services that are exposed over HTTP wrappers. (HTTP-exposed APIs take the rule-breaking of CGI — which, remember, discouraged people from using redirects properly and led to the current user-hostile behavior of redirects; they are additionally generally less efficient than existing standard protocols.)</p><p>Applets have gotten a bad name, because most applets are either Java or Flash, and both of those platforms have a history of being quite awful. But, there’s no particular reason that an applet viewer for javascript, or lua, or smalltalk couldn’t exist, provided that someone decided on a decent standardized drawing model that properly supported all the various things people like to put in GUIs.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The Value of Subtle Communication: Toward a Secular Materialist Model of Chaos Magick]]></title>
            <link>https://modernmythology.net/the-value-of-subtle-communication-toward-a-secular-materialist-model-of-chaos-magick-c038d5a02fa1?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/c038d5a02fa1</guid>
            <category><![CDATA[religion]]></category>
            <category><![CDATA[occult]]></category>
            <category><![CDATA[magick]]></category>
            <category><![CDATA[spirituality]]></category>
            <category><![CDATA[ritual]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 18 Jan 2017 21:42:56 GMT</pubDate>
            <atom:updated>2017-01-18T22:17:52.528Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*HH4EY_3z0v9GIhup9p7Y3A.jpeg" /></figure><p>Where occult traditions typically anchor themselves firmly to the metaphysical, chaos magick has historically been open to more materialist interpretations, although inconsistently so. I do not claim that metaphysical understandings of magic are necessarily wholly invalid, but I would like to suggest that most if not all of the major practices associated with chaos magick do not require or benefit from appeals to ideas outside the scientific mainstream. In other words, the practices of ritual (particularly sacrifice) and sigilcraft (including hypersigils, etc) are fully compatible with a conventional scientific, secular, materialist worldview.</p><p>The cornerstone of my argument is the idea of subtle communication with oneself and others as a means of influence.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/500/1*4NWHfEQRbeC9-txSxqp9lw.jpeg" /></figure><p>By subtle communication, I mean: communication that bypasses conscious, verbal modes of understanding. This is not to say that such forms of communication have no verbal component; only that the most important aspects of these communications are not, to the target, immediately understood in terms of the most obvious and direct interpretation. Subtle communication in the domain of writing includes subtext, wordplay, irony, symbolism, oblique reference, the literal content of metaphor, and emphasis; in speech, we can also consider changes in meaning and emphasis created by timing and modulation; when speaking to someone in person, facial expressions and body language constitutes high-bandwidth subtle communication mostly hidden from us but transferred by unconscious mirroring behavior. Regular speech can become subtle communication if the target is unable to distance themselves enough to objectively analyse it, either because it becomes internalized before it is fully understood (as with song lyrics), or because something is interfering with verbal processing (as with the repetition of creeds or mantras — jamming the verbal processing facilities — or when the target is tired or under the influence of various drugs). Subtle communication has lower bandwidth and a greater error rate than overt communication, and it is often missed or dropped, but it also bypasses many of the mechanisms that might work against some goal, which makes it an ideal way to circumvent forces that would work against a more direct attempt.</p><p>Seen in this way, sigils (when directed at the self) operate a bit like affirmations. A sigil is a reminder of an intent, but one that is oblique enough that it avoids triggering self-defeating behaviors. When sigils are directed at others, they retain less of their meaning, but some subtle communication is still achieved (with the amount depending upon the quantity of shared understanding and assumptions between the creator and the target). We can expect only a small effect from showing our sigils to others, at best, unless we give them enough context that it is comparable to their having made the sigil themselves; if we share enough culture with the others, however, subtle communication from them can reinforce our own goal-seeking behavior, like a smaller-scale version of publicizing one’s to-do list or new year’s resolutions. When such pressure is small and subtle, it doesn’t overwhelm.</p><p>Rituals abstract our goal in much the same way that sigil creation does. The pressure is higher because of sunk cost: rituals are costly signals to the self about the importance of achieving some goal. The time and effort turned over to a ritual is itself a sacrifice (and one that is properly set in our minds, as opposed to a pathological case like gambling wherein sacrifices are disguised as investments or amusements), and an actual sacrifice increases the cost. Group rituals bind the group together to a common goal: they all made the same sacrifice, and would like to avoid the cognitive dissonance of having wasted it, so they must achieve their goal in order to justify their sacrifice.</p><p>Books like Mind Performance Hacks produce rationalist-friendly “life hack” versions of these practices, with the occult terminology stripped out. Rather than sigils, print out a sheet with affirmations or themed words in order to encourage particular primed responses! Rather than rituals, make a betting pool with your friends about the success of some project, or vow to donate to a charity you hate if you fail! By embracing the verbal mind, these practices open up the door to endless second-guessing, and thus to self-sabotage. I would recommend the chaos magick versions of these practices instead. Self-sabotage seems likely, particularly if you don’t respond well to direct pressure.</p><p>With hypersigils, the mechanism of action is even easier. People model their worldview mostly on <em>art</em>: experiences provided by art are easier to find and consume than experiences provided by life, and are also safer. A hypersigil takes a naturalistic view of the world and adds elements to it that encourage emotional investment, and then slowly modifies it in ways that correspond to some intent. The result is that the creator and audience both have their world view modified by the creator’s intent. When the audience has adjusted expectations, it becomes more likely that they will manipulate the world to fit those expectations, as well as communicating their expectations to secondary audiences.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[For Medium, the most sensible monetization policies would probably be:]]></title>
            <link>https://medium.com/@enkiv2/for-medium-the-most-sensible-monetization-policies-would-probably-be-8ee9b19f421f?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/8ee9b19f421f</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 18 Jan 2017 13:22:37 GMT</pubDate>
            <atom:updated>2017-01-18T13:22:37.702Z</atom:updated>
            <content:encoded><![CDATA[<p>For Medium, the most sensible monetization policies would probably be:</p><ul><li>microtransactions from readers to authors (where Medium takes a cut whenever anybody wants to cash out, &amp; otherwise holds cash in escrow). (This is essentially what Adsense, Mechanical Turk, and Second Life did.)</li><li>pay for privacy (a variation on freemium used by github, wherein normal use is free but paid accounts can whitelist or blacklist posts to specific audiences — making it possible to treat medium like a private forum)</li></ul><p>Users of Medium can already use something like patreon, but Medium could potentially benefit from integrating something like SPP (an ancestor of patreon) and taking a cut. In SPP, a work is created but only released to the public when a certain threshhold of funding/donation is passed; since Medium is a publishing platform, they are in a unique position to hold a piece of writing in escrow until the threshhold is passed. (I like SPP in concept, but of all the variations I cover in <a href="https://medium.com/@enkiv2/alternatives-to-advertising-7af0e32b8a8e#.6rkbh6lq7">my overview piece</a>, it’s the only one that hasn’t really been properly implemented, and the idea may be a little too alien to most users.)</p><p>Medium already uses a freemium model to some extent, with publications having greater control of color and layout. This by itself won’t keep them afloat, though. I think if they kept publications as their freemium model &amp; added microtransaction support (maybe even just as an author option in the licensing menu), they could do significantly better than they would with advertising.</p><p>If full support for microtransactions is too scary for them (since it would require casual users to put money into the system), another possibility is to integrate submission payment into Medium itself. Some publications pay for submissions, but perform draft submission &amp; editing via Medium itself; the only portion of the process that’s done outside of Medium is the payment. (I’ve been paid for submissions and had a ~4 month wait between publication and payment because of overseas wire transfers.) If publications are already paying into Medium, giving users all an account balance &amp; building support for basic publication agreements into Medium itself would actually streamline the process enough that Medium could justify taking cuts comparable to what PayPal takes. (And, while Medium holds on to all that borrowed money they can keep the interest that accumulates.) Doing this might be a first step toward supporting microtransactions on a larger scale.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The command line and GUI replaced voice as an interaction model decades ago, because for most tasks…]]></title>
            <link>https://medium.com/@enkiv2/the-command-line-and-gui-replaced-voice-as-an-interaction-model-decades-ago-because-for-most-tasks-d994ab8e189e?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/d994ab8e189e</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 17 Jan 2017 13:52:23 GMT</pubDate>
            <atom:updated>2017-01-17T13:52:23.415Z</atom:updated>
            <content:encoded><![CDATA[<p>The command line and GUI replaced voice as an interaction model decades ago, because for most tasks it’s easier to do it yourself than tell a secretary to do it for you. (And make no mistake, much of the time secretaries were more intelligent and capable than the people who commanded them.) Until the advent of weakly superhuman artificial general intelligences, the absolute best case for voice and natural language as an interaction model will be strictly worse than instructing a human subordinate.</p><p>The sorry steady state of most large organizations (the SNAFU) is the direct result of the flaws of natural language as an interaction model. As an organization becomes more close-knit and efficient, jargon proliferates and language becomes more exact for things that matter, until what people speak to one another resembles one of the less well-thought-out programming languages (perl, php, basic, fortran). In other words, the end goal of any natural language interface (even between humans) is to become a command line interface.</p><p>Of course, between humans, the learning curve is hidden because it is merged with the organic emergence of a shared cant. But, this hiding of the learning curve can only be performed once: people who come later to a community must learn the language of that community. Why not standardize, when we can? After all, machines aren’t very good at improvizing collaboratively generated vocabularies based on implication but are very good at consistently interpreting the same conventions the same way (and copying those conventions exactly to other machines).</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Medium started out with the goal of fixing clickbait, and the (correct) understanding that an ad…]]></title>
            <link>https://medium.com/@enkiv2/medium-started-out-with-the-goal-of-fixing-clickbait-and-the-correct-understanding-that-an-ad-53cd5fd62190?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/53cd5fd62190</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 17 Jan 2017 13:17:23 GMT</pubDate>
            <atom:updated>2017-01-17T13:17:24.385Z</atom:updated>
            <content:encoded><![CDATA[<p>Medium started out with the goal of fixing clickbait, and the (correct) understanding that an ad-driven revenue model encourages clickbait / low-quality content.</p><p>Somewhere along the way, it decided to support ads anyway, and while early design decisions worked against clickbait, later design decisions didn’t. (As a result, everyone’s feeds got worse.)</p><p>I welcome Medium’s return to their original goal, and if the people who were laid of were contributing to the downfall of the platform, I’m glad that they are no longer in a position where they can make things worse (although it would be naive not to put the ultimate blame on top staff, and probably ultimately VCs). However, it’s sort of alarming that Medium isn’t aware of the many reasonable alternatives to ad-based revenue &amp; paywalls, after so many years.</p><p>‘Finding’ an alternative to ad-based revenue implies that one isn’t already in front of you. In the industry there’s this idea, probably borne out of cognitive dissonance, that ad-based monetization is a necessary evil; this has never been true, since alternative proposals predate the advent of banner ads by 30 years.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Hiring is a whole different mess.]]></title>
            <link>https://medium.com/@enkiv2/hiring-is-a-whole-different-mess-e426f84ae527?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/e426f84ae527</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Sat, 14 Jan 2017 00:43:25 GMT</pubDate>
            <atom:updated>2017-01-14T00:43:25.799Z</atom:updated>
            <content:encoded><![CDATA[<p>Hiring is a whole different mess. I appreciate the problem of necessary yet bullshit credentials. (I learned a lot from college, but very little of it related to computer science, and while I owe my current job to college, it’s because a member of the faculty used a personal connection to recommend me for an internship. So, I would have done almost as well with a fake degree.)</p><p>I have other rants on hiring, having been involved in interviews on both sides of the table several times. It’s broken, in a different but related way.</p><p>Ideally, we’d consistently have technical people interview technical hires, remove bullshit credentials as requirements, and end up undercutting the industry in bullshit credentials while simultaneously improving the average quality of worker in the industry. I don’t think that’ll happen until after the next major tech industry crash, though.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ramifications of nearsightedness in tech]]></title>
            <link>https://medium.com/@enkiv2/ramifications-of-nearsightedness-in-tech-b00cc0473ce3?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/b00cc0473ce3</guid>
            <category><![CDATA[entrepreneurship]]></category>
            <category><![CDATA[startup]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 13 Jan 2017 22:36:13 GMT</pubDate>
            <atom:updated>2017-01-13T22:36:13.797Z</atom:updated>
            <content:encoded><![CDATA[<p>A tool that is used for everything will necessarily be a poor fit for most of the tasks for which it is used. In theory, a vice grip can be used as a hammer, screwdriver, or wrench; a mechanic who uses a vice grip for all these tasks does not inspire confidence. Somehow, this is not the case in the tech industry — whose vice grips include the web, hadoop, java, and c++.</p><p>Language wars aren’t totally pointless: it’s useful to inspect and document what tasks various tools are good at, and how best to use these tools. However, language wars at some point became a matter of tribalism, and tribal defense of the idea of one language over another for all tasks benefits no one — with the exception of snake-oil salesmen who want to sell you the panacea for all your programming woes. Such confidence artists exercise a lot of power in the industry these days.</p><p>One would think that common sense would prevail. After all, performance, man-hours, and downtime are all measurable. But, even as more and more is being automatically measured and recorded, connection to reality is increasingly tenuous: “unicorns” worth billions of dollars nevertheless have no plans for monetization, companies are created with the goal of being sold instead of providing services, and the fortunes of most players are determined arbitrarily by small gambling rings called venture capital firms. Everything’s a web service, and to the extent that they are monetized at all, they use ad-tech — a mutated version of microtransactions where an arbitrary corporation pays a fraction of a cent to a web host in return for an http request, with the value of that fraction determined by an uninformed estimate of how likely that request is to result in a product sale, and wherein that estimate drops endlessly because most requests come from robots incapable of purchasing products. As a result, the most highly valued properties are ones that no one wants, and fashions wholly disconnected from popular desirability sweep the industry. The tech industry strongly resembles modern Hollywood: dominated by expensive flops, and under thrall to its own marketing due to excessive insularity.</p><p>Another thing the tech industry strongly resembles is a pyramid scheme, or a cult.</p><p>At the very least, our industry is amusing, in the way that <a href="https://en.wikipedia.org/wiki/Sanatorium_Under_the_Sign_of_the_Hourglass"><em>Sanatorium In the Sign of the Hourglass</em></a> or <em>The Penal Colony</em> is amusing. Like most things whose value is based on faith in ideas that don’t track with reality, it probably won’t last in this state for very long. We’re in the Wiemar Cinema era of this industry, probably: Murnau can’t keep making films like Nosferatu if he binges on opium every night.</p><p>I’m not really concerned with the delusions of the elites, though. Peter Thiel and Paul Graham can make grand pronouncements, but they wouldn’t even notice if nobody on the ground listened. My major concern is that naive, lazy ideas dominate the industry even within the entry level. I attribute this to problems in education.</p><p>We have a bunch of mythology in the current industry, but it bears little in common with the earlier body of mythology and it teaches the wrong lessons. It elevates venture capital, lucky charismatic sociopaths, and companies whose value is wholly imaginary. It justifies using one tool for everything (via Paul Graham’s adulation of Lisp, didiactic standards for college curricula that suggest everything should be a Java class, the normalization of bootcamps that push you through a tutorial for a single language in a few weeks with the promise that you’ll be ready for employment). It’s the kind of mythology that cocaine-snorting ad men from the 80s would invent, because that’s who invented it.</p><p>When we eschew real history in favor of hero-worshipping Steve Jobs, we are eschewing real knowledge in favor of ad copy and flavor text. Our lack of familiarity with history allows us to imagine that the web is the way hypertext is supposed to work, putting an RDBMS on top of hadoop makes sense, PHP is an acceptable language, and new fashions in the industry are world-shaking innovations. It lets us imagine that Slack is a major improvement over IRC, Uber is the underdog fighting against foolish overregulation, smart phones are the future of computing, and hard work will make you a millionaire.</p><p>New, trendy ideas in tech are typically poorly-understood ideas from the 1970s. The flaws in these ideas that will cause everyone to abandon them in six months were published in the first response to the original paper, if not in the original paper itself. Save yourself some time, and read CS publications from the 70s. When the rare genuinely new idea appears, you will be uniquely suited to understand it.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I always thought “borked” was derived from “borken”, the early 1960s era humorous mistyping of…]]></title>
            <link>https://medium.com/@enkiv2/i-always-thought-borked-was-derived-from-borken-the-early-1960s-era-humorous-mistyping-of-2615ff378118?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/2615ff378118</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 13 Jan 2017 18:26:13 GMT</pubDate>
            <atom:updated>2017-01-13T18:26:13.001Z</atom:updated>
            <content:encoded><![CDATA[<p>I always thought “borked” was derived from “borken”, <a href="http://catb.org/esr/jargon/html/B/borken.html">the early 1960s era humorous mistyping of “broken” within the MIT hacker community</a>. (While ESR doesn’t give a date or etymology, this entry goes back to the original Hacker’s Dictionary, which was compiled in the early 60s.) I never knew about this second, politically-charged meaning!</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I think you’ll find that web browsers can, in fact, render hand-written plain HTML.]]></title>
            <link>https://medium.com/@enkiv2/i-think-youll-find-that-web-browsers-can-in-fact-render-hand-written-plain-html-8e772d6970d?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/8e772d6970d</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 09 Jan 2017 14:50:22 GMT</pubDate>
            <atom:updated>2017-01-09T14:50:22.221Z</atom:updated>
            <content:encoded><![CDATA[<p>I think you’ll find that web browsers can, in fact, render hand-written plain HTML.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cyberpunk, sadly, died in infancy. What’s worse is, it was replaced by a changeling.]]></title>
            <link>https://medium.com/@enkiv2/cyberpunk-sadly-died-in-infancy-whats-worse-is-it-was-replaced-by-a-changeling-1fa04ca39b65?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/1fa04ca39b65</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 09 Jan 2017 14:11:43 GMT</pubDate>
            <atom:updated>2017-01-09T14:11:43.346Z</atom:updated>
            <content:encoded><![CDATA[<p>Cyberpunk, sadly, died in infancy. What’s worse is, it was replaced by a changeling.</p><p>When I talk about cyberpunk, I’m really talking about the politically-charged visionary science fiction written by Bruce Sterling’s cohort in the late 1970s and early 1980s that combined the stylistic experimentation of the New Wave movement, the social consciousness &amp; focus on economic injustices of naturalistic fiction, the moral complication of hardboiled/noir fiction, and the bite of the then-recently-deceased punk movement. By the time Neuromancer got published, most of the really interesting stuff in the cyberpunk movement had already stopped; the occasional really good cyberpunk after that point (such as the Ghost in the Shell manga — not the film or the show — or Akira, or Altered Carbon) were rare, because immediately upon breaking into the mainstream, cyberpunk was consumed by the Spectacle and became an aesthetic instead of a movement.</p><p>As a result, it has a really complicated legacy.</p><p>Gibson never really stopped writing about the same kind of material he wrote about in Neuromancer. He still explores the sociology of extreme economic inbalance. Likewise, Bruce Sterling is as good as he’s ever been. John Shirley &amp; Rudy Rucker, despite being central to the group, were always doing their own thing and continued to do their own thing without really being able to be clearly categorized as cyberpunk. But, post-1992, nothing Gibson wrote was really considered cyberpunk, and Sterling transitioned even earlier.</p><p>Because it’s considered an aesthetic, cyberpunk is strongly associated with specific imagery, and the imagery is tied to various periods. People make odes to first-generation cyberpunk (prior to 1990, essentially) by fetishizing 80s tech (see Jackrabbit, for instance), and while this aesthetic is one I find only minimally problematic, it misses the underlying point in the same way that Steampunk misses the underlying point of The Difference Engine.</p><p>By the early 90s we started removing even the punk aesthetic from cyberpunk aesthetic, and cyberpunk was almost entirely politically neutralized by 2000: we associate cyberpunk often with Hackers (1995), wherein the political content is limited to vague and half-hearted anticapitalist sentiment and a cliched-by-1994-standards environmental message tacked on as an afterthought, The Matrix (1999), which gives a pretty good representation of the Spectacle but whose political content has nevertheless been completely misunderstood by a core audience who has reinterpreted it as anti-woman and anti-semitic, and Swordfish (2003), which was slicker and in retrospect smarter than all the others but extremely politically confused. The idea of a cyberpunk protagonist in 1990 was a low-level criminal with a drug addiction — a tweaker who needs a bath. The idea of a cyberpunk protagonist in 2000 was a rich white teenager with bleached hair, sunglasses, and a leather duster. By 2005, the ideal cyberpunk protagonist willingly worked for the government. Today, as the original cyberpunk works are more relevant than ever, people ignore the books in favor of movies that show pretty people in leather performing magic.</p><p>A return of cyberpunk aesthetic will do nothing for us. A return of cyberpunk sensibility, on the other hand, could be extremely helpful.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Our systems (even on relatively longread-friendly platforms like Medium) disincentivize nuance.]]></title>
            <link>https://medium.com/@enkiv2/our-systems-even-on-relatively-longread-friendly-platforms-like-medium-disincentivize-nuance-f65765184547?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/f65765184547</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 09 Jan 2017 13:42:28 GMT</pubDate>
            <atom:updated>2017-01-09T13:42:28.128Z</atom:updated>
            <content:encoded><![CDATA[<p>Our systems (even on relatively longread-friendly platforms like Medium) disincentivize nuance. They don’t need to.</p><p>Consider Medium’s ranking process, by which it sorts content for the dashboard/feed, recommendations, and various lists. While I’m unaware of a writeup of how it actually works, it’s clear that ranking is not based purely on recency. Instead, it appears to be based upon a combination of recency &amp; interaction (recommendations and comments) weighed by social network distance. A minor tweak that would increase the weight of full reads (and increase that weight based on estimated read time, so that an article that takes an hour to read that got five reads by people you’re following will be ranked higher than an article that takes five minutes to read but got twenty-five reads) could make short clickbait articles mostly disappear from our feeds. Instead, recommendations clearly count for much more than reads or length.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I think we can tag him. Ev Williams]]></title>
            <link>https://medium.com/@enkiv2/i-think-we-can-tag-him-ev-williams-6bf3e70f0120?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/6bf3e70f0120</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 05 Jan 2017 17:06:03 GMT</pubDate>
            <atom:updated>2017-01-05T17:06:03.747Z</atom:updated>
            <content:encoded><![CDATA[<p>I think we can tag him. <a href="https://medium.com/u/268314bb7e7e">Ev Williams</a></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I think the time might be right for micropayments as a publishing monetization model.]]></title>
            <link>https://medium.com/@enkiv2/i-think-the-time-might-be-right-for-micropayments-as-a-publishing-monetization-model-8ecf3a89479d?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/8ecf3a89479d</guid>
            <category><![CDATA[advertising]]></category>
            <category><![CDATA[monetization]]></category>
            <category><![CDATA[medium]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 05 Jan 2017 15:20:16 GMT</pubDate>
            <atom:updated>2017-01-05T15:20:16.014Z</atom:updated>
            <content:encoded><![CDATA[<p>I think the time might be right for micropayments as a publishing monetization model.</p><p>The reason is that ad-based monetization is already micropayment-based. An advertiser estimates how much a view would be worth, and sends that much to an ad host per view. The big problem with ad-based monetization is that neither the author nor the viewer of the post is on either end of this transaction and the transaction cost has been turned into a futures market that everyone has been incentivized to game. As a result, the average impression is of approximately zero value, because the average impression is made by a bot looking at an advertisement for a nonexistent product on a site intended to farm fraudulent ad impressions.</p><p>If we associated our accounts with some money, and charged as much per view as ads pay out, then gave medium half of that (which is more than the ad host would get paid out under adsense), we would cut out a whole industry of middle-men and your average user could coast on five bucks for decades. (If new users got a dollar credit or something, it would essentially simulate a freemium model; if users had to add funds in five dollar increments, Medium could make a fortune on interest from their escrowed cash. The normal case would have money mostly stay inside the system — in Medium’s coffers — because most people who do a lot of writing on Medium also do a lot of reading on Medium. Big publications would still make bank, because they’d still get a lot of views; they’d actually make more profit, because three tenths of a cent per page view is more than they’d ever make off ads.) Medium already determines the distinction between a “view” and a “read” — so if they charge/pay double or triple as much for a “read” than a “view”, readers wouldn’t notice but authors would be highly incentivised to create high-quality content worth reading, and clickbait would disappear.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I mean that, ideally, facebook, medium, and youtube wouldn’t be websites, because the web is a poor…]]></title>
            <link>https://medium.com/@enkiv2/i-mean-that-ideally-facebook-medium-and-youtube-wouldnt-be-websites-because-the-web-is-a-poor-640438dd6634?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/640438dd6634</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 04 Jan 2017 16:25:06 GMT</pubDate>
            <atom:updated>2017-01-04T16:25:06.541Z</atom:updated>
            <content:encoded><![CDATA[<p>I mean that, ideally, facebook, medium, and youtube wouldn’t be websites, because the web is a poor solution to the problem of building responsive user interfaces.</p><p>Sometime in the late 90s, we all collectively decided that all networked applications were supposed to run off port 80 and sit inside a web browser. This leads to massive engineer labor (software engineers end up spending enormous amounts of effort trying to do what would be trivial as a native app inside a web browser, software engineers spending an enormous amount of effort trying to make web browsers capable of doing everything web designers are trying to do with them without creating security flaws), massive resource waste (cycles and packets wasted en masse because nobody’s using more efficient methods, even when those methods would also be easier to implement, because crappy solutions have become the default), and ultimately we screw the pooch on security too because we’ve layered everything important on top of a simplified version of a 1992 demo intended to explain Enquire to suits instead of ensuring that our technical decisions make technical sense.</p><p>We’re locked in now. But, were we to make sensible decisions from the beginning, our hypertext systems would have permanent content-based addressing with automatic replication (instead of temporary machine-based addressing that fails to uniquely, consistently, or permanently correspond to any given piece of information), no scripting (since scripting is totally unnecessary for hypertext), no association with the domain name system (because domain names are broken), no association with the certificate chain system (because root certificates get leaked all the time), no ad-based revenue (because ad-based revenue encourages a race to the bottom in terms of content quality), and no embedded markup (external, offset-based markup is easier to implement and avoids most common markup-related problems).</p><p>As a web developer, your job is to make objectively poor decisions about web development in ways that are profitable to your employers. That doesn’t mean that you need to believe those decisions are good; you just need to implement them.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I’m not kidding.]]></title>
            <link>https://medium.com/@enkiv2/im-not-kidding-cc20a124305c?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/cc20a124305c</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 04 Jan 2017 13:14:30 GMT</pubDate>
            <atom:updated>2017-01-04T13:14:30.409Z</atom:updated>
            <content:encoded><![CDATA[<p>I’m not kidding.</p><p>The web is good at exactly one thing: transmitting static text documents that include minimal formatting and hyperlinks. It’s not even great at <em>that</em>. CSS and Javascript take the easy problem that the web already mostly fails at, and turns it into a hard, complicated problem by providing poor tools for simulating native applications.</p><p>If you feel like you need CSS, write LaTeX or PostScript. If you feel like you need JavaScript, write a native app (maybe in JavaScript!). Don’t put a browser where it doesn’t belong.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[This is why I always say that if we want an idea of how life will be under UBI, we should look at…]]></title>
            <link>https://medium.com/@enkiv2/this-is-why-i-always-say-that-if-we-want-an-idea-of-how-life-will-be-under-ubi-we-should-look-at-ca58be186075?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/ca58be186075</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 03 Jan 2017 14:00:25 GMT</pubDate>
            <atom:updated>2017-01-03T14:00:25.116Z</atom:updated>
            <content:encoded><![CDATA[<p>This is why I always say that if we want an idea of how life will be under UBI, we should look at the current lives of the wealthy.</p><p>Labor won’t suddenly completely dry up, for the same reason that those who are wealthy enough not to need to work often end up performing volunteer labor: the more labor is disentanged from survival, the less one is alienated from it (and the more it resembles a hobby). (Under UBI, we also won’t really need to worry about the wealthy performing jobs normally done by the poor at lower rates, since labor flexibility becomes normal rather than the privilege of the elites.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[You don’t really need to go to 4chan for this.]]></title>
            <link>https://medium.com/@enkiv2/you-dont-really-need-to-go-to-4chan-for-this-c6786130a774?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/c6786130a774</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 03 Jan 2017 13:55:28 GMT</pubDate>
            <atom:updated>2017-01-03T13:55:28.534Z</atom:updated>
            <content:encoded><![CDATA[<p>You don’t really need to go to 4chan for this. The facebook group “Ancap Memes from Rothbard’s Dreams” specializes in these.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ive is very much acting in line with Jobs’ legacy.]]></title>
            <link>https://medium.com/@enkiv2/ive-is-very-much-acting-in-line-with-jobs-legacy-e79d943eba8f?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/e79d943eba8f</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 30 Dec 2016 13:03:10 GMT</pubDate>
            <atom:updated>2016-12-30T13:03:10.059Z</atom:updated>
            <content:encoded><![CDATA[<p>Ive is very much acting in line with Jobs’ legacy.</p><p>There’s a lot of mythmaking at Apple, and it’s in some ways responsible for Apple’s recent success, but in this case it really obscures the history. Jobs was all about removing functionality in favor of form in his work at Apple, starting with his take-over of the Macintosh project at the latest. While he didn’t do this at NeXT to the same degree, as soon as he came back at Apple, he doubled down on it.</p><p>Apple has never been the “fun” alternative (if you count all its competitors, rather than pretending the only alternative to the Mac has ever been the IBM PC, which was never true). On the other hand, removing important features in order to cut production costs was pretty standard in the late 70s and early 80s, and would have been completely acceptable in the generation of machines the Apple ][ belonged to. (The Apple ][ initially was unable to display lower-case letters, in order to save on ROM; similarly, Sinclair BASIC used single characters as commands, to save space.) We owe Jobs’ and Ive’s legacy to the predictable commercial failure of the Lisa and certain cynical ideas Jobs developed about the market in the wake of that failure. The relative success of competitors like the Atari ST and Amiga despite marketing and advertising failures demonstrates that Jobs’ model of the computer industry in the mid-80s was completely wrong, but it nevertheless defines the behavior not only of Apple but of many of Apple’s competitors to this day.</p><p>The Lisa would have been a half-decent machine, if made with today’s technology. It was, however, made with late-70s technology, and very little attention was paid to performance. As a result, this machine cost two thousand dollars in 1982 money, couldn’t operate without an external hard drive of roughly equivalent price, and once operational would take minutes to perform simple operations. It was a failure, because it was an expensive and unusable machine; on a purely technical level, it was a success at being interesting, building in many truly novel ideas. After the market failure of the Lisa, Jobs kicked Raskin off the Macintosh project and turned the Macintosh into an attempt at a low-budget version of the Lisa.</p><p>(Raskin’s ideas for his original Macintosh project really were novel and revolutionary in a way that the Macintosh was not; unfortunately, aside from a short-lived attempt at selling it as ‘Swyftboard’ extension cards for the Apple ][, these ideas only ever made their way into the Canon Cat — a dedicated word processor that cost as much as a Lisa.)</p><p>Jobs decided that the failure of the Lisa was the result of high cost and low performance (which is true), but (being non-technical) he had no idea what kinds of functionalities are actually slow or require special hardware and (being an egomaniac) he made ridiculous pronouncements about performance in public and held his engineers to them. As a result, the original Macintosh had a small, built-in monochrome (not greyscale!) display, half the RAM of competitors, no multitasking, and only one mouse button. It sold for less than the Lisa, but for double the price of competitors that had double or triple the performance. Much of the development and prototyping cost actually went into repeated changes to the shape of the case.</p><p>As a result of the Macintosh hemmoraging money (despite the high margins, not enough people were buying them to make up for the famously wasteful development, and by the time the Mac shipped it was four years behind the curve on hardware) and Jobs’ habit of yelling at employees until they cry, he was replaced as CEO by John Sculley, and eventually forced to resign. (Apple under Sculley continued a Mac-centric plan, but continued to lose money; however, Macs under Sculley actually had color displays and more-or-less competitive hardware.)</p><p>For people who have short memories and only care about Apple post-1997, this may seem like ancient history and irrelevant. But, we have to recognize that during the era when Jobs wasn’t in charge, Apple pushed the Mac in the direction of being like its competitors. During those years, the Mac competed on features. There were low-budget models that cost less but had crappier hardware. For a short period in the 90s, there were licensed (and unlicensed) third-party Mac clones that could run Mac OS. (Apple didn’t compete <em>well</em> with the other players, but with Atari practically going out of business again due to the failure of the Jaguar and Lynx and Commodore’s spectacular mismanagement of the Amiga line, they ended up surviving a pretty tumultuous period, with their major competitors as of the late-90s being mostly competitors run by former Apple employees — NeXT and Be. Apple at this time was a little like Yahoo is now: losing money and repeatedly making awful business decisions, but holding on to enough loot from its glory days of decades before to still be an important player to consider, like a senile giant.)</p><p>When Jobs came back, he cancelled all ongoing projects and instructed his employees to start working on making a Mac OS emulation layer for NeXTSTeP. He then had a cut down version of their next-generation Mac released, in a colorful case and without a floppy drive. (Releasing a machine in 1998 without a floppy drive was like releasing a machine today that can’t display lower-case letters.) Eventually, we got a fully re-branded NeXTSTeP/BSD hybrid that could run legacy Macintosh applications, in the form of OSX, and a bunch of really bizarre case designs (ranging from something that resembles a modern tablet embedded in a brick of lucite to screens mounted like desk-lamps). (We also got a couple conventional towers, but you have to recognize that in 1997, Macs were all still beige boxes.)</p><p>In other words, Jobs’ influence on the Macintosh prior to 1986 was to drop anything resembling an interesting feature (including his famous refusal to include expansion ports on the original Mac) in favor of fancy beveling, and Jobs’ influence on the Macintosh from 1997 to 2000 was primarily to drop important hardware in favor of translucent colored plastic and drop current multi-year development projects in favor of just copying what his last company did.</p><p>(We should examine NeXT a bit. NeXT was full of people from the original Macintosh team — Jobs took the best and brightest from the Macintosh and Lisa teams with him when he left. NeXT used an off the shelf UNIX kernel, hired on the inventor of Objective C, and did some interesting technical work by mid-80s standards (we owe many of the strange behaviors and limitations of the modern web browers to the fact that Tim Berners-Lee liked the NeXT UI builder tool), hidden behind a machine that still had a monochrome display at the edge of the 90s. NeXT didn’t have the same resources as Apple did, so development couldn’t be so wasteful; the NeXTCube was a decently solid machine. Still, NeXT boxes were expensive, and the company hobbled along just like Apple did. During this era, Jobs wasn’t continuing his Macintosh habit of taking somebody else’s design, stripping features from it at random, and calling himself a genius for knowing which features to strip; but, when he got back to Apple, he did this with his own NeXT machines.)</p><p>Apple’s real success under Jobs, though, was to take existing products on the market, make clones that strip important features at random, and sell the clones for double or triple the cost of the technically-superior originals. In other words, to perform the same operation that turned the Alto into the Macintosh (by way of the Lisa) on the existing MP3 player &amp; smartphone markets.</p><p>When Apple runs out of things to copy, it tends to either produce ill-conceived products of its own or start removing features from its own previous generation at random. Jobs didn’t have to be good at removing features: he had sufficient charisma that he could pass off all his mistakes as works of transcendent genius. But Apple is now run by his ghost, and while Apple employees are close enough to the source to have their realities warped, the rest of us have been snapping out from under the spell.</p><p>The truth is, removing features is something that has to be done very carefully. Jobs’ charisma masks the fact that nothing he did from 1979 to 1999 was a good business decision and every one of his successes are owed to his ability to persuade strangers to believe plainly false things. Without that shield, Apple can’t last very long with the same rulebook, because none of the rules ever had to make sense before.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Where Wizards Stay Up Late would be a great addition, but I haven’t finished it, so I didn’t feel…]]></title>
            <link>https://medium.com/@enkiv2/where-wizards-stay-up-late-would-be-a-great-addition-but-i-havent-finished-it-so-i-didn-t-feel-977e9e46424d?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/977e9e46424d</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 29 Dec 2016 16:08:26 GMT</pubDate>
            <atom:updated>2016-12-29T16:08:26.857Z</atom:updated>
            <content:encoded><![CDATA[<p><em>Where Wizards Stay Up Late</em> would be a great addition, but I haven’t finished it, so I didn’t feel it would be right to include it. (This is also true of <em>The Soul of a New Machine</em> by Tracy Kidder)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[18 book reading list for computer history]]></title>
            <link>https://hackernoon.com/a-short-reading-list-for-computer-history-eab5f942bf34?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/eab5f942bf34</guid>
            <category><![CDATA[computer-history]]></category>
            <category><![CDATA[technology]]></category>
            <category><![CDATA[hacker-reading]]></category>
            <category><![CDATA[books]]></category>
            <category><![CDATA[computer-books]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 28 Dec 2016 14:10:17 GMT</pubDate>
            <atom:updated>2016-12-29T15:58:16.976Z</atom:updated>
            <content:encoded><![CDATA[<h4>from broad strokes to the lore to the stories to the tangents to the UNIX, these are must reads for every hacker.</h4><p>The tech industry has a bad case of memory loss these days. Luckily, previous generations of the industry (along with journalists and academics) have done a pretty good job of cataloguing and contextualizing our history for us.</p><p>If you have any interest in engaging in or interacting with the tech industry, knowing the history gives you the upper hand. With that in mind, here are my picks for the minimum set of volumes you should read, in order to get a general idea of the important bits of computer history.</p><h4>The broad strokes</h4><p><em>Rise of the Machines</em>, by Thomas Rid</p><p><em>The Information</em>, by James Gleick</p><h4>The lore</h4><p><em>The Devouring Fungus</em>, by Karla Jennings</p><p><em>The New Hacker’s Dictionary</em>, by Eric S. Raymond</p><p><em>Out of Control</em>, by Kevin Kelly</p><p><em>Microserfs</em>, by Douglas Rushkoff</p><p><em>In the Beginning… Was the Command Line</em>, by Neal Stephenson</p><p><em>Man-Made Minds</em>, by M. Mitchell Waldrop</p><h4>Stories</h4><p><em>Turing’s Cathedral</em>, by George Dyson</p><p><em>Hackers: Heroes of the Computer Revolution</em>, by Steven Levy</p><p><em>What the Dormouse Said</em>, by John Markoff</p><p><em>Fire in the Valley</em>, by Michael Swaine and Paul Freiberger</p><p><em>Possiplex</em>, by Theodor Holm Nelson</p><p><em>Weaving the Web</em>, by Tim Berners-Lee</p><h4>Tangents</h4><p><em>The Idea Factory</em>, by Jon Gertner</p><p><em>Interface Culture</em>, by Stephen Johnson</p><h4>UNIX</h4><p><em>The Art of Unix Programming</em>, by Eric S. Raymond</p><p><em>The Unix Haters Handbook</em>, by Simson Garfinkel, Daniel Weise, and Steven Strassman</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The tragedy is that this feature is easy to implement if you work for Medium (or Facebook, or…]]></title>
            <link>https://medium.com/@enkiv2/the-tragedy-is-that-this-feature-is-easy-to-implement-if-you-work-for-medium-or-facebook-or-9f4e3636e421?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/9f4e3636e421</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 29 Dec 2016 15:05:49 GMT</pubDate>
            <atom:updated>2016-12-29T15:05:49.302Z</atom:updated>
            <content:encoded><![CDATA[<p>The tragedy is that this feature is easy to implement if you work for Medium (or Facebook, or Netflix, or whatever) but impossible if you’re a user.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[There’s a culture (and I think it’s a relatively new one — even as recently as fifteen years ago…]]></title>
            <link>https://medium.com/@enkiv2/theres-a-culture-and-i-think-it-s-a-relatively-new-one-even-as-recently-as-fifteen-years-ago-52b636e1dbd1?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/52b636e1dbd1</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 29 Dec 2016 12:47:01 GMT</pubDate>
            <atom:updated>2016-12-29T12:47:01.649Z</atom:updated>
            <content:encoded><![CDATA[<p>There’s a culture (and I think it’s a relatively new one — even as recently as fifteen years ago, these attributes were pretty rare) that devalues context in favor of shallow easy fixes, and I blame at least some of the forces that discourage craft in coding (like boot camps) on this cultural shift.</p><p>Once upon a time, programmers really embraced elitism, which made for an emotionally toxic environment but nevertheless was very effective in encouraging people to absorb the lore. As a result, most people either had a prety deep understanding of a wide variety of ideas (ranging from technical concepts to techniques to purely cultural things like legends &amp; in-jokes) or were excluded. During this era, code was still bad: tools we use to improve the quality of code and make writing high-quality code easier didn’t exist or were barely usable; however, for the most part, people writing abnormally bad code knew that their code was bad &amp; how it was bad, and just wrote it anyway out of laziness.</p><p>We lost some of that toxic elitism, and that’s probably a good thing. On the other hand, it’s not totally gone: it has mutated into a less useful form, where groups of people who are all almost uniformly incompetent form toxic hierarchies based on bogus values because they’re isolated from the greater development community. Additionally, we’ve sort of given up using shame in appropriate ways. Shame is a really excellent tool for encouraging good habits and discouraging bad ones on a community level, and where serious study and careful thinking is of great importance, not using a tool at least as powerful as shame to encourage study and care leads inevitably to a culture dominated by ignorance and carelessness.</p><p>We’ve made a mistake in the way that we’ve smoothed out the learning curves for our industry. We took the pressure off beginners to advance quickly, which is fine, but we allowed beginners to believe they are experts, and now they run bootcamps. We encouraged people to value coding, but we failed to distinguish the value of internalizing the lessons of programming from the value of memorizing how implement simple applications in a single language by rote, and we failed to distinguish the intellectual value of the programming mindset from the economic value of the programming vocation, so we’ve incentivized beginners to teach other beginners simple formulae and allowed them to believe that their limited understanding sets them up to be geniuses and millionaires. Now, we’re surrounded by overpaid beginner programmers writing reams of crap code, and it’s a crisis.</p><p>Writing good code is hard and takes time. Writing a single line of really good code takes years, because you need to study and practice for years before you are capable of distinguishing good code from bad code. Just being mindful in the moment of how much effort you’re putting in is wholly insufficient.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[On the other hand, it seems to encourage rabbitholes.]]></title>
            <link>https://medium.com/@enkiv2/on-the-other-hand-it-seems-to-encourage-rabbitholes-ee83a8a8ef78?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/ee83a8a8ef78</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 28 Dec 2016 15:49:20 GMT</pubDate>
            <atom:updated>2016-12-28T15:49:20.451Z</atom:updated>
            <content:encoded><![CDATA[<p>On the other hand, it seems to encourage rabbitholes. If I click on an article by someone who writes prolifically on the same general group of subjects, the recommendations will send me on a random walk through their works; if I click on an article by someone who primarily interacts with some group of people, I will see mostly the articles from that group.</p><p>This is great if you want to encourage relevance. Sometimes, though, I wish I had a recommendation system that would direct me, specifically, to the opposite: give me what your algorithm would consider the worst possible match. While something like reading roulette will sometimes give me pleasantly bad matches just by including completely random articles (for instance, I once ended up reading an evangelical christian Trump voter’s article about abortion), it’s hard to get a sense for where your overton window lies on the whole spectrum of users just from random entries. Recommending the absolute worst matches might cause some interesting churn, as people are systematically introduced to ideas that any other recommendation system would actively hide from them.</p><p>Systems that exist to serve this niche of people who want to get outside their bubble don’t tend to take full advantage of the network. Something like Rando Carlassian (a bot that tweets news stories randomly from an evenly sized pool sourced from right-wing and left-wing sources) still is limited to fairly conventional sources and can’t take into account anything about the mind of an individual user, so as a result it misrepresents the world such that it presents something like Breitbart as being as far right as people go and Jacobin as being the extreme on the left. The reality is that all ideas have a political dimension and politics are weird and divisive in a fractiline and fortean manner: flat-earthers, hollow-earthers, accelerationists, and people who legitimately believe that the moon is a hologram all exist and sometimes have an out-sized effect on the mainstream because our universe often resembles a kind of absurdist prank gods play on each other. Even mainstream political ideas are unbearably weird if you look at them from an outsider’s perspective.</p><p>A systematic search for pathologically poor recommendations would allow us to immerse ourselves in an outsider perspective tailor-made to detourn our own ideas.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I hypothesize that the chumbox gets populated by items that intersect along the lines of author or…]]></title>
            <link>https://medium.com/@enkiv2/i-hypothesize-that-the-chumbox-gets-populated-by-items-that-intersect-along-the-lines-of-author-or-3ae28e7fe085?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/3ae28e7fe085</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 28 Dec 2016 15:22:20 GMT</pubDate>
            <atom:updated>2016-12-28T15:22:20.292Z</atom:updated>
            <content:encoded><![CDATA[<p>I hypothesize that the chumbox gets populated by items that intersect along the lines of author or tag, ranked by some sort of ‘hotness’ metric (some combination of time since publication, number of recommends, and comments), and that if there are fewer than three items above some arbitrary threshhold cutoff the remaining items are populated using the same mechanism as reading roulette (i.e., hotness plus user’s followed / interacted with tags &amp; authors). I might be way off base, though.</p><p>Medium’s particular chumbox is less offensive than outbrain/taboola, and tends to limit itself to mostly articles that genuinely will be interesting to people who read and were interested in the articles. As a result, I wonder if they’re doing something with recomendation-engine-style statistics; after all, they have not only view statistics but read statistics for all articles, not only tags but suggested tags (along with the training data they use to compute suggested tags from content), and full interaction graphs. They have all the information they need to get really excellent suggestion targetting, and (because there’s nothing remotely resembling monetization) there’s no real incentive for people to spend a lot of effort trying to game recommendations.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The CS/IT world seems to have an unusual absence of understanding of its own history, compared to…]]></title>
            <link>https://medium.com/@enkiv2/the-cs-it-world-seems-to-have-an-unusual-absence-of-understanding-of-its-own-history-compared-to-addefc92eb2c?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/addefc92eb2c</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 27 Dec 2016 13:42:35 GMT</pubDate>
            <atom:updated>2016-12-27T13:42:35.588Z</atom:updated>
            <content:encoded><![CDATA[<p>The CS/IT world seems to have an unusual absence of understanding of its own history, compared to other engineering fields.</p><p>Sure, everybody with a degree is vaguely aware of Turing, and maybe they’re aware of Babbage, Lovelace, and a couple other figures. But, I rarely meet even professionals who are aware of the lineage of the ideas they work with.</p><p>Web developers somehow limit their understanding of the history of hypertext to the idea that Tim Berners-Lee did it, and are unaware of Ted Nelson, Hypercard, NLS, and Memex. Front-end developers repeat the idea that Apple invented the GUI, or repeat the idea that Xerox did, but generally don’t distinguish between WIMP interfaces &amp; other forms of GUIs, and aren’t aware of the landscape of UX going back to Raskin, Licklider, and Englebart, nor are they aware of the way that the Macintosh interface was influenced by the Lisa, the Amiga, GEM, and other contemporary competitors.</p><p>Software engineering culture, at the low end, consists mostly of uncontextualized lore, often repeated and accepted without much consideration. We repeat the maxim that premature optimization is the root of all evil without recognizing the extremely limited context in which the author of that epigram would have agreed with it, nor the fact that the same guy would have wanted every prospective computer programmer to first obtain a doctorate in mathematics.</p><p>The proliferation of fads comes from a broader feeling among the HN crowd that the history of this domain is not worth understanding more than very shallowly, because all valuable ideas lie in the future. As a result, otherwise intelligent people repeatedly reinvent the wheel, not realizing that their great idea was invented, written about, and eventually rejected by someone much smarter than they are in the late 1950s.</p><p>In the sixty years that this field has had a commercial presence, we’ve picked much of the low-hanging fruit. Future progress will be harder, and if we don’t cultivate a culture of understanding history we won’t be able to apply the wisdom of the past to ideas in the present. When breakthroughs in computing were primary academic, this was less of a problem: to get a paper published, you have to cite your references and give a sense of where the new idea fits in the existing domain. In a commercial environment, on the other hand, misrepresenting old things as new and cultivating an ignorance of other related work is encouraged from a marketing perspective — and when your work is VC-funded, marketing is the only thing that matters.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Lots of people don’t — or can’t — distinguish between knowing how to solve simple problems in a…]]></title>
            <link>https://hackernoon.com/lots-of-people-dont-or-can-t-distinguish-between-knowing-how-to-solve-simple-problems-in-a-ac0f5f1ff0bf?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/ac0f5f1ff0bf</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 19 Dec 2016 16:25:10 GMT</pubDate>
            <atom:updated>2016-12-19T16:25:10.984Z</atom:updated>
            <content:encoded><![CDATA[<p>Lots of people don’t — or can’t — distinguish between knowing how to solve simple problems in a specific language &amp; being a programmer.</p><p>Nearly all boot camps seem to lose this distinction, as do people who advocate for computer programming education in schools. Some universities also don’t make this distinction. Most beginner programmers don’t make this distinction, or else falsely believe themselves to have graduated to the other side of it.</p><p>This goes hand in hand with the idea of programming being a primarily vocational skill. The very shallow version of programming is, of course, of only vocational use — and of generally low value.</p><p>Boot camps probably can deliver what they promised, in the sense of producing incompetent, white-belt programmers that will get hired by non-technical HR people (who can’t distinguish between real programmers and white belts) and put into offices full of white-belts, who will crunch away at simple problems until the budget runs out. It’s in line with a lot of the worst practices in the tech industry, insomuch as it involves people who don’t know any better tricking other people who also don’t know any better &amp; pretending everything’s fine until the inevitable collapse.</p><p>I value the other skills developed by programming over actually programming, and I think people would benefit in all sorts of fields that don’t involve programming if they’d learn and apply them. Of course, these skills are hard to test for. It’s very easy for pockets of white belts to develop in any organization, and white belts can’t really conceive of that kind of distinction (and nothing is really a good proxy for it — in part because wage inflation in this sector makes people game everything they can, so proxy measures have a half life of weeks before they must be retired).</p><p>A bootcamp won’t ever do more than give you a white belt, and a bootcamp won’t teach you that a white belt isn’t enough. Bootcamps and schools attract the insufficiently self-directed, who will never graduate beyond the white belt because they don’t really want to learn for the sake of learning. Some of these people don’t feel the need to become competent, because they came for the high wages; when the wage bubble collapses and white belts start being paid like other semi-skilled entry-level white-collar workers, there will be fewer of them.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Lack of political sophistication is often a side effect of being sheltered.]]></title>
            <link>https://medium.com/@enkiv2/lack-of-political-sophistication-is-often-a-side-effect-of-being-sheltered-aca1a429ee3f?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/aca1a429ee3f</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 22 Dec 2016 12:58:01 GMT</pubDate>
            <atom:updated>2016-12-22T12:58:01.062Z</atom:updated>
            <content:encoded><![CDATA[<p>Lack of political sophistication is often a side effect of being sheltered. Of course, the truth is that politics is weird and wild and wooly, and there are more corners to it than most people will ever be able to imagine. (Try explaining the concept of accelerationism to someone who thinks Obama is left-wing.)</p><p>In this sense, our best weapon is mere exposure. Even without attempting to remain civil, and even without bringing up views we necessarily believe in, just exposing people with a limited understanding of the range of political ideas to positions outside their mental models is helpful.</p><p>If someone is pushing an extreme view, push a view you see as extreme in the opposite direction, so that the overton window expands rather than shifting. Expose fascists to anarchocommunism. Expose neocons to negative taxes and neoliberals to deflationary currency. Expose right-wing transhumanists to anarchoprimitivism.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I feel like some of this material is covered in transactional psychology, though my understanding…]]></title>
            <link>https://medium.com/@enkiv2/i-feel-like-some-of-this-material-is-covered-in-transactional-psychology-though-my-understanding-aa25c94ca795?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/aa25c94ca795</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 21 Dec 2016 13:18:26 GMT</pubDate>
            <atom:updated>2016-12-21T13:18:26.829Z</atom:updated>
            <content:encoded><![CDATA[<p>I feel like some of this material is covered in transactional psychology, though my understanding of transactional psychology is heavily influenced by Robert Anton Wilson so this might not be canon.</p><p>You can kick somebody down from object- or meta-level discourse (third circuit thinking, in Wilson’s terms) to tribal-level (second circuit) or stroking-level (first circuit) by being percieved as a threat to identity or to survival, respectively: isolation is treated as an existential threat, and so social strokes are treated as a proxy for being fed and protected by a community. It’s only when someone has bodily comfort that they are able to fully immerse themselves in anything other than stroking-level thinking (and so, people with severe anxiety or with chronic pain often end up alternating between being needy &amp; being standoffish — which makes their situation worse — because the effort it takes to jump up to the meta level and think clearly about how to effectively manage their need for social interaction is much more difficult for them to achieve); it’s only when someone feels like their sense of identity is not under threat from outside that they can be flexible about questioning, changing, or violating it from the inside.</p><p>In other words, when life is shitty, everyone operates with less mental capacity for abstraction, leading to life becoming even more shitty. (There are other variances in individual capability, of course, which means that just because you’re in pain doesn’t necessarily mean you’re completely screwed.)</p><p>This makes for a clear but difficult route toward improving the state of dialogue. Improving general quality of life globally will make clear thinking easier (and though it will not make for rosier topics, it will make it easier to retain emotional distance and avoid engaging in behaviors that are globally counterproductive), but pretty much every existing social or economic system is pinned against an across-the-board increase in quality of life. On the other hand, temporarily excluding the most toxic actors from conversations via shadowbans &amp; similar mechanisms — probably the most reliable method short of improving quality of life — is already done.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A qualified defense of slacktivism]]></title>
            <link>https://medium.com/@enkiv2/a-qualified-defense-of-slacktivism-69c9ea36c12?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/69c9ea36c12</guid>
            <category><![CDATA[activism]]></category>
            <category><![CDATA[slacktivism]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 20 Dec 2016 14:05:07 GMT</pubDate>
            <atom:updated>2016-12-20T14:05:07.884Z</atom:updated>
            <content:encoded><![CDATA[<p>Slacktivism is a failure if you consider it to be a form of activism, but as a form of value signalling, it is terribly effective. We underestimate the value of signalling at our peril.</p><p>Some parts of our moral landscape appear to be biological in origin: a revulsion reaction to the idea of incest, for instance, appears to be the result of the sexual imprint process (and we can tell because siblings separated at birth actually have a much higher likelihood of ending up together, while unrelated children who spend a lot of time living together prior to puberty, even in non-family settings like boarding schools, have unnaturally low rates of sleeping together as adults). Others, however, seem to be primarily controlled by culture, specifically by cultural manipulation of empathy and shame. (We dehumanize enemies in war via propaganda, in order to eliminate the empathy we might normally have toward them &amp; the shame we might hold for killing them, and instead substitute a new set of rules around what kinds of killings are shameful. If the domain over which empathy operated was biologically determined, the flexibility that makes modern warfare possible would not exist.)</p><p>Some people lack empathy (or its effect on them is abnormally low), just as some people lack the in-built biological drive to avoid incest. Shame works to police such people. Ultimately, shame serves to punish people who engage in violations of a culture’s idea of moral behavior by lowering social status (and with it, access to various resources — particularly, other people). While we should still be concerned about sociopaths (who have a strange sort of superpower: their actions are not constrained by the force of empathy, and they lack the self-control to respond reliably to shame), the worst excesses of garden variety empathy-deficient narcissists can be avoided by judicious application of social pressures.</p><p>Value and virtue signalling is a major way in which a culture indicates what behaviors are considered acceptable and what behaviors are not considered acceptable. The other major way in which acceptable behaviors are signalled is punishment; however, punishment requires that the behavior be practiced and the culprit be caught. Value signalling might include describing counterfactuals or hypotheticals about punishment for breach of acceptable behavior (ranging from fantastical visions of hell to fairly concrete legal sentencing guides).</p><p>Slacktivism is a form of weak value signalling, wherein large numbers of people expend small amounts of effort in a token representation of the ideal behavior. While strong / costly signalling would send a more powerful message, it’s not accessible to most people, and so the number of people engaging in it will necessarily always be small. Weak value signalling, at scale, is actually more potent: after all, costly signalling is more desirable both to those with sufficient resources that the marginal cost of signalling is smaller than its apparent cost to its target audience (philanthropists) and those with nothing to lose for whom costly signalling also represents an out (terrorists), neither of whom can be trusted to be an accurate representation of group norms. Mass action, on the other hand, is group norms embodied, and low social cost makes scale possible. As a result, slacktivism allows small changes in moral values to propogate quickly from the majority who already accept them to the minority who haven’t yet, in much the same way as the Game of Life: if you’re surrounded locally by people who send a particular signal, you’re more likely to send that signal, until the signal reaches some saturation point.</p><p>Slacktivism, by changing the collective value system, also encourages acts of costly signalling in the same direction as that weak signal. Popular causes get donations (although the ratio of weak signals to strong signals will always be large).</p><p>Criticisms of slacktivism tend to hinge on the idea that it’s a substitute for activism — that everyone who changes their profile picture to a flag might otherwise be staging a sit-in or assassinating a congressman or otherwise helping make real changes. But, slacktivism is better modeled as a form of collective social control of activism: a means by which various causes have their perceived importance ranked.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[One’s career is rarely a vocation.]]></title>
            <link>https://medium.com/@enkiv2/ones-career-is-rarely-a-vocation-8b6926d7248a?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/8b6926d7248a</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 20 Dec 2016 13:17:21 GMT</pubDate>
            <atom:updated>2016-12-20T13:17:21.251Z</atom:updated>
            <content:encoded><![CDATA[<p>One’s career is rarely a vocation.</p><p>It is not the norm for workers to be filled with purpose by their job; it’s the exception, and one accessible only to those lucky enough to have a lot of freedom to choose positions.</p><p>People who have a sense of purpose will work toward it for free, if it doesn’t interfere with their ability to live comfortably (and sometimes even if it does). This is, after all, what hobbies are: situations where someone spends money in order to do work that nobody is willing to pay them for, simply because they enjoy working.</p><p>The typical worker is performing tasks they despise in order to earn barely enough money to eat. To free them from that toil without taking food out of their mouths is a mercy; it gives them the opportunity to persue a purposeful life.</p><p>Right now, all economic and social incentives are focused on automating the position and simultaneously removing the income, replacing it with nothing. This is cruelty: we’ve taken a person who could already barely survive, and while we’ve removed their ability to survive slightly better by performing a task that makes them miserable, we’ve simultaneously stuck them in a situation where, in order to maintain their ability to eat at all, they must show proof of looking for work while avoiding actually finding any; after all, getting back a job equivalent to the one we automated away means having no income between the benefit cutoff and the first paycheck, and since they were prevented from accruing savings, it means weeks of not eating. UBI targets the welfare trap and eliminates it, making changing jobs less risky for everyone.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[News to me.]]></title>
            <link>https://medium.com/@enkiv2/news-to-me-368fc046efb0?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/368fc046efb0</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 20 Dec 2016 13:03:14 GMT</pubDate>
            <atom:updated>2016-12-20T13:03:14.011Z</atom:updated>
            <content:encoded><![CDATA[<p>News to me.</p><p>The CIA &amp; FBI believe that the leaks were supplied by russian intelligence — which is in line with what most security researchers already believed. It’s not unexpected that the FSB would time a leak to maximize its effect.</p><p>If the CIA &amp; FBI have stated that Wikileaks is complicit in choosing the timing of releases to benefit the FSB’s plan, rather than agreeing that the FSB’s leak timing was appropriate for their own purposes, I haven’t heard that.</p><p>This is, of course, your claim: that Wikileaks is in bed with the Kremlin, instead of being a separate organization with its own goals, some of which may accidentally coincide with other actors.</p><p>I don’t really see any evidence of explicit collusion.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[There are a couple misunderstandings here.]]></title>
            <link>https://medium.com/@enkiv2/there-are-a-couple-misunderstandings-here-286f8ee8cdea?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/286f8ee8cdea</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 19 Dec 2016 16:41:15 GMT</pubDate>
            <atom:updated>2016-12-19T16:41:15.835Z</atom:updated>
            <content:encoded><![CDATA[<p>There are a couple misunderstandings here.</p><ol><li>No serious proposal for fighting fake news involves filtering. Facebook’s proposal involves manipulating ranking (so that spurious articles, which have until lately had an artificially high ranking, will appear lower in the newsfeed than similar real articles) and tagging articles visibly as suspicious, along with an extra dialog when sharing. Likewise, extensions for identifying fake news rely upon tagging. The point is to ensure that people are aware, when sharing an article, that the article they are sharing is from a systematically unreliable source; given the number of people who react with horror to Onion articles, this kind of clear tagging is probably justifiable even on the grounds that obvious satire is not obvious to drunks.</li><li>Satire and detournment will always have a place in discourse. However, they function via an interplay with a consensus reality. The problem with “fake news” is a collusion between large groups of people to create an internally consistent but false version of world events, in order to manipulate people who accept it into performing specific kinds of actions. Presenting a collage of Hitler and Moussolini kissing is very different from creating a media ecosystem of hundreds of sites all geared toward selling people on the idea of drinking colloidal silver, or replacing all their money with gold bullion, or shooting up pizza parlors; for one thing, while the former is easily fact-checked, the latter can only be fact-checked by referring to sources outside of this alternate media universe, which of course are tainted in the eyes of those taken in.</li></ol><p>Art can be very powerful. As a result, we should use it responsibly. If people are dying because of your artwork, then you bear some responsibility for their deaths; likewise, if your artwork led to suffering, the onus is on you. I won’t say that fake news stories can’t be art; I will, however, say that politically charged art doesn’t exist in some pure apolitical universe without consequences.</p><p>If you can’t act responsibly, someone else will take responsibility and recontextualize your art in a way that you may not like; if your community can’t police its own behaviors, then the people your community effects will police them for you.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Any solution that’s ineffective unless 100% of the population is morally upright is unusable.]]></title>
            <link>https://medium.com/@enkiv2/any-solution-thats-ineffective-unless-100-of-the-population-is-morally-upright-is-unusable-a10a7a8c9ad?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/a10a7a8c9ad</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 19 Dec 2016 16:08:06 GMT</pubDate>
            <atom:updated>2016-12-19T16:08:06.525Z</atom:updated>
            <content:encoded><![CDATA[<p>Any solution that’s ineffective unless 100% of the population is morally upright is unusable.</p><p>Any group will contain defectors — cheaters who use the letter of the law against the spirit of the law, and will break the letter of the law too if nobody’s looking. (This isn’t necessarily a bad thing, but it’s a problem when these defectors also lack empathy or morality.) You can’t identify and eliminate these people — for one thing, the ethics of that are pretty muddy, and for another, their main talent is passing as morally upstanding — so any strategy for disincentivising a behavior needs to operate at least in part by making such people fight amongst themselves and prevent each other from engaging in whatever behavior you want to disincentivize. (This is why shame is such a powerful tool: it allows anyone to elevate their status over anyone else so long as that person engages in (or can be made to seem to engage in) some behavior that’s more or less globally accepted as undesirable in the community, so even very morally reprehensible people will shame in a prosocial way because it gives them an advantage.)</p><p>The thing about fake news is that it’s potentially pretty powerful. (It’s also a really vague term, but the variety of fake news that people are concerned about is specifically what’s normally called “disinformation” — mixtures of true and false statements crafted into a narrative designed to cause a specific targetted group of people to engage in some specific behavior. We’re not particularly concerned about staged photos of rats riding crocodiles, or press releases regarding dog brothels, or clear satire, or reports on the recent exploits of Bat Boy, even though all of these things are also fake news.) Anyone who wants to wield power will use the tools at their disposal, and the fact that media has become a very inexpensive tool to wield is probably a good thing since the kind of people who would use it to consolidate power are more likely to fight each other than to collude.</p><p>However, the real power of this kind of fake news is that people spread it because they want it to be true, even if a very small amount of effort would show that it’s false. This is not an accident: disinformation is engineered specifically to appeal to the target audience, so that it spreads.</p><p>I would argue that the best way to slow the spread of disinformation &amp; rob it of its power is to educate people specifically to be significantly more skeptical of anything they want to believe (or that fits with their world-view) than of things that do not. In a media landscape that is in competition with its users, we must reverse Sagan’s maxim: that which is easy to believe (ordinary claims) needs more proof, because what constitutes ordinary has been taken into account (and sometimes engineered) when constructing false messages. At the very least, we must distinguish clearly between claims that are easy to believe for emotional or narrative reasons versus claims that are easy to believe for reasons related to the hard sciences.</p><p>A major flaw in humans is that believing is seeing instead of the other way around: we see evidence of what we believe, and anything that really violates our mental models is mostly invisible. We only see things that we’re looking for, most of the time. This vulnerability is well-known, and all con artists from minor to major take advantage of it. It can be battled with habit.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Supporting this facility is the medium staff’s design decision, sure, but it’s also clearly the…]]></title>
            <link>https://medium.com/@enkiv2/supporting-this-facility-is-the-medium-staffs-design-decision-sure-but-it-s-also-clearly-the-b634e96c1247?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/b634e96c1247</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 16 Dec 2016 17:10:01 GMT</pubDate>
            <atom:updated>2016-12-16T17:10:01.701Z</atom:updated>
            <content:encoded><![CDATA[<p>Supporting this facility is the medium staff’s design decision, sure, but it’s also clearly the wrong decision, if their goal is to built a community for intellectually honest communication.</p><p>Medium made certain design decisions early on that made it seem like they wanted to encourage good content and discourage clickbait: a lack of a facility for reblogs, extremely high maximum content sizes, reading time estimates, a relatively spare &amp; simple design with very limited theming support and no ability to embed ads. Allowing people to reccomend an article without at least scrolling to the end of it is not in line with these other decisions.</p><p>I understand allowing people to recommend articles without registering a ‘read’ — Medium’s reading time estimates are often wildly inaccurate, and when I take five minutes to read something Medium expects to take twenty, I don’t want to wait another fifteen to click that heart. But, even if low-quality recommendations are allowed, we don’t need to cater to them.</p><p>Medium’s general quality seems to have dipped over time, with short, low-effort articles becoming more common or more often recommended. Titles have, in my experience, become more click-baity. Any mechanism that allows people to focus on an engagement metric less stringent than reading is likely to encourage this kind of decay (because, if you give somebody a number, they will do whatever it takes to maximize or minimize it).</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[This essay was more entertaining when Robert Anton Wilson wrote it.]]></title>
            <link>https://medium.com/@enkiv2/this-essay-was-more-entertaining-when-robert-anton-wilson-wrote-it-3a9c6793ed68?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/3a9c6793ed68</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 14 Dec 2016 15:22:23 GMT</pubDate>
            <atom:updated>2016-12-14T15:22:23.856Z</atom:updated>
            <content:encoded><![CDATA[<p>This essay was more entertaining when Robert Anton Wilson wrote it.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[There are different right-wing tribes, with distinct values.]]></title>
            <link>https://medium.com/@enkiv2/there-are-different-right-wing-tribes-with-distinct-values-991578d8b367?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/991578d8b367</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 13 Dec 2016 16:09:56 GMT</pubDate>
            <atom:updated>2016-12-13T16:09:56.425Z</atom:updated>
            <content:encoded><![CDATA[<p>There are different right-wing tribes, with distinct values.</p><p>While the two-party system in the united states encourages us to treat them as a block, the right is no less fractious than the left, and we forget this at our peril. Any political party is a tenuous marginal cease-fire between groups that would otherwise be at each other’s throats.</p><p>Just within the republican party’s core mainstream (not counting the more rare and elaborate forms whose flowering during the Obama administration made them news items), we have several breeds.</p><p>There’s ivy-league conservatives, who are wealthy *and* educated. Generally, they make decisions based on a free-market ideology and a sense that they live in a meritocracy — after all, the system as it exists has elevated them and their family, so it can’t be that wrong. Randian objectivism became a hit with this group way back in the 50s and 60s. Some of the people currently in this group are former hippies who embraced capitalism later in life; others are people who were Birchers in the 60s. Hillary Clinton would be of this group. The unifying attributes of this group are wealth, education, and a belief in the moral good of the free market; secularism varies here but is almost entirely irrelevant, because public shows of faith are in poor taste.</p><p>Then, there’s new-wealth conservatives — people with a blue-collar background who subscribe to the same belief in free-market ideology and meritocracy, but without most of the cultural and intellectual trappings as the ivy-league conservatives. The first generation of any lineage in this group would, generally, be someone who worked up from a lower-middle-class background and became wealthy, and believes themselves to have become wealthy due to Horatio Alger style preserverence rather than through luck. Objectivism landed here in the 70s and 80s, where it cast off some of its anti-religious aspects. The children of the lineage can become ivy-league conservatives if they are taught to respect tradition and ettiquite, but otherwise remain new-wealth conservatives. Donald Trump is of this group. The unifying attributes of this group are wealth, a focus on the idea of meritocracy, a lack of “taste” and “subtlety”, and a distain for people who they see as “cheating”.</p><p>You also have the rural poor, who may be one or the other but are often both. They work off a model of the new-wealth conservatives, and are often explicitly against the ivy-league conservatives. The religious sentiment and anti-intellectuallism usually is focused in this group. Objectivism came to this group via the prosperity gospel in the 80s and 90s, and this group doesn’t generally associate it with anti-theism.</p><p>Among the new types (which are not necessarily new, but are instead newly important), we have:</p><p>Accelerationists — marxists who believe that the best way to bring about a communist utopia is to be as capitalist as possible, so as to hasten the inevitable breakdown. They may consider themselves leftists, but they behave in a way that is indistinguishable from the far-right.</p><p>Neoreactionaries — people with a nostalgia for an idealized version of centralized absolute power. A lot of them think that the best way to bring about the emergence of a global centralized power is to make democracy &amp; capitalism collapse by exploiting the flaws in the existing structure, so as a result neoreactionaries and accelerationists are in alignment in working together in acting economically far-right despite not believing in economic far-right policies.</p><p>The ‘alt-right’ — a mix of various smaller groups, mostly dominated by people who subscribe to a dumbed-down version of the neoreactionary ideology, with some of the anti-capitalist stuff removed. The alt-right is neither intellectual nor anti-intellectual but pseudo-intellectual; as a result, they are at odds with both the anti-intellectuals (because they consider themselves intellectual) and the intellectuals (because they’re resistant to examining their beliefs). They circulate material from neoreactionaries without having a clear understanding of it. Often they have a perspective that combines objectivism in its anti-theistic dimension with social darwinism and scientific racism. They are not neo-nazis, because they don’t really have an interest in tradition. There are lots of engineers in this group.</p><p>Right-libertarians — a mix of objectivists of various stripes, people whose fully justified paranoia about government (as the best-armed group in their vicinity) can be easily overwhelmed with invented paranoia about foreign invaders, and people who simply have a much greater faith in free markets than in other social constructions. This group was part of ground zero for objectivism in the 50s and 60s, when libertarianism was mostly undifferentiated, and starting in the 90s this group had an influx of people from the much more religious “rural poor” group. I classify anarchocapitalists under this banner, no matter how much they might complain. Sole unifying attribute: distrust of power.</p><p>Actual neo-nazis — these guys never went away. Social darwinism, traditionalism, and pretty explicit anti-intellectualism, with a strong racial &amp; xenophobic component, characterize this group. They haven’t been part of mainstream discourse or a large block for a long time, but some of their ideas get circulation via other groups.</p><p>Right now, you can’t win an election by targetting only one of these groups. To win, you need to at least get the big three older groups. Some of the newer groups are gaining numbers and power, particularly in places like California.</p><p>If you go to a university, the conservatives around you will generally not be of the rural poor variety: a university education would be expensive and of dubious value to that group. All other groups (with the exception of the neoreactionaries, who consider universities to be a propaganda outlet for democracy and capitalism, and neo-nazis, who consider universities to be smearing the good name of Hitler) would be well-represented at universities; accelerationists would actually be overrepresented — there aren’t many of them, but they are all university-educated and most have been university-employed.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I wonder how much of this effect has to do with the mixture of pseudo-neutral & centralized media…]]></title>
            <link>https://medium.com/@enkiv2/i-wonder-how-much-of-this-effect-has-to-do-with-the-mixture-of-pseudo-neutral-centralized-media-924736ee207c?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/924736ee207c</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 13 Dec 2016 15:20:30 GMT</pubDate>
            <atom:updated>2016-12-13T15:20:30.180Z</atom:updated>
            <content:encoded><![CDATA[<p>I wonder how much of this effect has to do with the mixture of pseudo-neutral &amp; centralized media we have.</p><p>The long tail didn’t really address the rich-get-richer trend in even random distributions. (If you have a bunch of evenly connected nodes, all of which randomly decide whether or not to share a signal they recieve with their peers, you get a hockey stick distribution. If some signal starts off with a positive bias, that bias grows enormously. And, if connections are allocated the same way, the number of connections between nodes has the same asymmetry.) If we have a mix of curated, centralized media that promotes some particular figures (and particularly if those figures are promoted toward highly connected clusters of people), we’ll see a much larger growth in the popularity of those figures than we would in a purely centralized context.</p><p>On the other hand, the greater the influence of neutral carriers, the easier it is for whole groups to become less affected by some popular figures. I have never heard a song by Drake, Beyonce, Rihanna, or Adele; in 1993, I would have definitely heard any artists of similar popularity, because the only way to discover music would have been radio and television — in other words, curated broadcast media. Because I don’t listen to the radio or watch television, my taste is music is mostly formed by the tastes of my peer group — and presumably many of them have heard those artists but haven’t found them impressive enough to convince their peer group to engage with them (the way that they would for Bablicon, or Skinny Puppy, or other groups that are much more obscure on the global scale but are much more popular in particular groups).</p><p>When we look at the head in isolation, we sort of miss the point, which is that favoring organic communication of tastes over broadcast both raises all ships &amp; slightly flattens the distribution. The long tail is longer and fatter, but the head is also higher, because the communication between preferences &amp; the things that fulfill them is more efficient &amp; tastes can evolve more quickly in a resource-rich and diverse environment. Someone who really only likes free jazz or ambient harshnoise would have, in 1993, thought they “didn’t like music”, but now has a much greater likelihood of being exposed to these much less globally popular genres.</p><p>(This is not to propose either preference-essentialism or some kind of free market optimism. Preferences evolve in response to experience, and this kind of evolution only happens when the marginal cost of exposure approaches zero. The long tail is made profitable only because piracy has expanded the domain before it, creating a market of savvy and dedicated people willing to spend money on obscure things where before there was only a hostile and alien environment.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[With regard to sample size, small sample sizes in studies that are taken at face value is an issue.]]></title>
            <link>https://medium.com/@enkiv2/with-regard-to-sample-size-small-sample-sizes-in-studies-that-are-taken-at-face-value-is-an-issue-12c0b237d9a6?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/12c0b237d9a6</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 05 Dec 2016 17:38:36 GMT</pubDate>
            <atom:updated>2016-12-05T17:38:36.271Z</atom:updated>
            <content:encoded><![CDATA[<p>With regard to sample size, small sample sizes in studies that are taken at face value is an issue. Your example of small sample sizes in the context of less-serious exploratory research would not be the kind of thing that would get press, unless someone then treated that exploratory research as canon.</p><p>My understanding of the replication crisis, however, comes from people like Goldacre &amp; Neuroskeptic who write frequently about the subject; their coverage focuses on systematic distortions in scientific literature related to perverse incentives. Your post here is the first one I’ve seen that situates it as a problem related to specific studies misleading primarily other scientists in the field. I’d be interested in knowing what articles in particular you’re complaining about, because the suggestion that any single exploratory study in isolation is a problem (outside of the tendency for the science press to hype low-quality studies) tends to be dismissed early in the coverage I’ve read. (In other words, I’ve only seen this framed as a systematic incentive problem, where scientists are discouraged from performing certain forms of vital tasks, such as large-scale replications with large samples.)</p><p>Thanks to your response, I’m more willing to treat the article in good faith, but my alarm bells started going off specifically because the model you present of the reasons behind the replication crisis is one that is explicitly rejected in the pro-replication-movement pieces I thought were seminal.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[There’s a tradeoff to code reuse, insomuch as code written for a different problem is often a poor…]]></title>
            <link>https://medium.com/@enkiv2/theres-a-tradeoff-to-code-reuse-insomuch-as-code-written-for-a-different-problem-is-often-a-poor-d5a6b67f902d?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/d5a6b67f902d</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 05 Dec 2016 17:12:08 GMT</pubDate>
            <atom:updated>2016-12-05T17:12:08.760Z</atom:updated>
            <content:encoded><![CDATA[<p>There’s a tradeoff to code reuse, insomuch as code written for a different problem is often a poor fit.</p><p>Using someone else’s code often requires writing wrapper code to change how certain things work; often, particularly if you have unusual scale requirements or are doing other things that invalidate common assumptions, you will end up writing more code to use someone else’s library than you would be if you just implemented the functionality they provide yourself. Of course, if you are performing a very common task under very common constraints, using the same software as your competitors makes sense; it’s only when you go outside the normal range that things begin to fall apart &amp; natural choices start to make less sense than strange choices.</p><p>Take, for instance, search. ElasticSearch is a pretty polished and reliable system — as long as you’re not pushing up against any hardware resource limits on your cluster, because running out of ram or hard disk space on any single node on even a large cluster can cause invisible data corruption &amp; cascading failures. In other words, if your scale is normal ES makes sense, but if you have too much data and you want to wring more performance out of your hardware, you’ll want to homebrew something.</p><p>Using platforms whose facilities you don’t benefit from is how ecosystems like hadoop become nightmares. Hadoop makes sense on paper for a small set of very specific problems — bioinformatics stuff, and other situations where doing a small amount of simple math on very large numbers of very small wholly independent records is necessary. Outside of that domain (if your total amount of data is too small, or individual records are too large, or you have too many machines, or too few machines, or if the data is insufficiently independent), using hadoop on a thousand machines is usually slower than running simple command line tools on a single machine. Nevertheless, people attach to hadoop because they feel like they need power, and start using systems like hive (an RDBMS is the absolute last thing you want to integrate with a map reduce system), and suddenly something that would normally be a single line of shell and run in 30 seconds on your laptop becomes eight hundred lines of java and runs for eight hours on a four hundred node cluster.</p><p>In other words, often what matters is not writing less code but running less code, and often that involves avoiding using potentially useful libraries when they will add rather than remove complexity. Determining whether or not running someone else’s code is appropriate is complicated and can require a deep familiarity with the behavior of the library: usually, the best way to determine whether or not a library is worth using is having had already written something very similar yourself &amp; knowing from experience how easy or hard certain things are to implement (along with knowing from experience the pitfalls of different implementations) — in other words, unless you’ve reinvented the wheel, you’re at a disadvantage when shopping for the car.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[This article sort of represents a straw-man version of the reproducability crisis.]]></title>
            <link>https://medium.com/@enkiv2/this-article-sort-of-represents-a-straw-man-version-of-the-reproducability-crisis-df80d2dac194?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/df80d2dac194</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 05 Dec 2016 16:18:10 GMT</pubDate>
            <atom:updated>2016-12-05T16:18:10.740Z</atom:updated>
            <content:encoded><![CDATA[<p>This article sort of represents a straw-man version of the reproducability crisis.</p><p>Any serious article on the subject does not focus on the correctness of individual studies, but instead on the absence of published replication attempts for landmark studies. It’s precisely because science is hard &amp; false positives are common that the low rate of reproduction attempts, the tendency to avoid publishing negative results, and (on the science journalism side) the naive acceptance of shocking-sounding results are so damaging at scale.</p><p>Will teaching general audiences &amp; science journalists about the variety of potential statistical &amp; methodological flaws help? Sure — at least with respect to the science journalism side. It won’t help with the acceptance of false positives due to selection bias (which led to people like Kanneman putting a lot of trust into ideas like cultural priming that ended up being completely unreproducible).</p><p>Anyone with an interest in science knows that without high-quality replication &amp; large, randomized samples, results are meaningless. This is not to say that small-scale exploratory studies are not worthwhile, but instead that such studies should be treated as one step above opinion columns with regard to how seriously they should be taken.</p><p>There are also real reasons why scientists end up having research and publication habits that encourage bad science; we can’t pretend these reasons don’t exist, but they are economic/incentive-related reasons, and new incentives are easily introduced into science if somebody has the money.</p><p>Providing funding for pre-registered replications seems like it’s likely to solve many of the problems that people have with the state of experimental psychology (and if you don’t agree that those problems exist, you don’t have to participate in such programs: you can leave the money on the table, and instead watch other people attempt to replicate your work); likewise, automatic stats checkers are pretty uninvasive: if you avoid mathematical errors, you won’t get a lot of notes, and if you disagree with the notes you can ignore them and wait to be vindicated. These are systems that already exist, and are already being used to change incentive systems in experimental psychology in order to compensate for common sources of concerns.</p><p>Individual experiment sample sizes were never the point of the replication crisis, except when experiments were being taken significantly more seriously than they should be, which is not unusual.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[It’s very strange that widespread high-speed internet access would coincide with increasing…]]></title>
            <link>https://medium.com/@enkiv2/its-very-strange-that-widespread-high-speed-internet-access-would-coincide-with-increasing-5038cf57597d?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/5038cf57597d</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 05 Dec 2016 14:49:33 GMT</pubDate>
            <atom:updated>2016-12-05T14:49:33.690Z</atom:updated>
            <content:encoded><![CDATA[<p>It’s very strange that widespread high-speed internet access would coincide with increasing urbanization.</p><p>After all, one of the major utilities of this kind of communication tech is that geography becomes much less important: why bother moving to be closer to people who you’re mostly going to talk to on twitter anyway? One would, naively, think that we would end up with (within any given locality) greater ideological diversity: today, someone in a rural area surrounded by conventional republicans can discover fringe political ideas like accelerationism and adopt them — something that really couldn’t have happened in the 1980s. Why doesn’t this happen?</p><p>Perhaps it does happen, but confirmation bias leads us to both ideological and physical self-segregation? People who discover fringe leftist ideas will migrate to blue areas where those physically nearby are more open to these ideas, while people who adopt fringe rightist ideas will move to red areas. (This also explains blue oasis areas surrounded by red, like Atlanta Georgia and Austin Texas, both of which have become abnormally influential as cultural centers.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The problem of a lack of free public indoor spaces isn’t limited to New York City; I live in…]]></title>
            <link>https://medium.com/@enkiv2/the-problem-of-a-lack-of-free-public-indoor-spaces-isnt-limited-to-new-york-city-i-live-in-9d9277e5ddc7?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/9d9277e5ddc7</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 02 Dec 2016 14:40:32 GMT</pubDate>
            <atom:updated>2016-12-02T14:40:32.342Z</atom:updated>
            <content:encoded><![CDATA[<p>The problem of a lack of free public indoor spaces isn’t limited to New York City; I live in suburban Connecticut, and (barring public libraries, and the occasional bus shelter or other wall-less structure on public land) indoor spaces accessible to the public are either retail spaces or member-supported ‘clubs’ with limited access (often, non-members are allowed in only by invitation or are only allowed during particular time periods).</p><p>I get the impression that in the past (say, prior to 1950) public spaces were more common and more vital, with community organizations like clubs, churches, and lodges being less closed-off simply because socialization and other forms of entertainment for those without any money was necessary. Salon parties &amp; coffee houses also catered to this use case, and it seems like coffee houses would cultivate social groups and bring in events like scientific demonstrations &amp; political speeches during the nineteenth century, as a means of drawing a crowd some of whom would purchase coffee, the same way that bars will occasionally bring in gratis musical acts. By the 1960s, at least from the perspective of europeans, these spaces were already gone or commercialized: the concept of a shopping mall was created specifically to produce european-style public spaces in the united states, with shops and commerce being in the original conception an unimportant side-effect &amp; features like benches, squares, and food courts being more central. (Of course, shopping malls essentially suffered through a very long bubble, as a result of real estate loopholes; they were everywhere and extremely commercialized up through the early 90s, at which point they started going out of business.)</p><p>The best idea I can think of for bringing back public spaces is to expand &amp; publicize the low-key social spaces that already exist in or associated with libraries: libraries are already indoors, and they already essentially deal with people, but most social spaces in libraries in my experience are exclusive &amp; by reservation only; with good sound-proofing &amp; clever layout, social spaces &amp; quiet spaces within a library can be segregated and the kind of free-wheeling nineteenth-century-coffee-house experience can be reconstructed to some extent.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Monochrome Vertex Ch. 1]]></title>
            <link>https://medium.com/@enkiv2/monochrome-vertex-ch-1-4c0f06b94e9f?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/4c0f06b94e9f</guid>
            <category><![CDATA[fiction]]></category>
            <category><![CDATA[science-fiction]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 30 Nov 2016 16:04:00 GMT</pubDate>
            <atom:updated>2016-12-02T13:15:21.506Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p><em>A few years ago, I started writing a story set in a world where the GUI was never invented — a world with cultural norms and economic pressures shaped by different technological trends. I never finished it, but I will post the first 2 parts here.</em></p><p><a href="https://medium.com/@enkiv2/monochrome-vertex-chapter-2-fea35b9a0224#.d7qm9tp16"><em>Chapter 2</em></a></p><p>The scant light through the venetian blinds gleamed against the machine on the table. It was a luxury model produced by Texas Instruments, but clearly based on the GRiD and QL in industrial design: a sharp-edged clamshell, it now resembled a set of precision-machined wedges, but closed it would resemble nothing more so than a small steel briefcase. It seemed vaguely out of place on the expanse of the dark mahogany desk. Behind the VP sat an equally expensive dark mahogany bookshelf, one shelf dominated by a sparse row of carts, each probably a whole gigabyte (though it is inconceivable that the VP could have so much to store) and designed to look like extremely short leather-bound books. The other shelves were full of non-solid-state media: tapes, magnetic disks, and even a few optical disks.</p><p>“Could you give me the condensed version, Mr Logan?” The VP looked at the printed report as though it was a rotting snail.</p><p>Dex kept himself from sighing. “Well, your network security is good.” The VP nodded solemnly, and Dex suppressed a smile. “But, that doesn’t really matter because your personnel training sucks. I tailgated into the building and bluffed my way into the air-gapped network.”</p><p>“And the files?”</p><p>“The evidence has been uploaded to a public FTP in the Caucus Republic. The hostname is in the report.” Dex stood for a while in silence.</p><p>The VP made chewing movements with his mouth. Nervous habit? “I’m not paying you by check,” he said finally. “The agreed-upon sum has been wired to your account as of this morning.”</p><p>“That is highly ir-”</p><p>“Goodbye, Mr Logan.”</p><p>Dex took the hint.</p><p>–</p><p>The noodle shop was busy, as always. Soon, Dex would be bustled out. He curled his hand around the china bowl protectively, and peered at the television across the room, machine generated closed-captions scrolling across the bottom of the screen in a language not entirely unlike English: “…FRANKLIN-KYOCERA RELEASED NEW CLAMSHELL WILL CLAMSHELLS TAKE OVER FILM AT ELEVEN IN OTHER NEWS ARCTEK DOWN TEN POINTS IN RESPONSE TO LEAKS ABOUT TUESDAY PRESS RELEASE LETS TALK TO EXPERT JAMES JAMES ROGERS WHAT DO YOU THINK OH ARCTEK HAS ALWAYS BEEN…” Dex reached into his coat in search of a toothpick, hand brushing a small bottle of amphetamines. “…WOZNIAK CLAIMS NEXT-GEN OS DOES NOT VIOLATE GPL TERMS COULD THIS BE STALLMANS REVENGE FOR…”</p><p>“Three fifty, please.” The young woman seemed pleasant. She must be new.</p><p>“…SAYS CEO NELSON AND NOW BREAKING NEWS VICE PRESIDENT OF PROGRAM DATA CORPORATION MISSING PRESUMED DEAD AFTER BOATING ACCIDENT THIS MORNING GREEK AUTHORITIES CONTINUE TO SEARCH…”</p><p>“Motherfucker.”</p><p>“I’m sorry?”</p><p>Dex swallowed. “Sorry, not you. Here,” he handed her a twenty. “Keep the change.” He pulled off his pager and dropped it in the trash can on the way out.</p><p>Turning his collar up, Dex crossed the street and then turned sharply into the subway stairwell. He used his Metro card to reserve a spot for Coney Island, then walked to a neighboring counter and bought a ticket to Grand Central. He slipped the Coney Island ticket into the crack between two empty bricks in the tunnel, then took the next trip to Grand Central. From there, he took the train to Albany.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I don’t have any problem with self-help articles per-se, but I definitely have a problem with…]]></title>
            <link>https://medium.com/@enkiv2/i-dont-have-any-problem-with-self-help-articles-per-se-but-i-definitely-have-a-problem-with-18550d4051a2?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/18550d4051a2</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 01 Dec 2016 14:03:00 GMT</pubDate>
            <atom:updated>2016-12-01T14:03:00.441Z</atom:updated>
            <content:encoded><![CDATA[<p>I don’t have any problem with self-help articles per-se, but I definitely have a problem with unoriginal content — and none of these articles told me anything I hadn’t heard twenty years ago. (I am twenty-eight, and I don’t think I was an especially well-read eight year old.)</p><p>Tell me something I’ve never heard before. I don’t care if it’s stupidly wrong. In fact, maybe it’s better if it’s wrong.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Monochrome Vertex Chapter 2]]></title>
            <link>https://medium.com/@enkiv2/monochrome-vertex-chapter-2-fea35b9a0224?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/fea35b9a0224</guid>
            <category><![CDATA[science-fiction]]></category>
            <category><![CDATA[fiction]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 30 Nov 2016 16:05:08 GMT</pubDate>
            <atom:updated>2016-11-30T16:05:34.791Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p><em>Chapter 1 is </em><a href="https://medium.com/@enkiv2/monochrome-vertex-ch-1-4c0f06b94e9f#.9oz2j0axu"><em>here</em></a></p><p>Dex was already ducking under the fence by the time he saw the sentry. It was an Arctek machine, top of the line perhaps half a decade ago, subtly modified and equipped with a sonic stunning device (nonfatal, but exceedingly unpleasant — developed for crowd control by the Argentinian equivalent of DARPA). “Identify yourself,” it said.</p><p>“Dexter Logan. I’m here to see Tom.”</p><p>The robot buzzed quietly for a moment, and Dex noticed that the Cicadas were out. “Dex!” The tone was familiar — a synthesized simulacrum.</p><p>“Tom? Quit fucking around and call off the bot.”</p><p>The robot swung its sonar apparatus smoothly back and forth, in a crude mimicry of a person shaking its head. “I’m not fuckin’ with you, Dex. It’s been a while. Ten minutes?”</p><p>“Eleven,” Dex said.</p><p>“Eleven candles candles,” the robot said. “Candles candles candles candles candles candles. Candles eleven of them.”</p><p>“Fuck.” Tom’s a broken robot, thought Dex. Just then, a figure surfaced from within the long grass.</p><p>“Dex, my man. Come with me.”</p><p>Dex followed Tom, and the robot trailed a few feet behind, still stuck in its verbal loop. “Some kind of fluke in my model traversal,” Tom said. “Fucker works just fine until suddenly it decides some word or phrase links to itself with a probability of one. Sometimes it matches my patterns enough to get registered as me, and then I have to go in and delete the bullshit from the database by hand.”</p><p>The farmhouse was small and old, but it offered shade from the unseasonably warm weather. The table was piled chest-high with second-hand junk. Scavenged robot chassis sat under it, sometimes on the floor and sometimes on chairs. The shaded lamp hanging from the ceiling had its power cable extracted, cut, joined with a pair of plastic caps, and cut again further down. Tom brought in a pair of stools from an adjoining room.</p><p>“It’s been a while. What, ten minutes?”</p><p>“Eleven.”</p><p>“Eleven. What can I do for you?” He glanced at the cupboard. “A beer, maybe?”</p><p>“I’m afraid this isn’t a social visit. I need your help.”</p><p>Tom got up abruptly. “I think I’m gonna need a beer, then.” He found a reasonably clean glass and cracked open a can of lukewarm beer, then settled down and took a long swig out of the can, not bothering to pour. “Okay, shoot.”</p><p>“I got fucked over, Tom.” Dex sighed.</p><p>“Infringement, again?”</p><p>“Fuck no.” He grimaced. “Five minutes for that shit, and I wasn’t even doing it — just running the BBS. Staying straight now. Pen testing. Figured that was the way to go — using my skills but no chance of getting locked up.”</p><p>“So?”</p><p>“So, I think maybe I’ll need that beer after all.” While Tom got up, Dex took another look around. There were cameras and microphones everywhere. Through the crack in a half-opened door he glimpsed a bank of closed circuit television monitors. “You recording this shit, Tom?”</p><p>“I record everything. Turns out that’s the only way to get believable responses.” He put a much cleaner glass down on an empty spot on the table and poured an equally warm beer into it. Dex looked at it as though it might contain more cameras.</p><p>“I did pen testing yesterday for Tim Dolby.”</p><p>“The VP of Program Data?” Dex nodded. “But, yesterday…”</p><p>“I know. There’s more.” Dex paused. “Whatever scam he’s pulling, he had me steal some files for him and fence them overseas.”</p><p>“What files?”</p><p>“I don’t know, man.” Dex took a swig of his beer. He got mostly hot foam. “I just know the filenames, and those were UUID. Base 64 shit.”</p><p>Tom began fidgeting with his pen. A few minutes as cell mate had left Dex with an understanding of this man’s nervous habits, and he felt apprehension.</p><p>“So a guy fakes his death, steals some files, frames you… And you run to me?” A whine crept into his voice. “You think I ain’t got enough problems as is?”</p><p>“I covered my tracks as Most Unexceptional I could.”</p><p>“Still–” he took a deep breath and calmed slightly. “Where overseas?”</p><p>“The Caucuses.”</p><p>Tom sighed. “You just got fuckin’ lucky, man.” Dex stared blankly. “What, haven’t been watching the news?” He took a device out of his pocket and flicked on a small CRT hidden amongst the bric-a-brac on the far side of the room.</p><p>“…IN THE CAUCUSES HAS HAD A MAJOR EFFECT ON OIL PRICES IN ADDITION TO OLYMPIC PLANS. THE UNITED NATIONS HAS SIGNED A DECLARATION TO SUPPORT THE REBELS AGAINST THE INTERIM…”</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A short glossary of tech industry terms]]></title>
            <link>https://medium.com/@enkiv2/4b5f9fef8db3?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/4b5f9fef8db3</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 30 Nov 2016 14:00:53 GMT</pubDate>
            <atom:updated>1970-01-01T00:00:00.000Z</atom:updated>
            <content:encoded><![CDATA[<p>Enterprise-grade: slow and broken</p><p>Enterprise ready: once reached the front page of HN</p><p>Script: a small segment of someone’s shell history</p><p>Software engineer: a programmer with a bachelor’s degree</p><p>Software engineering: writing code that doesn’t need to exist, but writing it in Java</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[An alternate web design style guide]]></title>
            <link>https://hackernoon.com/an-alternate-web-design-style-guide-1aae8d0b5df5?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/1aae8d0b5df5</guid>
            <category><![CDATA[web-development]]></category>
            <category><![CDATA[web-design]]></category>
            <category><![CDATA[css]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 29 Nov 2016 17:34:31 GMT</pubDate>
            <atom:updated>2016-11-29T17:34:31.287Z</atom:updated>
            <content:encoded><![CDATA[<ol><li>Don’t use CSS or Javascript. These technologies exist to help a web browser poorly simulate a native app; if your goal is to simulate a native app, you’re better off just writing one.</li><li>Web sites are, ideally, static hand-written HTML. Sometimes, it makes sense to write plain text and then write a short shell script to convert to static HTML. You don’t need a database, or server side scripting; if you do, write a native app.</li><li>Don’t specify fonts or colors. Browsers provide the capability for users to configure default fonts and colors; if the user prefers something other than their current default, trust them to change it.</li><li>Don’t specify alignment, except with respect to table elements. Eschew purely aesthetic distractions like page breaks, drop quotes, and tenuously related images. The user came here to read: let them.</li><li>One document per page, please. If you write a whole book, the whole book should be on that page.</li><li>Eschew sidebars. If you need a navigation menu, a top or bottom bar is fine: it’s easier to implement, and doesn’t interfere with the flow of text.</li><li>Use only the following tags: a, b, body, br, center, h1, head, i, li, ol, p, table, th, title, td, tr, ul. All other tags are unnecessary distractions. If, for some reason, you <em>must</em> include images, the img and align tags are also suitable.</li><li>Embedded markup is, within the context of the web, a necessary evil: as it stands now, without it hyperlinks aren’t possible within a web browser. Use it as little as possible, and make sure that it can be easily eliminated so that when external markup becomes widely available the transition is easier.</li><li>Any web page should be written so that it is usable and understandable with a text-only browser that does not preserve spacing. In other words, text formatting, images, and position on the page should never contain essential information. If you cannot strip all tags and get a nearly equivalent experience from reading non-tag content as a contiguous stream of text, you have failed to make an accessible web page.</li></ol>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Soylent definitely wins, when the choices are between Soylent, a candy bar, and nothing at all.]]></title>
            <link>https://medium.com/@enkiv2/soylent-definitely-wins-when-the-choices-are-between-soylent-a-candy-bar-and-nothing-at-all-64a020d253ad?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/64a020d253ad</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 29 Nov 2016 16:47:41 GMT</pubDate>
            <atom:updated>2016-11-29T16:47:41.532Z</atom:updated>
            <content:encoded><![CDATA[<p>Soylent definitely wins, when the choices are between Soylent, a candy bar, and nothing at all. I often have a hard time getting through to people who resist the idea of meal replacement fluid for cultural reasons, since these people typically have never felt the complete loss of drive that makes me resistant to even microwave meals. (In my case, it’s not depression so much as a mix of sub-clinical mania &amp; some executive function issues, but the result is the same: I’ll go days without eating properly, subsisting on chocolate or microwaved hot dogs or something, and if I’ve got something like Soylent then the absolute least-effort thing to eat is also the healthiest thing in the house.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[There seems to be the assumption that “fake news” shouldn’t be consumed.]]></title>
            <link>https://medium.com/@enkiv2/there-seems-to-be-the-assumption-that-fake-news-shouldnt-be-consumed-f78ff6257691?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/f78ff6257691</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 29 Nov 2016 16:33:00 GMT</pubDate>
            <atom:updated>2016-11-29T16:33:00.210Z</atom:updated>
            <content:encoded><![CDATA[<p>There seems to be the assumption that “fake news” shouldn’t be consumed. I disagree entirely. It’s fine to have a list of sites that have mostly “fake” news, because you should be critical of (and, preferably, perform some fact-checking on) everything you read, and having a list of sources for which you have reason to treat with more skepticism is probably a good idea — particularly since recycling stories without fact-checking is a common behavior among low-budget outlets, so you should always be backing up anything with some source that are not on the list.</p><p>(The Daily Dot does some quality journalism; I’ve been reading their stuff for several years now. They also occasionally publish pieces that are shallow or subtly incorrect — but so does the New York Times &amp; Wired.)</p><p>You shouldn’t avoid fake news. In fact, you should go out of your way to read fake news. But, you should also go out of your way not to trust anything — especially things you already agree with.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[News and Lies 1: In Defense of (some) Propaganda]]></title>
            <link>https://modernmythology.net/a-qualified-defense-of-fake-news-3a1a31b0168a?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/3a1a31b0168a</guid>
            <category><![CDATA[fake-news]]></category>
            <category><![CDATA[essays]]></category>
            <category><![CDATA[journalism]]></category>
            <category><![CDATA[politics]]></category>
            <category><![CDATA[culture-jamming]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 23 Nov 2016 17:50:25 GMT</pubDate>
            <atom:updated>2016-11-28T18:20:18.631Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*6S422HmqkHKwGFxbNhGaQw.jpeg" /></figure><p>There’s been a lot of blow-back regarding fake news — which is to say, fiction using the style of news stories and disguised as news stories — since Trump’s election. <a href="https://www.washingtonpost.com/news/the-intersect/wp/2016/11/17/facebook-fake-news-writer-i-think-donald-trump-is-in-the-white-house-because-of-me/">The general premise is</a> that false news stories circulated among the communities dominated by Trump supporters bolstered their support of him, and of course social media was leveraged to an almost unprecedented degree by his campaign.</p><blockquote>“Our biggest incubator that allowed us to generate that money was Facebook,” says Parscale, who has been working for the campaign since before Trump officially announced his candidacy a year and a half ago. Over the course of the election cycle, Trump’s campaign funneled $90 million to Parscale’s San Antonio-based firm, most of which went toward digital advertising. And Parscale says more of that ad money went to Facebook than to any other platform.</blockquote><blockquote>“Facebook and Twitter were the reason we won this thing,” he says. “Twitter for Mr. Trump. And Facebook for fundraising.”</blockquote><p>At the same time, even politically-charged fake news has a powerful capability to aid us in the pursuit of truth. This seems paradoxical but isn’t necessarily so, as I’ll explore.</p><p>We should not ignore this history, but we should analyse what makes the standard discordian fake news different from the stuff that people are currently concerned about.</p><blockquote>[C]ulture jammers […] introduce noise into the signal as it passes from transmitter to receiver, encouraging idiosyncratic, unintended interpretations. Intruding on the intruders, they invest ads, newscasts, and other media artifacts with subversive meanings; simultaneously, they decrypt them, rendering their seductions impotent. Jammers offer irrefutable evidence that the right has no copyright on war waged with incantations and simulations. And […] they refuse the role of passive shoppers, renewing the notion of a public discourse. — <strong><em>“</em></strong><a href="http://project.cyberpunk.ru/idb/culture_jamming.html"><strong><em>Culture Jamming: Hacking, Slashing, and Sniping in the Empire of Signs</em></strong></a><strong><em>,” The Open Magazine</em></strong></blockquote><p>I should clarify that I will not be focusing on the distinction between satirical fake news and fake news made to be believed. Satire is of great value — there’s not just a cultural or propaganda value to satire but also a concrete procedural value to it — but we don’t solve all our problems by clearly indicating that certain stories or sites are fictional or satirical, and there’s a lot of good that can come out of fake news that isn’t clearly satire. (Furthermore, this doesn’t move us away from the problem of people sharing it uncritically and believing it, as anyone whose grandmother has forwarded them chain emails about Onion stories can attest.)</p><p>The history of using fake news for explicitly political purposes goes back a long way, but the current state of the art in this domain can probably be attributed to Paul Linebarger’s book <em>Psychological Warfare</em> — a description of US propaganda activities during the second world war, used as a training manual for the US army.</p><p>Linebarger’s advice is fairly straightforward, and forms the basis of what outlets like RT and Breitbart do: take true statements out of context, mix in fiction that the target audience either wants to believe or wants to fear, and construct the story in such a way that the target audience is led to a particular conclusion. Linebarger gives examples of descriptions of the good treatment of POWs — an enticement for soldiers, unhappy in the field, to surrender — and other stories suggesting that a group of soldiers allies are sex-crazed or have abnormal sexual prowess — an enticement for soldiers to desert their posts in order to safeguard their wives and girlfriends at home, and an encouragement to further distrust wartime allies whose history with one’s culture is more complicated.</p><p>The goal of this kind of work, which we might call propaganda news stories, is for the target to actually believe the stories and come to the conclusions suggested. Linebarger suggests that the goal of such stories should be to convince enemy soldiers to surrender or desert their posts, so that war can be ended with a minimum of bloodshed, and that to bolster the effectiveness of this kind of propaganda, all of the things that can benefit the enemy soldiers once they follow the suggestions provided by these stories should be made true — in other words, one should suggest that POWs are well treated and then actually treat the POWs well, even if the POWs are treated better than the neighbouring citizens.</p><p>There’s another form of fake news, of about the same vintage, that would specifically be coming out of the intelligence community: the double cross. Knowing that a party is listening but skeptical, one can produce fake news or fake documents that are a mix of truth and fiction produced in such a way that the end goal is to produce confusion and greater skepticism — to waste the time of the opposition. A good example is the idea that carrots promote night vision — which was, in fact, a story that was circulated locally in Britain to simultaneously hide the existence of advances in radar and radar detection systems and push the Axis powers into a series of ill-fated and expensive attempts to improve soldier eyesight with dietary changes. Another good example is “red mercury”, a fictional chemical that was mentioned in leaked nuclear weapon plans — these plans looked fairly convincing, but anyone working off them would spend a great deal of time looking for the imaginary red mercury, resulting in a delay in nuclear weapon development.</p><p>Linebarger’s propaganda approach is fairly straightforward: if people believe the news story, they can be controlled; if they don’t, they can’t be controlled. The trick is to compose stories that people want to believe — and it’s no trick at all, if you have a sufficiently nuanced understanding of the culture and history of the target group. While positive uses are possible here — the historical use of these stories to convince Nazis to surrender or go AWOL would be seen as positive by most — this tool is basically totally dependent upon the intent of its wielder, and it can be turned against anybody in a rather uninteresting way.</p><p>The double-cross is more interesting, because it deals directly with the idea of a nuanced, skeptical, sophisticated audience. It’s less predictable in its concrete results, but an environment saturated in double-cross media is an environment that is extremely resistant to Linebarger-style propaganda. Anybody with a vested interest in determining truth, when dealing persistently with a consistently yet not systematically unreliable source of data, will develop a habit of skepticism and reflexive self-awareness that borders on paranoia, and such a habit is extremely useful when actually isolating truth from fiction.</p><p>There’s a third kind of fake news, which I’ll call the single-source double-cross. This is the kind of propaganda produced by long-running state media that are required to toe the party-line — think Pravda, or North Korean press releases. Like Linebarger-style propaganda, it has a clear goal which can be trivially determined by the target population if they’re inclined to look critically. Like the double-cross, it is created with an awareness that nobody will take it at face value.</p><p>However, the major difference is that it comes without opposition — anything it says, true or not, will be backed up by any other media released, because all of the media are required to adhere to the same set of rules. Knowing that what the media says is in some places false, but at the same time having no alternative view provided, we cannot produce a consistent view other than the official one and risk engaging in a kind of learned helplessness.</p><blockquote>Everyone in Russia in the early 1980s knew that the managers and technocrats in charge of the economy were using that absurdity to loot the system and enrich themselves. The politicians were unable to do anything because they were in the thrall of the economic theory, and thus of the corrupt technocrats. And above all no-one in the political class could imagine any alternative future.</blockquote><blockquote>In the face of this most Soviet people turned away from politics and any form of engagement with society and lived day by day in a world that they knew was absurd, trapped by the lack of a vision of any other way. — <strong><em>“</em></strong><a href="http://www.bbc.co.uk/blogs/adamcurtis/entries/20c22534-f722-3d7a-b7ba-0506fcc00063"><strong><em>THE YEARS OF STAGNATION AND THE POODLES OF POWER</em></strong></a><strong><em>,” Adam Curtis</em></strong></blockquote><p><a href="http://nymag.com/scienceofus/2016/11/how-facebook-and-the-filter-bubble-pushed-trump-to-victory.html">Some of the coverage</a> of filter bubbles with regard to fake news has focused on how self-segregation has allowed Linebarger-style propaganda to become extremely effective in certain communities, which is true.</p><p>Other coverage instead focuses on the idea of “post-truth” politics, which is essentially a combination of the double-cross and the single-source double-cross: when we self-segregate, we can turn the regular double-cross into a single-source double-cross by only sharing stories we find agreeable, even if we know that they aren’t true. It’s important to note that the filter bubble isn’t some recent invention, or some conspiracy by tech companies. When we don’t think clearly and critically, we have a <a href="https://www.wired.com/2016/11/filter-bubble-destroying-democracy/">tendency</a> to ignore information we don’t like and hoard information we do. When we’re provided with the ability to share a stream of information of unknown veracity with a group of peers — chosen via some kind of semi-mutual consent — we <a href="http://math.unice.fr/~dmitsche/Publications/homophily.pdf">self-segregate</a> based on who shares information they like.</p><p>But, where a double-cross media landscape promotes a sophisticated, skeptical, cosmopolitan approach, the aggressive filtering of dissent provided by social feedback producing a single-source double-cross landscape promotes a nihilistic approach: “everything is fake, and I don’t know what to believe, so I’m not even going to try to learn anything”.</p><p>In other words, if you expose yourself to a media mix that is both appealing and unappealing, apparently true and false, you’ll end up becoming a more effective and discerning thinker, while if you filter that same spew by appealingness you will end up a less effective and less discerning thinker.</p><p>People like Joey Skaggs — and others who take a discordian-inspired culture-jamming approach — are attempting to improve critical thinking via fake news. For instance, <a href="http://joeyskaggs.com/html/cat.html">Cat House for Dogs,</a></p><blockquote>“Cat House for Dogs,” said an ad in the Village Voice, “featuring a savory selection of hot bitches…” Along with this ad, a press release was sent to the media saying that if your dog graduated from obedience school, if it was his birthday, or if he was just horny, for $50 you could get your dog sexually gratified. This was not a breeding service, but purely a sexual pleasure service.</blockquote><blockquote>The phone rang off the hook as hundreds of people called to talk to New York’s first and only dog pimp. Surprisingly, not only were the calls from bonifide customers willing to pay $50, but there were just as many calls from people who wanted to have sex with dogs or watch dogs have sex with other people. Dog pimp, Skaggs, recorded all of these incoming phone calls.</blockquote><blockquote>When contacted by the news media, Skaggs got together 25 actors and 15 dogs and staged an elaborate performance in a SoHo loft — a night in a bordello for dogs. The performance featured models posing with female dogs in look-a-like outfits, and actors posing with the male dogs waiting to view the bitches. Friend Tony Barsha played a bogus veterinarian on site who, when interviewed, explained that the female dogs were injected with a drug called Estro-dial to artificially induce a state of heat. If a bitch was already in a natural state of heat, she would be given a contraceptive called Ova-ban, so there would be no fear of fatherhood.</blockquote><p>The intent here is clearly different than those who want to use fake news to manipulate you into voting a certain way, or people who want to wear you down to the point where you’re unwilling to even complain.</p><p>Where Linebarger-style propaganda tells you what to believe and satire tells you that other people’s beliefs are silly, culture jamming of this type encourages you to question your beliefs by making you consider believing something silly. And in terms of ill intent, the worst that can be accused if such efforts is that they cast shade on the legitimacy of press outlets that carry the story without being in on the joke. There’s no harm to be rendered by that in light of the Post Factual, and plenty to gain.</p><blockquote>Surrealism is the key. Surrealism will shock your mind of its track. Surrealism can shut your mind down for a fraction of a second, allowing you to experience the world for just a moment uncensored. —<strong><em> Operation Mindfuck</em></strong></blockquote><h3><a href="https://modernmythology.net/we-can-weaponize-fiction-but-how-do-we-monetize-truth-ef9ffb52299e#.ua4r4kxqw">Part Two Here</a></h3>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Considering that the root cause is the essential incompatibility between optimizing for truth and…]]></title>
            <link>https://medium.com/@enkiv2/considering-that-the-root-cause-is-the-essential-incompatibility-between-optimizing-for-truth-and-6c473666428b?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/6c473666428b</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 28 Nov 2016 15:13:50 GMT</pubDate>
            <atom:updated>2016-11-28T15:13:50.228Z</atom:updated>
            <content:encoded><![CDATA[<p>Considering that the root cause is the essential incompatibility between optimizing for truth and optimizing for commercial success, I don’t see fake news ever going away or being seriously addressed. People will continue to pay for spurious information that matches their biases, and people will continue to generate spurious information that matches the biases of people willing to pay for it, for as long as money continues to exist.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I develop quite a bit of open source software.]]></title>
            <link>https://medium.com/@enkiv2/i-develop-quite-a-bit-of-open-source-software-a79593753c37?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/a79593753c37</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 28 Nov 2016 13:46:21 GMT</pubDate>
            <atom:updated>2016-11-28T13:46:21.809Z</atom:updated>
            <content:encoded><![CDATA[<p>I develop quite a bit of open source software. The reason is that I develop software for my own use, and because I am not being paid for that software and never will be, I might as well make it available to the occasional other developer who may want to use it in the far future. Since I’m only developing software to scratch my own itches, there’s no real possibility of fame or fortune coming out of it: nobody has bothered to write this code before, and I didn’t spend a huge amount of effort on it, so clearly demand must be low.</p><p>I think this is probably closer to the norm for open source projects. Most open source projects are maintained by one person, used by two or three people total, and are short scripts (less than ten thousand lines of code, in some scripting language) either written over a period of a few days or written a few lines at a time over the course of a decade. These projects become open source because there’s no potential upside to closing them off and no potential downside to opening them up: end users can’t even conceptualize the tasks that these projects perform, because they are the type of developer tool that only the rare developer will even consider worth using, so feature requests will never appear.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The idea that major religious figures are ambassadors from outer space goes back at least to…]]></title>
            <link>https://medium.com/@enkiv2/the-idea-that-major-religious-figures-are-ambassadors-from-outer-space-goes-back-at-least-to-214302f2099c?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/214302f2099c</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 21 Nov 2016 16:23:12 GMT</pubDate>
            <atom:updated>2016-11-21T16:23:12.044Z</atom:updated>
            <content:encoded><![CDATA[<p>The idea that major religious figures are ambassadors from outer space goes back at least to Theosophy, with its idea of “secret chiefs”; Theosophy was extremely influential, particularly on the ideas of other syncretic religious groups, so it’s not a surprise that the Aetherius society has adopted this idea (just as the Raelians have). It’s also not surprising that it made its way into pop culture, since Theosophy was basically the Spiritualism of the 1920s: a minor religion with very influential followers that captured the zeitgeist &amp; thus had an overwhelming effect on popular discourse.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Clearly, the only thing that can defeat Trump now is the veneration by chaotes of an even older…]]></title>
            <link>https://medium.com/@enkiv2/clearly-the-only-thing-that-can-defeat-trump-now-is-the-veneration-by-chaotes-of-an-even-older-4e867818f5e5?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/4e867818f5e5</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 14 Nov 2016 13:44:36 GMT</pubDate>
            <atom:updated>2016-11-14T13:44:36.483Z</atom:updated>
            <content:encoded><![CDATA[<p>Clearly, the only thing that can defeat Trump now is the veneration by chaotes of an even older deity. (I’m thinking maybe Innana, patron goddess of love, war, prophecy, the impossible, and fashion.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[On communities]]></title>
            <link>https://medium.com/@enkiv2/on-communities-cf4ad1b6ce3?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/cf4ad1b6ce3</guid>
            <category><![CDATA[community]]></category>
            <category><![CDATA[politics]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 07 Nov 2016 19:16:04 GMT</pubDate>
            <atom:updated>2016-11-07T19:16:04.798Z</atom:updated>
            <content:encoded><![CDATA[<p><em>An extension &amp; refinement of </em><a href="https://meaningness.com/metablog/geeks-mops-sociopaths"><em>the MOP theory</em></a><em>.</em></p><p>The function of any given community is social noise reduction: a community allows groups of people with certain sets of attributes to access each other with fewer “misses” — i.e., without accidentally interacting with a person lacking any of these attributes. (Whether or not this is a good thing depends pretty heavily on the circumstances; however, ultimately, a country club, a Bilderberg conference, a birdwatching forum, and a hackerspace all have in common this basic definition.) Gatekeeping is therefore a huge part of the function of the community.</p><p>In a sense, the gatekeeping rules of any community define that community. After all, gatekeeping rules ideally act as a test to ensure that members approximate the ideal community member, but functionally, gatekeeping rules specify who gets into the community and therefore what the range of attributes are of community members. Gatekeeping rules are rarely explicit, and many are inherently implicit: after all, community norms, tolerance for particular community members, and desire to be part of the community all have major gatekeeping ramifications despite never being written or systematically enforced.</p><p>Communities are not the result of people coming together so much as they are the result of people seeking a temporary separation by some arbitrary category. They happen naturally, as people congregate toward other people who can fulfill needs and desires. When a community becomes diluted such that different sub-groups within it have different needs, it fractures into multiple communities, whether or not anybody recognizes or points this out for any particular group. Community fracture is always present and fractal to some degree: cliques appear within any community among people who get along better together, and this is part of the community fracture gradient and caused by the same impulse toward sorting. However, all of these organizations are temporary and desire-driven: someone who ceases to be interested in hot rods has left the hot rod community, and communities don’t organize along racial lines in the absence of racial tension. The rich and powerful form cliques among themselves because they share attributes that are only accessible to them (nasty gossip about foreign dignitaries isn’t available to people who aren’t presidents; discussion about how to prevent your kids from murdering you for your inheritance isn’t useful for people who have no estate), and pooling power is a side effect rather than a goal.</p><p>Prior to complete fracture, a cultural change within a community changes the community’s ideals. When somebody leaves a community and calls it “dead” — it’s not dead, but it no longer serves the purpose that person needed it for. Communities are tools for solving particular social/interpersonal problems (usually, a desire to communicate about a particular subject), and when community norms change, it’s as though someone’s screwdriver has been replaced with a hammer.</p><p>The MOP theory explains a very specific special case of this phenomenon — one that happens pretty frequently, particularly in “geek” circles. Specifically, it explains what happens when an affinity group organized around a particular subject becomes subverted for the sake of commercial interests. (When we talk about this in terms of Punk, or Star Wars, or comic books, we’re really talking about a set of established commercial interests that had already taken over partial control of a social group being subverted by another, larger and more powerful set of commercial interests with different norms.) Whether or not this is a good thing basically comes down to which norms align more closely with the ones you value. While typically the group that takes over has values closer to the notional “mainstream”, it’s not as though communities haven’t been taken over by commercial interests that are even more fringe — as with Palmer-Luckey-funded alt-right trolls infiltrating 4chan. That said, the typical pattern is as mentioned in the MOP theory: a community with a focus on detail and quality has its gatekeeping process subverted by a second group whose focus is on commerce, in such a way that an influx of less-dedicated members become involved; the average dedication level of the group plummets while the most dedicated group members leave the community to form their own. Without the most dedicated members, the infrastructure involved in gatekeeping and in keeping conversations going disappears, leading to most of the casual members also leaving, but enough money has been extracted from the group by commerce-centric outsiders to make this tactic a success.</p><p>When a community that has been infiltrated becomes self-sustaining (usually because the new gatekeeping mechanism is sufficiently exclusive that most members still find something valuable in each other’s company), it’s essentially a new community with new norms: obviously most of the old guard will find this new community less to their liking than the old one, because the old community was based more closely on their own desires and values. It also becomes vulnerable to being infiltrated, split, or subverted by some other commerce-centric group. Whenever a commerce-centric group infiltrates a detail-centric group, the group norms become more lax, because commerce works best at scale and details work best with strong gatekeeping.</p><p>While toxic community norms (as mentioned on <a href="https://status451.com/2016/09/15/social-gentrification/comment-page-1/#comment-1960">the Status 451 piece</a>) can become part of gatekeeping, they are rarely truly valuable as such. Communities with toxic norms can become stable so long as they consist primarily of people who can’t easily split off. Having been a long-time member of several autism-related internet communities, I can verify that schism doesn’t take a huge amount of emotional intelligence or social capital; more typically, toxic norms dominate in groups where confidence in one’s ability to split off is low &amp; desire to avoid a toxic community is low — in other words, toxic communities are a result of learned helplesness, not a calculated tactic.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I’ve never believed that clickbait had anything to do with audience preferences.]]></title>
            <link>https://medium.com/@enkiv2/ive-never-believed-that-clickbait-had-anything-to-do-with-audience-preferences-d5136786e145?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/d5136786e145</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 07 Nov 2016 13:55:20 GMT</pubDate>
            <atom:updated>2016-11-07T13:55:20.921Z</atom:updated>
            <content:encoded><![CDATA[<p>I’ve never believed that clickbait had anything to do with audience preferences. The popularity of longreads shows that people would well and truly prefer to read proper, in-depth journalism.</p><p>The thing is, low-content reporting (short listicles that are mostly images, 500-word “articles” that are mostly pull quotes from other people’s coverage, reposted press releases) is super cheap and easily outsourced to content farms. If you’re being paid by the click and you can’t easily maximize the clicks (because you’re in a red queen’s race) then you can at least make sure you’re spending as little money as possible on each ad-hosting page of “content”.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Early attempts at implementing transcopyright (essentially, a system by which quote attribution is…]]></title>
            <link>https://medium.com/@enkiv2/early-attempts-at-implementing-transcopyright-essentially-a-system-by-which-quote-attribution-is-4b76d9edf081?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/4b76d9edf081</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 07 Nov 2016 00:38:23 GMT</pubDate>
            <atom:updated>2016-11-07T00:38:23.831Z</atom:updated>
            <content:encoded><![CDATA[<p>Early attempts at implementing transcopyright (essentially, a system by which quote attribution is treated as a mechanism of remixing &amp; is built-into the editing and publishing system with fees, the idea being that long discussion threads could become a kind of economy where tiny amounts of money are transferred) such as TokenWord failed because there was no community, and other systems that attempted to adopt some of the ideas of transcopyright didn’t go all-in and thus ended up falling back on their alternative revenue systems in lieu of actually explaining the mechanics of transcopyright to users. However, Medium seems like an almost ideal environment for a transcopyright-type system: long conversation threads emerge around long original posts, most posts aspire to something resembling “journalism proper” rather than the kind of blog-like or social-media-like content that dominates on Tumblr or similar, and many old-school publications have moved to Medium and integrated with its systems. Not only that, but Medium already has a licensing menu &amp; complicated licensing mechanisms. In other words, if Medium were to build a mechanism for pasting highlights into a new post while making them link to the original context &amp; hook that system into a default license that explicitly allows these highlighted sections to be put into a new post in exchange for redeemable credits, Medium would immediately have a transcopyright-style system (although they would need to hook into some sort of payment framework in order to allow people to put money in and take it out; probably, they’d have to set aside a bit of money for people to start off with, so that users wouldn’t need to pay something in first).</p><p>Ads don’t pay much at all. Any replacement for ad-supported systems would need to let people pay as much as ads would, and were that payment truly automatic many people would: we’re talking a fraction of a cent for hundreds of views. (I subscribe to Google Contributor, which basically turns Google’s own ad system into a micropayment system: I rarely see ads, but every site gets the kind of money it would if I saw every ad. The problem is that for certain ads, Contributor is disabled, and these are the most irritating ones, so I still have to use ad blockers on desktop — only sites I view on my phone end up going through Contributor in the end. However, if Google were to charge me $4 instead of $3 and properly block *all* the ads, I’d happily turn off ad blocker and pay the money.) The ad ecosystem wastes money by involving a bunch of third parties; direct automatic micropayments to all involved web hosts is better, because anybody calculating how much showing me an ad is worth to them is drastically overestimating: I’m never going to buy something by clicking through a pop-up ad because it’s insecure, so they’re never going to make that fraction of a cent off me that they paid the web host, and as soon as they realize how many people out there think the same way, ad impressions will be worth even less.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Yeah. It’s useful as a rule of thumb for who you should probably be extra careful not to mock for…]]></title>
            <link>https://medium.com/@enkiv2/yeah-its-useful-as-a-rule-of-thumb-for-who-you-should-probably-be-extra-careful-not-to-mock-for-bf9be8738121?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/bf9be8738121</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Sat, 05 Nov 2016 13:29:37 GMT</pubDate>
            <atom:updated>2016-11-05T13:29:37.631Z</atom:updated>
            <content:encoded><![CDATA[<p>Yeah. It’s useful as a rule of thumb for who you should probably be extra careful not to mock for no good reason, but satire falls into the category of legitimate criticism layered in humor. Nobody should be immune to legitimate criticism, and nobody should be mocked for no good reason, so as a rule it’s only useful when you’re already failing to follow other, more important rules.</p><p>I don’t think the idea of calculating punch vectors — i.e., trying to figure out power relationships — is not worthwhile, though. Systematic inequality tends to be easy to ignore, so encouraging people to look for it is important. But the thing about legitimate criticism is that it’s not an attack: the target of criticism benefits from understanding and accepting it, by definition. In other words, calculating power relationships should probably not be a part of determining who to criticize (although it may be part of determining how to criticize them), because criticism is a positive-sum game.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The Lazarus Pose]]></title>
            <link>https://medium.com/@enkiv2/the-lazarus-pose-6d0b197291d3?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/6d0b197291d3</guid>
            <category><![CDATA[mars]]></category>
            <category><![CDATA[fiction]]></category>
            <category><![CDATA[drones]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 03 Nov 2016 13:46:55 GMT</pubDate>
            <atom:updated>2016-11-03T13:46:55.023Z</atom:updated>
            <content:encoded><![CDATA[<p>February 23, 2025</p><p>Two weeks ago, when the first manned ship to Mars exploded, even if nation states wanted to cover it up, such a thing would be impossible. The scale and suddenness of this event exposed the the internet cranks’ claims of international conspiracy as wishful thinking. Much speculation about the evidence caught on radar and sattelite imagery has occurred, but to my knowledge, I am the only one to directly investigate the black squares.</p><p>Let me first reiterate the obvious: the Heart of Gold was the largest, fastest space vehicle humans have ever built by a large margin, and took a great deal of time and capital. It was one month into the three month trip. The things that intercepted it were of comparable size, and the time from when the squares in Siberia and the Outback first appeared and impact was only twenty minutes. This was not part of the abandoned Soviet Dead Hand interception system; the Soviets could not have built a device this size.</p><p>I got lucky: I was on Twitter when the news hit. I immediately booked a red-eye flight to Siberia; after all, the Australian square would be much harder to travel to. I bought every drone for sale in the airport mall.</p><p>The Siberian square, like the Australian one, was about a mile across. When it opened, it caused a building above it to collapse. I imposed upon the landlord of this building; luckily, there were no tenants at the time, though the landlord suspects that some squatters may have been lost.</p><p>With a hole a mile across, it’s reasonable to expect quite a bit of depth. The scale of the things launched from here gave me a bit of an estimate: at least 800 feet. I modified the drone firmware so that each drone could act as a signal repeater for the next one in the chain; I also added a ping function as a means of estimating depth, although with slow microcontrollers like those in the drones there’s a margin of error of about 2%.</p><p>My daisy chain of drones demonstrated that the square extended straight down about 200 feet, with some indication of shear stress on the edges for the first 25 feet below the rockhead. After 200 feet, the space opened up: my drone’s cameras, radar, and sonar all couldn’t find edges. There wasn’t much to see, other than a lot of dust. About a hundred feet lower, some debris (presumably from the collapsed buildings) sat atop a blunt cone made of a material that resembles smooth concrete. I had my lead drone land on the cone to get a closer look.</p><p>From the perspective of the tip of the cone, I could see a vast grid of similar cones in all directions. However, the lead cone (and others) began to move; tremors made the building I was staying in become unstable, and I had to flee. Unfortunately, my recordings were lost when the building collapsed on top of my computer, during the square’s closure.</p><p>From public sattelite imagery, it seems that the other square closed during the same two hour window; I suspect that it actually closed simultaneously.</p><p>With regard to the mystery of the squares and the tragic demise of our Martian colonists, it is my position that history has repeated itself. The Soviet dead hand system accidentally recapitulated, in some small way, an antedeluvian drama that once occurred between Earth and Mars, long before the age of man. We have finally reached the level of technological development necessary to become pitted against our forebears, who while not human were also people of Earth. However, their defenses are far beyond what we can reasonably wish to escape. How long will we be trapped on this planet by the nervous twitches of a long-dead race? The thousands of cyclopean missiles beneath the Siberian tundra are our formidable jailers, along with similar stockpiles who knows where else. We cannot leave the cradle of earth until we outwit them; but, even something as simple as the door mechanism for this defense system is centuries beyond our technology, and the very existence of a race who could build such things is beyond the current reach of our archaeology.</p><p>Who were the figures in this ancient drama? We have been presented with a mystery whose clues will be inaccessible for the forseeable future.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Books that should be made into movies, but never ever will]]></title>
            <link>https://medium.com/@enkiv2/books-that-should-be-made-into-movies-but-never-ever-will-5b86506b29ff?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/5b86506b29ff</guid>
            <category><![CDATA[science-fiction]]></category>
            <category><![CDATA[movies]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 02 Nov 2016 16:36:43 GMT</pubDate>
            <atom:updated>2016-11-02T16:36:43.826Z</atom:updated>
            <content:encoded><![CDATA[<p><strong><em>We Can Build You</em> by Philip K. Dick</strong></p><p><strong>Summary</strong>: A company that makes electronic instruments (something like a cross between a Mini-Moog and a Melotron, based on the description) decides to branch out into animatronics, and for an anniversary of the civil war, decides to produce autonomous androids designed to look and act like Lincoln and his secretary of state. Our protagonist, a salesman for this company, falls in love with the artist hired to build the faces; the artist starts off being represented as a manic pixie dream girl. (She sleeps with him, decides she doesn’t like him much, and disappears; he doesn’t get the hint.) Since these androids are autonomous and trained on the writings of the figures (along with records of their habits), they have no idea that they are robots, and they proceed to act as though they have been transported through time, leading to a plot where the salesman and robo-Lincoln go on a cross-country road trip looking for the robot version of the Secretary of State, during which robo-Lincoln tries and fails to give romantic advice. In the last scene, our protagonist is drunk in a bar with robo-Lincoln, coming to terms with the fact that he was dumped, while robo-Lincoln sinks into a deep depression and becomes essentially catatonic.</p><p><strong>Why it should be made</strong>: This would make an excellent counterpoint to modern rom-com fare like Scott Pilgrim, in that it does a good job of subverting the manic pixie dream girl progression: an artistic and damaged woman ends up rejecting the protagonist who is obsessed with her, and that result sticks. By having animatronics with just enough AI to be unpredictable, this ties in thematically with the Westworld franchise, which of course has recently been rebooted to some acclaim. Lincoln biopics had a sudden popularity a few years ago, as well. But, the most interesting part about this story is that it doesn’t do what pretty much every other story about AI does: it never bothers to touch upon the idea of whether or not these machines are “really conscious”. The machines are clearly machines, because our protagonist’s friends built them, and the story doesn’t make them out to be particularly advanced or clever; at the same time, they act like people and are therefore treated like people by our protagonists. When robo-Lincoln goes into a deep depression, nobody questions whether or not the depression is “real”, because of course it’s real: he’s so sad that he can barely move. It’s a book that substitutes the turing test for the eliza effect, and succeeds.</p><p><strong>Why it will never get made</strong>: Hollywood is really fixated on removing the lumps from PKD adaptations. Outside of the original Total Recall &amp; a couple scenes from Minority Report, PKD adaptations basically reach for a streamlined hollywood ideal of what twelve year olds in 1995 would consider a mind-blowing sci-fi movie. This ignores the kind of fuzzy weirdness PKD embraced in his writing, and which characterized much of the draw of <em>We Can Build You</em>. If you took this and removed the lumps, you’d get a really uninteresting result. For proof of this, compare <em>Do Androids Dream of Electric Sheep</em> (the book written immediately before <em>We Can Build You</em>, and one that is in many ways inferior) to its loose adaptation Blade Runner (which, while iconic for its cinematography and sound design, has removed so many lumps that it’s pretty much the closest thing to a science fiction cliche since Fritz Lang’s Metropolis).</p><p><strong><em>Gun, With Occasional Music</em> by Jonathan Lethem</strong></p><p><strong>Summary</strong>: A hardboiled detective story in a strange science fiction universe. In a world where the government supplies citizens with memory-loss drugs, uplifted animals form a servant underclass, and police enforce politeness with social credit chips, a private investigator tries to solve a brutal murder.</p><p><strong>Why it should be made</strong>: A good adaptation will introduce audiences to the true power of science fiction to play with novel ideas. The plot proper is nothing special: it’s frosting on top of the world-building, but because it’s so cliche, it does a great job of leading readers through this world. A proper adaptation would be visually arresting and weird: uplifted animals retain their usual size but talk and walk on two legs; the same technology is being used on the infants of the wealthy, who develop into perpetually drunken and misanthropic superintelligent infants with oversized heads and a pathological inability to avoid making puns. Imagine if Jupiter Rising was actually twice as smart as it thought it was instead of half as smart, and you’re imagining a <em>Gun With Occasional Music</em> adaptation.</p><p><strong>Why it will never be made</strong>: It’s unclassifiable. The only way we’d ever see this done justice is if Terry Gilliam or Don Coscarelli directed it; even then, with or without producer intervention, it’s an even bet whether this would end up being great (a la Brazil) or a top-heavy flop (a la Jupiter Rising). A lesser director would be tempted to try to play it straight and tone down the lumps. Unlike with <em>We Can Build You</em>, where the lumps are few and big and integral to the plot, <em>Gun With Occasional Music</em> has a million tiny lumps and an easily separable plot proper, but the only reason to bother with it is the lumps.</p><p><strong><em>Snow Crash</em> by Neal Stephenson</strong></p><p><strong>Summary</strong>: In an anarchocapitalist future where nation states have been replaced with franchises, a cable magnate tries to reintroduce an alien mind-virus to a swarm of refugees, and a master-swordsman journalist races against time to prevent a whale-riding knife-wielding sociopath from distributing it all throughout virtual reality.</p><p><strong>Why it should be made</strong>: <em>Snow Crash</em> mixes big ideas with the most interesting excesses of VHS-trash spectacle. A proper adaptation would do for the 90s what Quentin Tarantino did for the 70s.</p><p><strong>Why it will never be made</strong>: <em>Snow Crash</em> deals heavily in exploring weird political and racial dynamics, often explicitly. It uses the conflation of nationality with franchise preference to compare and contrast ethnic identity with branding. To do this, it engages in and plays with racial stereotypes. This is hard to do well, and risky even when it is; movie audiences will pretty much always contain somebody who takes things at face value, and with so much else going on, we’d probably see the same kind of missed-the-point fandom around a Snow Crash movie as we do around Scarface, Fight Club, Watchmen, Goodfellas, and Robocop.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Other things happening in November:]]></title>
            <link>https://medium.com/@enkiv2/other-things-happening-in-november-9c9668419327?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/9c9668419327</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 02 Nov 2016 15:10:05 GMT</pubDate>
            <atom:updated>2016-11-02T15:10:05.102Z</atom:updated>
            <content:encoded><![CDATA[<p>Other things happening in November:</p><ul><li><a href="http://github.com/nanogenmo/2016">NaNoGenMo</a>: write a program to procedurally generate a novel in a month.</li><li><a href="https://tullyhansen.github.io/NaBoMaMo/">NaBoMaMo</a>: create 31 twitter bots in November.</li><li><a href="https://itch.io/jam/procjam">ProcJam</a>: write a game using procedural generation in November.</li></ul>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[As a follow-up, I’d like to reiterate that, as Charlie Stross says, “bigotry is fractal”.]]></title>
            <link>https://medium.com/@enkiv2/as-a-follow-up-id-like-to-reiterate-that-as-charlie-stross-says-bigotry-is-fractal-ad77a0489c4d?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/ad77a0489c4d</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 02 Nov 2016 14:35:40 GMT</pubDate>
            <atom:updated>2016-11-02T14:35:40.078Z</atom:updated>
            <content:encoded><![CDATA[<p>As a follow-up, I’d like to reiterate that, as Charlie Stross says, “bigotry is fractal”. Power relations are complicated because they contain their own inversions (and may run in complicated loops in certain communities), so what constitutes punching “up” versus “down” is often unclear and very environment-dependent.</p><p>Satire at its best highlights through emphasis behaviors and systems that are malfunctioning and, if eliminated or repaired, would be a net positive. For instance, consider satires of government corruption in democratic republics: the power relationships are complicated since while elected officials are often wealthier and have more direct power than their average constituent, they are at least theoretically under the thumb of those constituents &amp; both the pressure to remain electable and various anti-corruption restrictions provide the impetus behind corruption in the first place; something like Yes, Prime Minister, by focusing on government, highlights a set of very strange circumstances that can force someone like Prime Minister Hacker to behave in the way we see actual officials behave despite his best efforts, and mostly criticizes the system. Ultimately, every character in that show is flawed, but the person with the greatest claim to ostensible power is the person we in the audience identify most with, because while he is vain and conniving and foolish, he is also naive, optimistic, and genuinely has the best interests of his constituents at heart after a fashion, and each episode shows how his tiniest motions toward exercising his power get quashed beneath the great weight of a government system designed to preserve the status quo. The humor comes from seeing one of the most powerful men in the world reduced to a petulant child by a dysfunctional system and empathizing with him.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Package dependency hell is *primarily* a function of unfamiliarity, and it’s not like it doesn’t…]]></title>
            <link>https://medium.com/@enkiv2/package-dependency-hell-is-primarily-a-function-of-unfamiliarity-and-its-not-like-it-doesn-t-20e4d908bcc?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/20e4d908bcc</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 31 Oct 2016 20:35:15 GMT</pubDate>
            <atom:updated>2016-10-31T20:35:15.716Z</atom:updated>
            <content:encoded><![CDATA[<p>Package dependency hell is *primarily* a function of unfamiliarity, and it’s not like it doesn’t exist on other platforms. Getting a functional development environment up and running on a Mac is just as hard as getting one up on Linux, so long as you’re OK with typing — the difficulties with homebrew are almost exactly the same because homebrew is basically just a unix-style package system! If you’re trying to get XCode to work properly and you’re used to vim, you’re going to have a lot more trouble with that than you would with installing a full development toolchain (minus IDE, because an IDE isn’t useful or necessary) on another unix.</p><p>Maybe you have a fat wallet and your idea of marginal value is different from mine, but I’d rather pay a few hundred dollars less and install my own unix on a machine that will continue to work if I drop it.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[If you want a professional quality development machine, buy a 2008 Thinkpad on ebay (cost is about…]]></title>
            <link>https://medium.com/@enkiv2/if-you-want-a-professional-quality-development-machine-buy-a-2008-thinkpad-on-ebay-cost-is-about-ffb2e3db395a?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/ffb2e3db395a</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 31 Oct 2016 20:29:53 GMT</pubDate>
            <atom:updated>2016-10-31T20:29:53.575Z</atom:updated>
            <content:encoded><![CDATA[<p>If you want a professional quality development machine, buy a 2008 Thinkpad on ebay (cost is about $80) and install Linux on it. It’ll remain perfectly good for the next decade, and perform all your development needs.</p><p>OSX is only marginally better for development than Windows is, and a professional should use neither, except for testing and packaging — and don’t you have access to build farms and test farms for that?</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[This kind of thing has been Apple’s MO since 1982.]]></title>
            <link>https://medium.com/@enkiv2/this-kind-of-thing-has-been-apples-mo-since-1982-4cc15fd29b8e?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/4cc15fd29b8e</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 31 Oct 2016 20:25:52 GMT</pubDate>
            <atom:updated>2016-10-31T20:25:52.857Z</atom:updated>
            <content:encoded><![CDATA[<p>This kind of thing has been Apple’s MO since 1982.</p><p>What I blame Steve Jobs for, more than anything else in the industry, is a strange and pervasive false minimalism where power and flexibility are removed in favor of one-off features. This starts with the original Macintosh.</p><p>The Macintosh team was originally working under Jef Raskin on what at the time was slated to be the Macintosh but eventually became the Swyft, and later the Canon Cat. It was a genuinely innovative design: a device that worked primarily as a word processor, but that had the capacity to perform programming operations in-place in the context of a document, like a combination of literate programming and spreadsheet macros. Steve Jobs, having had become obsessed with the Alto he saw demoed at PARC, had started the Lisa project, and when it became clear that Lisa was going to be a flop (it was expensive and underpowered, totally unusable without an aftermarket hard disk that cost as much as the computer, had no applications to speak of, and cost as much as a new car), Jobs got rid of Raskin and took over the Macintosh project, pushing it away from the original concept and towards being a lower-budget version of the Lisa. As a result, he pushed for lower specs: a last-generation CPU, not very much RAM, no support for TV output or external monitors, and a small monochrome (not greyscale) display. In the end, it debuted alongside the Commodore Amiga 1000 and the Atari ST, both of which had double the RAM, impressive high-resolution color display on standard color televisions, multitasking, and faster current-gen CPUs, at half or a quarter of the price. Somehow, the Macintosh sold better.</p><p>During development, Jobs was very wary of the ‘mistakes’ made with the Lisa, and so he forbade the developers from adding new features. Famously, he didn’t allow the hardware team to add any expansion ports; someone secretly added a single expansion port to the board design, however, and the original Macintosh shipped with a board set up such that an intrepid user could solder a connector onto the motherboard and get an expansion port (which couldn’t be used because the OS didn’t have any support for it). Removing expansion ports is, however, typical of Jobs’ attitude here, and it’s typical of his later work at Apple when he came back. (He was forced to resign over the failure of both the Lisa and the Macintosh, and took most of the Macintosh team over to NeXT, which doesn’t seem to have this particular problem somehow!) His idea was that the Macintosh was a computer for “regular people”, who he defined as people who would not only be incapable of using an expansion port but who would be incapable of learning what one is. In the end, plenty of cost on the Macintosh went into fancy beveling and other purely aesthetic aspects of the outer case, advertising, and other marketing concerns. The lesson was: a mediocre product, if it looks pretty and is advertised very well, can become the basis of a successful brand.</p><p>The lessons of the original Macintosh became a strange kind of warped “worse is better” ideology that affected Apple only occasionally during Jobs’ 17-year exile and almost constantly after his return. As soon as Jobs returned, he cancelled most ongoing projects, shifted focus from the pretty servicable beige boxes that represented macs in the mid-90s to the technicolor form-over-function blob of the first generation iMac, and ordered that floppy drives be excluded from all future devices (in 1998). Excluding floppy drives probably removed some cost, but margins for Apple products have always been huge in order to allow for big advertising budgets: owning Apple products, even in the early 90s, was as much a conspicuous display of wealth as it was a utility (outside of schools, which had deep discounts on Apple products as another marketing technique). With software developed under Jobs’ reign (like iMovie &amp; iTunes), even the limited flexibility and configuration of earlier mac products mostly went away or became more limited: as part of the marketing push, Apple products were set up to be configurable in only limited ways pre-screened to be in line with the style approved by Apple’s designers, and Apple software was designed to work primarily with Apple-proprietary formats even when open formats existed and were superior (in a mirroring of Microsoft’s extend-embrace-exterminate strategy from the same time period). The unofficial slogan for Apple was “it just works”, with the hidden caveat that “it” was limited to a small set of tasks Apple had chosen to focus on — while Apple made it easy to do the very specific things they wanted people to do, doing anything else was much more difficult than on competing platforms. This kind of shallow marketing-first strategy was very successful, even though most people more or less recognized it.</p><p>This strategy continued (even though the UNIX base inherited from NeXT made it difficult to lock-down software extensibility on macs and systems like homebrew became common). The original iPhone wasn’t supposed to have third party apps; later, the app store was added but in a way existed as a way to funnel money into Apple moreso than as a way to actually add third party apps to the platform: Apple retained complete veto rights to apps, had long evaluation periods, required third party developers to pay $100 a year to even be allowed to submit their code, and forced these developers to write everything in a language that, while not strictly Apple-specific, is an obscure early C++ competitor that only every achieved any kind of traction at NeXT and later within Apple for compatibility reasons. Apple used this mechanism to remove: apps that criticized Apple, apps that competed with Apple’s own services, apps that violated Apple’s current design guidelines, and apps that were reviewed by somebody who was in a bad mood that day. The iPhone has no distinction between desktop and application drawer, and has no task-switching capability. The iPod, unlike the mp3 players it initially competed with, only worked with macs, only worked with iTunes, only worked under firewire, and had extremely limited controls and configurability; while some of these limitations were changed later, this was only done as a means of bringing this overpriced luxury object to the masses of people who still ran Windows. Apple laptops started the push toward being thin and light, and removed useful things like disk drives and expansion ports using the excuse that thinness and lightness were legitimate goals; of course, while laptops benefit from not being <em>heavy</em>, after a certain point being functional becomes more important than being lighter, and being thin only means the device is easier to break: Apple had essentially invented an excuse for charging more money the less they actually invested in their device, so that whenever they removed a feature or a piece of hardware they could add both the cost of the hardware and their manufactured percieved value of thinness to the cost of the end product. More recently, Apple has pushed for the removal of both the function keys and the headphone jack, as part of this general push towards smaller and lighter devices.</p><p>Now, this would be one thing if Apple could be ignored. My complaint isn’t just that Apple has the kind of abhorrent paternalistic attitude towards its users that used to justify the rush for Africa; after all, individual people and individual companies have all sorts of abhorrent attitudes and ideologies, and they largely don’t directly affect me because I can avoid putting money into those organizations. My big complaint about this is that other hardware and software companies, faced with Apple’s success, have tried to emulate their objectively awful hardware and software design decisions (thus perpetuating this strange design sense that users are children who need to be protected from choosing ugly color schemes by Big Daddy Ive), never realizing that the key to Apple’s success in everything since the end of the Apple II line was to produce mediocre products, sell them for many times their actual value, and spend enormous amounts of money on ad campaigns to convince people that mediocrity is amazing and that even really common things were secretly invented by Apple. In other words, Apple, since the early 80s (but especially since 1997), has been the Kim Jong Il of the tech industry, and their ideas are being gobbled up by lots of people who really should know better.</p><p>The existence of function keys on a new-model laptop is really sort of a non-issue in the scheme of things. Apple has been torpedoing third party development in much bigger ways for a long time. Function keys are only used for development by users of IDEs, and the intersection of IDE-using developers who also use brand-new Apple laptops is a group whose situation and opinions in the grand scheme of things shouldn’t matter much. These people are already shooting themselves in the foot paying four or five times what they should be for an ultimately less functional machine than what they’d get if they bought a used Thinkpad on ebay and stuck Linux on it; it’s not the end of the world if they also have to use a crappy mouse to navigate ill-designed XCode menus sometimes. Maybe these people are developing on a mac because they are trying to develop for the iPhone; in that case, their slower rate of development may hasten the death of that device as well, and it would probably be a net good.</p><p>Like a lot of people, when Steve Jobs died it made me hopeful. Lots of legitimately smart people work at Apple; maybe one of them would take charge and reverse some of the most damaging policies, the way that many of Microsoft’s worst policies changed after Ballmer got ousted. I expected that after a handful of things that were still in the pipeline from the Jobs era managed to get pushed through, we’d start to see some good decisions: laptops with thick protective cases, metal hinges, and locks to keep them closed; three-button mice; hardware that’s actually up to date; machines that ship with homebrew already installed; iPhones you can run Android on. But, I’ve lost that hope: I now suspect that Apple, like RIM and Oracle, will keep to its current course until it finally screws itself over enough to actually die — and, like Atari and IMSAI before it, will probably become a free-floating brand to be placed on arbitrary hardware based on whoever buys the rights.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[While I agree with the sentiment, I think you misplace the blame.]]></title>
            <link>https://medium.com/@enkiv2/while-i-agree-with-the-sentiment-i-think-you-misplace-the-blame-c35cde8a1841?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/c35cde8a1841</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 31 Oct 2016 19:08:29 GMT</pubDate>
            <atom:updated>2016-10-31T19:08:29.894Z</atom:updated>
            <content:encoded><![CDATA[<p>While I agree with the sentiment, I think you misplace the blame.</p><p>I understand the desire to have more readers. My problem with style guides is not this motivation. Instead, most style guides for medium focus on attracting casual readers and gaming the metrics in ways that actually produces inferior content. In other words, they assume the motivation in writing for medium is to get attention for its own sake &amp; make those numbers go up, rather than clear communication.</p><p>For very short content, medium can’t easily distinguish between a ‘read’ and a ‘view’ anyway, so the metric hack of writing short articles is basically meaningless anyway. Likewise, misleading titles lead readers to be tricked &amp; (often, unless the article is of very high quality) to feel tricked.</p><p>All of these techniques make sense in an ad-driven system where authors are being paid per-impression or per-read, but while Medium provides these statistics, it does not pay users (and paying publications on Medium typically pay a flat rate). Clickbaity dark-UX tactics are bad enough when they’re paying the bills; there’s no reason to apply them when there’s no money involved &amp; all that’s happening is that readers are having their trust &amp; good will abused.</p><p>As an author on Medium, I’d rather write a meaningful essay that takes 2 hours to read and see it get four readers and ten views than write a tweet-length piece of content buffetted by images and affiliate links and get ten thousand reads. As a reader, I’d rather read something substantial than something anemic: Medium’s user interface isn’t optimized for short articles the way Twitter’s is, and every one-paragraph article is a waste of my time and effort, particularly when it doesn’t contain any new information.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Microsoft is no longer actively bad, the way it was under Ballmer.]]></title>
            <link>https://medium.com/@enkiv2/microsoft-is-no-longer-actively-bad-the-way-it-was-under-ballmer-bd17c3bf43c6?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/bd17c3bf43c6</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 31 Oct 2016 18:27:29 GMT</pubDate>
            <atom:updated>2016-10-31T18:27:29.144Z</atom:updated>
            <content:encoded><![CDATA[<p>Microsoft is no longer actively <em>bad</em>, the way it was under Ballmer. That doesn’t make it <em>good</em>, though. There’s forty years of dirty tricks that MS has to make up for just to get back to neutral, and it’ll probably <em>take</em> forty years, for those of us with long memories and a familiarity with history, to decide that this new direction is something more substantial than a PR move or a short-lived utopian optimism.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[There’s a potential link to folie au deux here.]]></title>
            <link>https://medium.com/@enkiv2/theres-a-potential-link-to-folie-au-deux-here-94c1afb754e1?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/94c1afb754e1</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 28 Oct 2016 12:20:39 GMT</pubDate>
            <atom:updated>2016-10-28T12:20:39.072Z</atom:updated>
            <content:encoded><![CDATA[<p>There’s a potential link to folie au deux here.</p><p>Most of what we as human being believe we accept as the result of social proof, rather than other kinds of proof. In other words, large portions of our mental model of the world are socially constructed: we accept things that our peer group accepts, even if they contradict our experience. Strange and delusional beliefs can easily take hold in social groups that are isolated from the greater population or have no impulse to share the same ontologies as the outside world (say, cults, conspiracy theory groups, and insular societies with enough power to avoid having to kotow to public opinion). The smaller the group, the easier it is to diverge further and further from consensus reality.</p><p>The halo effect also feeds into this. A group often feels the need to believe the opposite of whatever its opposing group believes, regardless of the relationship these predicates have to reality; a group will handicap itself in order to show group solidarity and such handicaps often come in the form of a ritual show of spite to some imagined outgroup, sometimes as a clearly absurd belief. The absurdity of the belief is proportional to the strength of group membership. Believing that Obama is a secret muslim is the right-wing equivalent of the Yakuza cutting off their own fingers: it’s a sacrifice that is capable of only symbolic utility but very concrete pain, and so the symbol gains strength from the pain.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The ideal chatbot is not a butler or a puppy, but an elder god]]></title>
            <link>https://chatbotslife.com/the-ideal-chatbot-is-not-a-butler-or-a-puppy-but-an-elder-god-10f243372e6f?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/10f243372e6f</guid>
            <category><![CDATA[singularity]]></category>
            <category><![CDATA[bots]]></category>
            <category><![CDATA[god]]></category>
            <category><![CDATA[chatbots]]></category>
            <category><![CDATA[ai]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 24 Oct 2016 15:13:05 GMT</pubDate>
            <atom:updated>2016-10-27T20:08:06.852Z</atom:updated>
            <content:encoded><![CDATA[<p>The commercial industry popping up around chatbots worries me.</p><p>There have been chatbot communities for a long time. I’ve been involved with several. I love chatbots, and I love chatbot communities: they intersect with experimental writing, performance art, and ‘punk’ communities to a much greater extent than traditional AI communities, and constitute melting pots. Chatbots are interesting to these people because they are a tool for playing with language and identity in an interactive and public way.</p><p>Another kind of chatbot community has appeared, only in the past few years. This community bears more resemblance to that surrounding Hacker News than to the other chatbot communities. These are commerce-driven, mostly clueless pseudo-entrepreneurs who heard someone say “bot is the new app” and decided to start writing bots, without looking at the history of the form. As a result, the state of the art in commercial bots looks a lot like it did twenty years ago: it looks like AIML.</p><p>I don’t think that this is an accident. Instead, commercial pressures make it impossible to produce interesting bots. Entrepreneur-types talk a lot about “joy”, but when “joy” is only possible in service to commerce it’s necessarily limited. A commercial chatbot must be not only useful but more useful than alternate methods for performing the same tasks — and since most of these bots are essentially text-based front-ends for existing web services, the only way they can get close to the productivity of the existing services is to simulate an inflexible command line interface. A commercial chatbot can contain only pleasant surprises: it cannot confront us with challenging ideas, because challenging ideas are not profitable; since things that are pleasant to some of us are challenging to others, a commercial chatbot is limited in how many of us it is allowed to surprise at all. Being “smart as a puppy” or acting like a butler, in addition to bringing in questions about the culture of servitude that these representations build upon and taking advantage of questionable levels of surveillance in order to implement these features, limit the range of behaviors of the bot to the domain of “cupcake fascism” — leading to situations like Siri telling users not to swear when they request resources about dealing with sexual assult. A bot that is limited to being as conservative as its most conservative user will be little more than a censor in the way of easier-to-use services.</p><p>When bots don’t need to be useful in the normal case, that is when they become exceedingly useful in the exceptional case. Bots don’t need to reason the way humans do; bots lack the creative limitations implied by a human consciousness, and while this produces mostly noise, accidental signal has a special value when we find it. Bots, freed from caring about humans, can become alien and impart alien wisdom to us. Such bots can synthesize novelty from vast corpora — this is what bots are good at, and it doesn’t take much human intelligence on the part of a programmer to produce very striking results. Bots can implement dumb ideas endlessly, and by implementing them and making them concrete, change our perspectives.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Mirai was appropriately named]]></title>
            <link>https://hackernoon.com/mirai-was-appropriately-named-257bd6892a24?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/257bd6892a24</guid>
            <category><![CDATA[tech]]></category>
            <category><![CDATA[security]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 27 Oct 2016 16:12:52 GMT</pubDate>
            <atom:updated>2016-10-27T16:12:52.399Z</atom:updated>
            <content:encoded><![CDATA[<p>Those of you who have been paying attention to the news already know that the major DNS outage last Friday is probably related to Mirai, a piece of malware whose source was released recently. You’ll also know that Mirai targets low-cost internet-connected embedded devices, and that it’s a comically incompetently written piece of code.</p><p>The idea that embedded devices would be vulnerable to attacks doesn’t even count as an open secret: the idea that major websites of the near future would be DDoSed by smart fridges was a cliche in some corners of the computer security world in 1999. Prior to around 2010, the dominant term for what we now call the Internet of Things was “ubiquitous computing” — a reference to Phillip K Dick’s novel Ubik, whose description of a group of appliances conspiring to extort and blackmail their human owner, now used as a parody of the “internet of things” concept, actually initially inspired it. The method that Mirai uses to get into these nodes is again an old one, familiar to war-dialers from the BBS era: Mirai iterates through a list of default username and password pairs until it gets a hit. Such lists are easy to find, and have been circulating on the internet since before it was called “the internet”.</p><p>In the early 90s, members of a hacking group called the L0pht made a public statement claiming that they could easily take down the internet, and unless security measures improve, someone with less impulse control would eventually do so. They weren’t bluffing; various methods of making the whole internet essentially unusable for long periods of time have been available for decades now, largely unpatched — it turns out that until now, few people have wanted to bother with such blunt instruments.</p><p>The general consensus in computer security that the human element is typically the weakest link isn’t without merit: in a competently secured system, humans are the most difficult element to lock down, and exploiting the human biocomputer requires less cleverness than exploiting a computer system. However, even when high stakes are involved, competence is not the norm: until recently, easily broken short PIN codes dominated online banking, and much banking infrastructure still relies upon things like account numbers and SSNs that conflate identification, authentication, and authorization; few systems implemented multi-factor authentication and nearly all systems will waive mutli-factor authentication in the face of a sufficiently convincing phone call; modern security practices have yet to penetrate industries like web dev and embedded systems development, where hardcoded authentication defaults, debugging backdoors, passwords stored as plaintext or unsalted hash, weak xor encryption against some arbitrary byte, and other awful behavior is tolerated or encouraged. We see from leaked documents that even the NSA is engaging in absolute idiocy, using Microsoft Word &amp; its macro system for dealing with confidential documents and allowing those macros to contain commands that interact with the network.</p><p>Mirai, created by weebs, is full of in-jokes refering to chan culture and anime. Some people have taken this to mean there’s an association with Anonymous; however, the lesson of Mirai is that an association with Anonymous is totally unnecessary. The situation that Mirai takes advantage of is an old one; the only thing new about it is that even the dumbasses have realized that even a dumbass can take down the internet. The release of Mirai’s source has allowed script kiddies of an even lower skill level than Mirai’s authors to take advantage of the collective ignorance that end users have been allowed to partake in.</p><p>The name “mirai” was probably chosen because it sounds cool, but it’s very appropriate. “Mirai” means future, and Mirai is representative of our future: one where you don’t need to be 4chan to take down large chunks of the internet, but can get away with just being the junior high glee club.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Does innovation have anything to do with commerce?]]></title>
            <link>https://medium.com/@enkiv2/does-innovation-have-anything-to-do-with-commerce-3b958d218e41?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/3b958d218e41</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 26 Oct 2016 17:24:12 GMT</pubDate>
            <atom:updated>2016-10-26T17:24:12.037Z</atom:updated>
            <content:encoded><![CDATA[<p>Does innovation have anything to do with commerce? Not any moreso than anything else. Innovative ideas are not necessarily commercially viable, and commercially viable ideas are rarely innovative; the space of commercially viable ideas is small, isolated, and nearly fully mined.</p><p>That said, I can’t agree at all with the idea that we live in a particularly innovative time. Most of the businesses that currently get marked as “innovative” are attempts to revive business plans that failed in 1999 (like Uber); the remainder are businesses that produce shoddy copies of the products of their technically superior competitors but make more money because they spend a bigger chunk of their budget on advertising to tell everyone how “innovative” they are than they spend on actual R&amp;D (like Apple).</p><p>Genuine innovation cannot be easily productized, and as a result, it isn’t really compatible with consumerist capitalism. At the same time, it isn’t easy to mistake genuine innovation for the kind of imaginary pseudo-innovation that is produced by the con-men who dominate most industries. If you can’t tell the difference, you aren’t looking.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[There’s a difference between constructive cynicism and edgelordism.]]></title>
            <link>https://medium.com/@enkiv2/theres-a-difference-between-constructive-cynicism-and-edgelordism-d6ecd5d49b53?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/d6ecd5d49b53</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 26 Oct 2016 14:10:08 GMT</pubDate>
            <atom:updated>2016-10-26T14:10:08.195Z</atom:updated>
            <content:encoded><![CDATA[<p>There’s a difference between constructive cynicism and edgelordism. It’s one thing to have and promote a cynical view in the face of utopianism; to jump onto the tail end of an existing backlash is far less useful.</p><p>Black Mirror, while well-made, tends toward repeating media criticisms that were already cliche in the early 90s. When your complaint is twenty-five years old, repeating it without adding anything is of limited utility; Black Mirror doesn’t introduce new and interesting twists to its complaints, and it doesn’t reproduce anything *but* the complaint.</p><p>(Now, I don’t hate Black Mirror. It’s like rewatching The Twilight Zone: everything is predictable, but there’s really excellent atmosphere.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Mr. Rheingold, thank you for reposting all of these.]]></title>
            <link>https://medium.com/@enkiv2/mr-rheingold-thank-you-for-reposting-all-of-these-ed5de6b10694?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/ed5de6b10694</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 25 Oct 2016 14:04:14 GMT</pubDate>
            <atom:updated>2016-10-25T14:04:14.359Z</atom:updated>
            <content:encoded><![CDATA[<p>Mr. Rheingold, thank you for reposting all of these.</p><p>As an afficianado of computer history, I’m frequently surprised at how little things change, and how often history repeats itself. The field has an amazing institutional forgetfulness; people today are still trying to attack problems that were solved properly by NLS and Xanadu fifty years ago. Ignorance of the history of computer-mediated communication is all too common even among people who are focusing on it, and so we keep making the same mistakes.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Yeah. (I haven’t recommended this for McDonalds before, because I think that the case for food is a…]]></title>
            <link>https://medium.com/@enkiv2/yeah-i-havent-recommended-this-for-mcdonalds-before-because-i-think-that-the-case-for-food-is-a-377f17d10524?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/377f17d10524</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 24 Oct 2016 14:46:12 GMT</pubDate>
            <atom:updated>2016-10-24T14:46:12.965Z</atom:updated>
            <content:encoded><![CDATA[<p>Yeah. (I haven’t recommended this for McDonalds before, because I think that the case for food is a lot more complicated, but I’ve definitely recommended <em>refusing to write bad code</em> to developers, by the same logic.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I don’t deny that there are social norms surrounding the elevation of bad design.]]></title>
            <link>https://medium.com/@enkiv2/i-dont-deny-that-there-are-social-norms-surrounding-the-elevation-of-bad-design-6e7597a81d47?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/6e7597a81d47</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Sun, 23 Oct 2016 18:50:28 GMT</pubDate>
            <atom:updated>2016-10-23T18:50:28.591Z</atom:updated>
            <content:encoded><![CDATA[<p>I don’t deny that there are social norms surrounding the elevation of bad design. Of course people who don’t have to eat their own dog food will have worthless and shallow opinions! But, there’s an ethical aspect to design: would you rather improve the world with good design or get paid more for bad design? There’s a didactic aspect to this as well: these semi-competent people in positions of power have the ideas they do because they have internalized trends that were promoted by actual designers or by people who have placed a heavy hand on the fashions of design; since warped ideas about what constitutes good design among designers caused these norms, corrections to these ideas (along with system-level changes like improved diversity and dogfooding) can correct these norms, albeit on something like a twenty year delay.</p><p>It takes resources to make a stand, so I can’t recommend everyone do so. But, if you’re a designer and you can afford to reject exceptionally bad norms, I recommend doing so. After all, accepting the awful state of design allows it to improve more slowly.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[With the procedural-OO hybrid, we see it applied in industry a little more often because it’s…]]></title>
            <link>https://medium.com/@enkiv2/with-the-procedural-oo-hybrid-we-see-it-applied-in-industry-a-little-more-often-because-its-fa20694969a4?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/fa20694969a4</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 21 Oct 2016 19:07:56 GMT</pubDate>
            <atom:updated>2016-10-21T19:07:56.816Z</atom:updated>
            <content:encoded><![CDATA[<p>With the procedural-OO hybrid, we see it applied in industry a little more often because it’s taught. That said, I think we often use more OO than is justified (I work for a large company and we have a large, essentially monolithic system for loading things from flat files into databases that’s megabytes upon megabytes of java code, most of which consists of less-than-100-line classes with deeply nested inheritance — to perform a task that would be more reliably performed by a single line shell script). When procedural or proper OO is the Right Thing (or, when a procedural-OO hybrid is the Right Thing), we have a leg up on the problem, but until recently most CS program graduates would have very little familiarity with functional or declarative languages.</p><p>The tasks I see at work are rarely good matches for OO: I process large streams of data, mostly, so pipes are the appropriate abstraction. The tasks I see in my personal projects sometimes require OO, and other times are a better match for a functional style; only the simplest pipe-component type tasks end up being something I’d want to use a purely procedural style with.</p><p>That said, we do the tasks we know how to do, and we solve them with the tools we’re familiar with. Very useful tools of the past have been totally forgotten by the industry: how often do you see a junior dev who knows what PROLOG is, or FORTH, or MUMPS, or tumbler indexing of enfilades? I’m very happy that certain useful tools are becoming much more common (asymmetric key encryption and hashing used outside of the context of communications security, for instance, and combining functional programming with implicit parallel execution), but when tools become subject to fashion everyone suffers.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[There’s something strange going on with Russian intelligence & the internet security / civil…]]></title>
            <link>https://medium.com/@enkiv2/theres-something-strange-going-on-with-russian-intelligence-the-internet-security-civil-8f21a672f0c7?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/8f21a672f0c7</guid>
            <category><![CDATA[vladimir-putin]]></category>
            <category><![CDATA[edward-snowden]]></category>
            <category><![CDATA[politics]]></category>
            <category><![CDATA[julian-assange]]></category>
            <category><![CDATA[hillary-clinton]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 20 Oct 2016 16:40:59 GMT</pubDate>
            <atom:updated>2016-10-20T16:40:59.727Z</atom:updated>
            <content:encoded><![CDATA[<h3>There’s something strange going on with Russian intelligence &amp; the internet security / civil liberties axis</h3><p>Julian Assange &amp; Wikileaks have been criticized for distributing pro-Trump Russian-generated propaganda by Edward Snowden. Snowden, despite receiving Russian asylum, has been pretty critical of Putin, even as Assange, whose asylum is provided by Equador, has strangely not been. What is going on?</p><p>Snowden and Assange are one of these political odd-couples: they have come to the same matrix of behaviors and assumptions from different political corners, and have ended up in the same precarious position by leaking important enough material to get people in positions of power to want to lock them up or kill them (even though ostensibly this is not the proximate cause of Assange’s asylum request). Snowden comes at this from the direction of the kind of right-reactionary libertarianism shared with Eric Raymond and Robert Heinlein — a distrust of government if and when it is the most obvious threat. Assange comes at this from the perspective of left-anarchism, filtered through the beginnings of cryptarchism that Assange lived through. While they have little in common outside a distrust of states and state secrets, they both have a kind of western-style civil-libertarian stance that’s pretty common but directly conflicts with Putin and his administration.</p><p>The only thing that all three of these figures (Assange, Snowden, and Putin) have in common is a deep familiarity with spycraft. Snowden was a contractor to two different american espionage agencies; Putin was in the KGB and brought KGB veterans and KGB tactics to his time in office; Assange, in addition to having a particular interest in exposing spycraft and the internal communications of espionage agencies, comes out of a culture of tech-savvy civil libertarians that since its inception in the clipper chip era has had an obsession with spies and espionage.</p><p>If there’s a figure that has even less to do with Assange and Snowden, it’s probably Trump. Putin might have an interest in a Trump presidency over a Clinton one only insomuch as the United States, if competently run, can be a major competitor to and impediment in Russian plans, particularly when such plans clash with those of international organizations in which the United States is a powerful member; Clinton, despite her flaws, is an effective politician and bureaucrat, while Trump is not. Perhaps Assange might dislike Clinton — after all, Clinton is of a piece with the current morally questionable state of governance — but Assange is not stupid and neither a North-Korea-like America nor America as a Russian puppet state aligns with his interests. Snowden has reason to worry about Clinton, considering that if he returned to the United States during a Clinton administration it is clear that she would not step in to save him, but Trump’s Nixonesque strongman stance doesn’t bode well for him either; no matter what happens in November, Snowden is unlikely to be able to return home during the next eight years.</p><p>The only explanation I can think of for the current strange behavior of these figures is that each has his own plan and believes himself to be using the others for it. Of course, in such a situation, all three plans will probably fail and all three figures merely add to the entropy of the social universe. Nevertheless, it’s very strange to see the civil libertarian axis of the infosec community take a hard right-hand turn and its anarchistic major figures show solidarity with secretive and famously corrupt authoritarians.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ham sandwich for president]]></title>
            <link>https://medium.com/@enkiv2/ham-sandwich-for-president-33ea112863cb?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/33ea112863cb</guid>
            <category><![CDATA[2016-election]]></category>
            <category><![CDATA[police-brutality]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 20 Oct 2016 15:33:04 GMT</pubDate>
            <atom:updated>2016-10-20T15:33:04.783Z</atom:updated>
            <content:encoded><![CDATA[<p>Putting Clinton in office is like giving a gun to a police officer: potentially dangerous &amp; problematic in an array of well-understood ways, and best seen as a continuation and extension of a questionable standard.</p><p>Putting Trump in office is like giving a gun to a dementia patient: dangerous and unpredictable.</p><p>Putting Johnson or Stein in office is like giving a gun to a raccoon: a raccoon has no well-defined concept of what a gun is or does, and doesn’t have any thumbs, and so the level of danger is low but non-zero.</p><p>Putting Vermin Supreme in office is like giving a gun to a ham sandwich.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[An Alternate Medium Style Guide]]></title>
            <link>https://medium.com/@enkiv2/an-alternate-medium-style-guide-263e067f6481?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/263e067f6481</guid>
            <category><![CDATA[writing]]></category>
            <category><![CDATA[writing-tips]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 19 Oct 2016 16:01:00 GMT</pubDate>
            <atom:updated>2016-10-19T16:01:00.906Z</atom:updated>
            <content:encoded><![CDATA[<p>I’ve seen several “medium style guides” promoting habits I find irritating. Here’s what you should do instead, if you (for whatever reason) want to attract readers like me.</p><ol><li>Choose a title that properly describes what you are writing about. Overly clever titles are no better than clickbait titles; if I can’t determine the subject of your article from your title, I can’t determine whether or not it’s of interest. This is not to say that titles must be uninteresting; a brief look at the titles of academic papers, particularly in the humanities, shows an exemplary example of how titles can be both direct and humorous.</li><li>Avoid embedding images or other content, unless absolutely required for understanding. It’s one thing to include important diagrams, and another thing entirely to abuse semi-relevant images as a means for breaking up the space. Images use up bandwidth and require extra scrolling for your reader, and often represent potential legal problems for authors; they are in no way an improvement over a vertical bar.</li><li>Don’t artificially limit the length of your article to cater to lazy readers. While short articles may inflate your “read” metrics in Medium’s stats page, they also make that metric less meaningful and devalue the platform as a whole. Instead, write as much about the subject as is interesting. When covering a subject, you can’t know exactly what material a prospective reader will already be familiar with; the longer the article, the greater the chance that even a seasoned reader will come across truly novel material. If you write a short article (less than a five minute read), ensure that what you write truly is novel; otherwise, you have wasted your time and the reader’s, having failed to communicate anything except the idea that you are a shallow and unoriginal thinker.</li><li>Sentence and paragraph size should be dictated by flow. The use of short sentences and short paragraphs does not necessarily make text more readable; usually, it just makes it longer without increasing the amount of information. With very dense information, the extra time it takes to read through the kind of fragmented &amp; decontextualized prose that artificially short paragraphs and sentences produce can actually make reading it much harder: consider the kind of numeric tables found on tax instructions as an extreme example. The english language has an extremely rich set of tools for organizing ideas: understanding the meaning, usage, and behavior of such things as colons, semicolons, commas, independent and dependent clauses, and the passive and active voice produces much more expressive and informationally dense prose than the pseudo-Vonnegut that slavish adherence to period, line break, and active voice will give you. The world is full of short sentences and short paragraphs in short articles; taking proper advantage of the expressive range afforded by english will make you stand out.</li><li>Bold and italic can be useful for emphasis, but are (like the period and the line break) blunt instruments. Do not rely upon typographical style where rhetorical style will suffice: rhetoric is more broadly applicable. Rhythm, alliteration, repeated phrases or patterns, puns, and careful use of the meanings implied but not denoted by idiomatic use of punctuation can all substitute for most uses of bold or italic.</li><li>Cliches are uninteresting because they are familiar. Don’t even mention them.</li><li>A direct argument is a weak argument: even a clear and complete description of one’s own position does not adequately identify or defend from potential counterarguments. A strong argument takes the form of a description of the strongest possible direct argument for the opposition, followed by an explanation of how that argument is flawed.</li><li>Use your vocabulary. Your target audience is not dumb, and has access to all manner of dictionaries; while you shouldn’t use a long word where a short one will do, it is a mistake to reject a long or obscure word that can substitute for a whole sentence. Since most interesting words are not merely longer versions of short words but instead carry a whole vast array of connotations, connections, nuances, and echoes of historical usage, the use of an appropriate interesting word is almost always preferable to a more common near-match.</li><li>Take advantage of, but do not rely upon, mirroring of well-known phrases. Much as with vocabulary, constructions can have baggage, and invoking that baggage can be a quick way to add extra dimensions of reading, at least for those readers who are familiar with the original source or with other usages of these constructions. However, because not all readers will recognize the construction (and an unknown construction is difficult to recognize and look up), your prose should be understandable without this extra information. Take care to ensure that the added dimension is useful rather than simply an indication of the size of your library: some constructions become overused or misused and eventually lose their utility. (As an example, I saw an article beginning “There is a spectre stalking…” in Breitbart: surely the reference is lost on that audience, and anyhow the article had nothing to do at all with Marxism; similarly, using “late capitalism” as a substitute for “capitalism” has almost become an idiom in some circles.) For an example of mirroring done well, take a look at The Society of The Spectacle.</li><li>Don’t force things into lists that are not lists. While numbering things can give the reader an idea of what they’re getting into, numbering things that are not easily or clearly enumerable means that the reader’s heuristic has been foiled. Medium provides reading time estimates, and while these estimates are flawed, they are better than listicle-style titles for indicating the level of engagement expected of readers.</li></ol>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Web design over time has gotten less and less connected to accessibility & utility, and more and…]]></title>
            <link>https://medium.com/@enkiv2/web-design-over-time-has-gotten-less-and-less-connected-to-accessibility-utility-and-more-and-7b8e92f05280?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/7b8e92f05280</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 19 Oct 2016 14:55:37 GMT</pubDate>
            <atom:updated>2016-10-19T14:55:37.033Z</atom:updated>
            <content:encoded><![CDATA[<p>Web design over time has gotten less and less connected to accessibility &amp; utility, and more and more connected to what might look good in a screenshot. Use of color is but one egregious example.</p><p>Of course, low-tech web pages with pure, unstyled HTML (and no formatting tags) continue to work just fine, and continue to load quickly. It seems like, as features become available, designers are using them to optimize for their own experience, not realizing that they should probably be optimizing for screen readers, twenty year old computers connecting over dialup, console-based web browsers without javascript support, and people who need to override styling with their own choice of typefaces, colors, and sizes.</p><p>There are real, accessibility-based reasons to make sure all of these things are configurable and the configuration sticks, but there shouldn’t need to be. When a web designer decides that his own sense of aesthetics matters more than the decisions of the user, a false division is created. The web designer should not be the master in this relationship; the web designer serves the user, and should bow to whatever any user prefers, to the extent possible. This is not the way things work now; instead, web designers act as arbiters of taste, with major consequences for large groups of people.</p><p>Most websites are essentially unusable for the blind or those with major vision problems — and for those of us with vision within the normal range, these websites are merely irritating. The average size of a website is approaching the size of the original shareware release of DOOM — in other words, if your machine is old, or your connection is slow, most sites are again unusable. A dyslexic person may want to set their font to one of the many fonts designed to change bilateral symmetry in order to improve the ease with which letters can be distinguished; CSS tricks are used to disable user-selected default fonts, and when user-selected fonts happen to show through, the sizing, layout, and behavior of the website is negatively affected because the designer has home-brewed a fragile system for implementing controls and layout rather than using standard widgets and sensible defaults.</p><p>A website is not an art project; a website is a piece of machinery that people accept into their lives, like an appliance. Just as nobody would accept a microwave that exploded if you tried to heat up pizza in it rather than baked potatoes, nobody should accept a website that ceases to function when the font is changed. Just as nobody would accept a stool that is nailed to the floor and cannot be repainted, nobody should accept a website that doesn’t respect a user’s color and size preferences. Just as nobody would accept a vaccum cleaner the size of an elephant, nobody should accept a website that takes ten megabytes to serve up 500 words of text.</p><p>A false idea of expert difficulty prevents people from demanding these things from the sites they visit. This idea is false not because modern web design isn’t complicated — modern web design is very complicated, and you really do need to be an expert to practice it. Instead, this idea is false because the only things in web design that are really difficult to do are things that should only be done rarely, if at all. The web is optimized for transmission of large chunks of minimally-styled text; using it to simulate native applications, while impressive, is a terrible idea and should never have become normalized.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[No title]]></title>
            <link>https://medium.com/@enkiv2/5e146689d8ff?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/5e146689d8ff</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 18 Oct 2016 17:20:22 GMT</pubDate>
            <atom:updated>1970-01-01T00:00:00.000Z</atom:updated>
            <content:encoded><![CDATA[<p></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I was once on cleanup duty, in a particularly unfortunate situation.]]></title>
            <link>https://medium.com/@enkiv2/i-was-once-on-cleanup-duty-in-a-particularly-unfortunate-situation-35af9955a286?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/35af9955a286</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 17 Oct 2016 19:20:22 GMT</pubDate>
            <atom:updated>2016-10-17T19:20:22.882Z</atom:updated>
            <content:encoded><![CDATA[<p>I was once on cleanup duty, in a particularly unfortunate situation.</p><p>I got a chance to work for a long-time hero of mine: someone who was influential in computer science circles in the 60s and 70s, who (while fairly non-technical himself) has a lot of ideas that haven’t really been given the chance they deserve. Along with a friend I had roped in, we embarked upon trying to ‘finish’ a ‘prototype’ that had been provided several years before by a self-taught programmer who had never worked on a large project before. He had told the man we were working for that he had gotten it very nearly finished, and it did demo nicely, but he burned out so badly that he ended up (from what I understand) in a mental hospital for a while, and had been out of touch and unable to work on that or any code for several years by the time we saw it.</p><p>Initially, the problem was that we couldn’t find any of the code. We were told that it was a combination of C++ and python, wherein python was being used as a plug-in language; we found no C++ or python code in any of the “source” zip files we were given, and while revision control had been provided, this guy never used it except once, right before he quit, to check in all the windows binaries and a whole bunch of screenshots and videos of various prototypes, along with a couple pieces of out of date documentation and a pdf copy of Dive Into Python.</p><p>Eventually, after much digging around on the part of various parties who at one time or another had copies of this, we got a large zip file that contained a nested series of smaller zip file copies of the same directory structure with progressively earlier dates. On the third or fourth level down, we found a single C++ file.</p><p>We discovered that this single C++ file contained all of the C++ code for the entire project. Nearly all of it was commented out, using line (not block) comments. It wouldn’t build on any platform — it had a bunch of typos and wasn’t actually valid C++; in other words, the only copy we had of the C++ source was a messy, old, in-between version. But, inspecting it, we discovered that it had partial C++ implementations of several functions that were supposedly “done” (such as loading and parsing a proprietary file format), which were mostly disabled. It was difficult to determine which of these were disabled, because there would be several functions with almost the same name that had nearly exact duplicates of the same code, and various caller functions would use various version. Often we discovered that some function that was closest to complete-looking couldn’t possibly work, only to discover later that the only call to the whole chain of operations had been disabled and replaced with some hard-coded value. This single C++ file was several megabytes in size.</p><p>Eventually, in order to make it easier to debug, we separated this file into about ten, by categories laid out in this (obsolete) documentation, and determined which blocks of code were definitely not close to functional, removing them. After this streamlining we got the size down quite a bit, but discovered that nearly all of the functionality was missing. Complicated mechanics behind drawing, file parsing, object placement, and structure were nowhere to be found, but it built and worked — on windows, at least. (It had also been sold as cross-platform despite being build in visual studio; it turned out that it was windows-only, but mostly because the author had used a windows-specific sound library to play notification sounds instead of using the one that came with SDL. We quickly fixed that.)</p><p>Combing through the code, we discovered that there was a single line early in execution that loaded a hard-coded arbitrarily-named text file (“abiowy2222.txt” or something) as a python script. We found a directory full of strangely named text files, and while some of them were full of junk (copied and pasted pieces of documentation or forum discussions, lists of error messages), about half of the 100+ text files were partially overlapping versions of a big chunk of python code.</p><p>It turns out that this text file contained a bunch of python code that performed a bunch of calls back into C++ to perform draw calls on some large chunk of hard-coded data. This programmer hadn’t bothered to write code for loading that ugly file format he designed; he hardcoded the content of the one file he was using for the demo. He had skipped writing the logic for determining layout, and instead had hard-coded the positions for the objects described in this file. And then, this python file had its own main loop and exited at the end of it — in other words, nearly all of the C++ code was entirely disabled.</p><p>We endevoured to rewrite pretty much all of this logic, and we did, at least twice. We wrote an actual implementation of the file format loader (and discovered that most of the examples we had were subtly corrupted) and an actual implementation of the layout logic, both in C++. While trying to debug a (semi-independent) module that implemented a kind of non-relational database based on a graph of arrays of pointers, we decided to attempt a pure python implementation, in the hopes that it might be fast enough to be a good comparison. (This original author was obsessed with premature optimization and with using obscure features of C++, and had comments next to each function calculating — typically totally incorrectly — how many bytes per object were being transferred. The database was implemented in an overly complicated way for documented speed-related reasons, but it turned out to be both slower and more bug-prone than the straightforward and naive approach we took in python, across many varied tests.) Having determined that this database in its C++ form was essentially beyond salvaging, we used the python version instead, and spent a great deal of time trying to square the fact that initial draw time was so fast with the extreme slowness of interactivity. We ended up rewriting most of that draw code, before rewriting all of it from scratch in python in a single all-nighter. This all-nighter occurred about two years after we initially started working on this project.</p><p>We did this for free, since we were doing it for a mutual hero, but it really put us off the idea of playing the role of code doctor in the future.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Intellectual property is the strongest it’s ever been, more or less worldwide.]]></title>
            <link>https://medium.com/@enkiv2/intellectual-property-is-the-strongest-its-ever-been-more-or-less-worldwide-1c2e91ed5447?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/1c2e91ed5447</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 17 Oct 2016 18:33:26 GMT</pubDate>
            <atom:updated>2016-10-17T18:33:26.057Z</atom:updated>
            <content:encoded><![CDATA[<p>Intellectual property is the strongest it’s ever been, more or less worldwide. Large, powerful organizations with enormous IP portfolios are active in the machine learning space: IBM has a huge number of active patents, and Google and Apple are both busy stockpiling them from third party sources. Even if learning models are legally determined unpatentable, that doesn’t keep people from attempting to (and often succeeding at) filing patents for them; the nonexistence of such patents doesn’t prevent any company with lawyers and brass balls from attempting to defend them (and any other nebulous or imaginary claims) in civil court.</p><p>Even if, somehow, these extremely powerful forces don’t manage to get their way in terms of ensuring learning models are protected by some form of strong IP (copyright for individual models or patent for novel formulations), and somehow the IP litigation system that has for decades been systematically favoring IP holders and ignoring strong fair use cases reverses tack, and somehow these companies forget that they could make a trade secret claim — in other words, even if somehow our dysfunctionally overpowered IP system suddenly started working properly — learning models are hardly the most common forms of potentially protected work, and they are years away from being capable of producing work of equivalent quality to most protected work. In other words, the end of protection for learning models is insignificant compared to the scale of IP.</p><p>Theft of learning models, of course, is both trivial and unprovable. A system intended to produce certain outputs for certain inputs can be trained on the same data or can be trained on API calls; as scale the result is the same, but the innards will be uncomparably different even for a very close match in behavior. Much like other behemoths of tech, the factor that would keep competitors out of the race with machine learning based API services is not the (public) concept or the (trivial and novel, mostly off-the-shelf/open-source) implementation but the cost of scaling to meet demand — anybody can write a facebook knock-off in a weekend but only facebook and a few others can afford the server cost to host facebook’s audience. Similarly, anybody can download tensor flow or torch, but few people can afford the cycles to train it on the entire google books corpus and add new books as they are released.</p><p>We don’t call facebook knock-offs (even very close ones, like those used for phishing) copyright infringment and consider them subject for suit, even though they definitely are using image assets against TOS; instead, we treat them as either legitimate attempts at competition doomed to failure or as cheap knock-offs indended to trick us. Likewise, trademark law is rarely applied directly against parasitic industries like that of mockbusters — the legal risk of loss of protection is low, and large film companies are mostly fine with allowing the parasites to continue preying on people with poor vision or damaged faculties of judgement who can’t distinguish between “Transformers” and “Transmorphers”; Universal is happy knowing that Asylum will never be able to compete with them head to head, and once the current generation of executives dies off and is replaced, they will treat internet piracy the same way.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[To “compete” in web search results is somewhat absurd.]]></title>
            <link>https://medium.com/@enkiv2/to-compete-in-web-search-results-is-somewhat-absurd-5a39fc941fe?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/5a39fc941fe</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 17 Oct 2016 18:06:12 GMT</pubDate>
            <atom:updated>2016-10-17T18:06:12.440Z</atom:updated>
            <content:encoded><![CDATA[<p>To “compete” in web search results is somewhat absurd. One-off retailers are rightly viewed with suspicion, and making a living off web advertising is something available only to sites at the scale of BoingBoing.</p><p>Make good content, ignore monetization, and you may end up with the self-satisfaction of a job well done. Engage with any form of monetization and you lose even that. Good content doesn’t need to appear high in search results, and doesn’t require monetization: if you post things that are of interest and aren’t already on the web, you will attract an audience; break either of those two rules and you are not posting good content but instead are at best acting as an aggregator (and then you’re competing with reddit). If you have an audience and a community, you can get support when you need it.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The legality of the provenance of the material is irrelevant to the ethics of reporting.]]></title>
            <link>https://medium.com/@enkiv2/the-legality-of-the-provenance-of-the-material-is-irrelevant-to-the-ethics-of-reporting-dcc6f28329bf?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/dcc6f28329bf</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 17 Oct 2016 17:58:22 GMT</pubDate>
            <atom:updated>2016-10-17T17:58:22.469Z</atom:updated>
            <content:encoded><![CDATA[<p>The legality of the provenance of the material is irrelevant to the ethics of reporting. After all, leaks like this are not being submitted directly to outlets: they are being handed to the public. To the extent that journalists have to worry about reporting on leaked material, they have the same concerns about publicizing any other effectively non-secret information: do they do more harm than good by repeating something to a wider audience?</p><p>The question becomes more complicated when an outlet receives the content of a leak directly, as happened with the Snowden documents: in that case, the material is still effectively secret, and releases must be carefully vetted, because in a sense the outlet is conspiring with the leaker, and is the party providing damage control.</p><p>Reporting on public leaks should be treated the same way as reporting on suicides or other sensitive yet non-secret events: they should be news if they are newsworthy, and they should be reported on in such a way that minimizes damage that might come directly from the manner of reporting rather than from the facts being reported.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The Lone Gunman]]></title>
            <link>https://modernmythology.net/e0962a75f571?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/e0962a75f571</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 30 Sep 2016 16:49:51 GMT</pubDate>
            <atom:updated>1970-01-01T00:00:00.000Z</atom:updated>
            <content:encoded><![CDATA[<p>There’s a lot of debate about gun control in the United States. However, both sides, by participating in the conversation at all, have a central confusion. The gun control debate isn’t (or at least shouldn’t be) about guns at all.</p><p>Gun control advocates and anti-gun-control advocates typically focus on the use of firearms in a very specific situation: when firearms are used in <em>mass</em> violence. The debate centers around <em>mass</em> shootings on one hand, and on the other hand, upon self defense against a <em>large</em> group of targets. Regulation debates focus on automatic and semi-automatic weapons and large clips. This is strangely at odds with reality. After all, even a machine gun is significantly less effective at mowing down large numbers of targets than a bomb — or a car. The firearm is a weapon oddly unsuited to mass murder: even for semi-automatic weapons, the ideal use case is against a single easily identified stationary target from relatively far away. As a weapon, a gun is a great deal like a bow and arrow, although a gun can shoot farther with more accuracy and with greater force, and it’s faster to reload its projectiles. This should be enough to immediately reject both sides’ arguments from the perspective of materialism: any constraints placed on guns should be placed doubly or triply on automobiles, pressure cookers, fertilizer, boats, and weak poisons. The argument isn’t about guns as physical objects.</p><p>If the best analogy to the gun as a physical object is the crossbow, then the best analogy to the gun as a symbol is the katana. Physically, the katana is a very limited weapon: it’s a sword, long and heavy enough to take a great deal of effort to wield yet with clearly shorter range than a projectile weapon or even a spear or lance; created via a laborious process made necessary by the poor quality of Japanese iron deposits and the relatively primitive state of Japanese metalworking techniques, even katanas legendary for their high quality steel would be laughed at by medieval european blacksmiths. Yet, because of the association between the katana and the samurai class (enforced by multi-century rules about who was allowed to own these weapons), the katana has incredible symbolic power. In an age where actual warfare in Japan was largely being performed by domestic copies of imported Portugese flintlocks, a sword ban was instated to keep the samurai down. Even today, Japanese cinema is full of sword users, and invents magical techniques by which the sword might act as a ranged weapon. Despite its impracticality as an actual weapon, the katana has an incredible symbolic power to the Japanese (and to some westerners) that keeps it from being ignored. The katana represents a romanticized view of the samurai, and especially the ronin — in other words, it represents the image of a lone warrior who maintains his pride despite disgrace and whose power comes from intense training and self-discipline.</p><p>It is another such image that keeps the idea of the firearm relevant in a world where most actual warfare is performed by bombs of varying degrees of autonomy: the image of the lone gunman.</p><p>Let us examine the action hero. He is a middle-aged white man — never young, never black, never blonde or a red-head. He is very much like the standard FPS protagonist. He is muscular, poorly shaven, and is usually either ex-police or ex-military (although occasionally he is still affiliated, but not considered a part of the in-group). He works alone. He fights a large and organized force of well-equipped enemies; he does not do so out of some traditional defense of “justice” or “the law” (because he is too cynical to believe in such things) but instead for some intensely personal reason (usually to protect or avenge a family member, who is most often female). Even as the enemy uses bombs, noxious gasses, poisonous injections, throwing knives, or other weapons, our action hero protagonist uses firearms; to the extent that he uses any other weapon, he does so out of necessity, improvising, after he loses his gun or runs out of ammunition, and the weapon he improvises is almost never more destructive than a gun. (This is mirrored in samurai flicks, particularly in parodies — in the first episode of Gintama, the title character destroys a highly advanced alien-made nuclear weapon by hitting it with a wooden sword, having refused to accept a laser gun previously.) The action hero doesn’t plant bombs, although he may allow the enemy to be blown up by their own bombs; when encountering a piece of destructive machinery, even after defeating its operator, the action hero will not choose to use it, except perhaps as a transportation device, and any destructive effects of such a device will be accidental — our action hero won’t steal a tank, and although he might steal an attack helicopter he won’t use the helicopter’s bombs or machine guns.</p><p>Our gun control advocates fear the action hero to some degree; after all, the action hero works toward the goal of a safe society only incidentally. Our gun control advocates also fear those actual human beings who have been possessed by the action hero / lone gunman archetype: school shooters, right-wing terrorists, and corrupt cops. To some degree this is justified: while the action hero himself does not and cannot exist, those who have sublimated themselves into this archetype can do quite a lot of damage before their luck runs out. However, in another sense, this is foolish: the terrorist who packs a machine gun instead of a bomb is a bit like the man who tries to take on the army with a sword; he has confused symbolic strength with literal strength, and the limitations of his weapon will prevent him from doing nearly as much damage as he expects. In a sense, those who fear these groups should feel lucky that they suffer under the delusion that their weapon of choice is ideal; were they to replace their media consumption with proper training and think clearly about weapons as tools, they would be far more dangerous.</p><p>On the other hand, those who fear gun control identify strongly with the action hero, or at least believe that they could become his manifestation under the right circumstances. People who hoard guns against what they see as an oppressive government are operating on action movie logic: a small group of people with automatic weapons cannot even <em>defend</em> themselves against a national army, although a single con artist could probably decimate a national army with some poison and a great deal of courage.</p><p>The lone gunman, though he is often associated with the religious right’s reformulation of Randian Objectivism, in a sense is a stranger bedfellow with Objectivism than the religious right itself is. No Randian hero, the lone gunman is a loser who does not win, but instead causes others to lose. He never profits from his actions, nor does he intend to; he comes into the story already damaged and rejected by a world that he doesn’t fit into, and his goal is to save someone (usually a family member) from a threat that appears after the beginning of the narrative, or to take revenge for that threat. He plays only negative sum games: his goal is to return to the same level of dysfunction he is used to, having caused harm to some third party (usually some variety of “foreign terrorist”). The family he rescues is one he is almost invariably estranged from, just as he invariably has a warped relationship with the career that gave him the training he uses: while usually a former soldier or police officer, if he happens to be a current officer he is a pariah.</p><p>I would place the beginning of the lone gunman figure in film with the release of Die Hard. The elements of Die Hard that were originally (in the style of the Last Action Hero) a satire or subversion of action movie tropes eventually became the defining traits that separate the lone gunman from older 80s-style action hero figures, and these traits are important to note: the lone gunman, though skilled, is not ‘fit’; rather than being a well-rounded person who happens to excel at violence, this figure is a loser and outsider who (in a strange warping of the hero’s journey) discovers that he has a talent for violence when he is thrust into a situation where he uses it. He may be an ex-police-officer, but he can fight off hundreds of current police officers who have better training. Much like how, out of context, the stories of popular detective characters appear to be about a person who supernaturally attracts criminal acts to happen around them, the lone gunman appears to attract swarms of unrelated attacks.</p><p>I would like to also distinguish the lone gunman figure from another star in our constellation of men of action, the hardboiled detective. While the hardboiled/noir protagonist appears to have much in common with the lone gunman — both are losers thrust into lives of violence to which they are unnaturally acclimated, within the matrix of a society they cannot integrate into — the hardboiled protagonist’s cynicism is always a put-on. A hardboiled protagonist, being a “shop-worn Galahad”, has more in common with the ronin figure or with the hero of westerns: he may pretend to have purely selfish and material reasons for his actions, but he acts according to a strict moral code he would rather not admit he adheres to. The cynicism and nihilism of the lone gunman figure is real, and in an inversion of the hardboiled protagonist, the lone gunman acts as if his behavior is justified by familial loyalty or revenge, when it is clear that revenge is just an excuse for immersing himself in a world of violence. Where all other action hero protagonists are acclimated to violence by necessity and are at least as estranged from violent exchange as they are from the rest of the social world, the lone gunman has a greater connection to violence than with the every-day. All other forms we have discussed are rejects who carry a set of moral guidelines from a world that no longer exists or is closed to them; the lone gunman has never had a home, but finds one in the process of taking revenge, and his moral sense is warped accordingly.</p><p>In other words, the lone gunman breaks from the tradition of justified violence, instead engaging in violence that justifies itself: loss for loss’s sake. Hardly sociopathic; this is instead the logic of a perpetually frustrated death wish. That this resonates with society is interesting but not impossible to predict: prescriptive codes of ethics, to the extent that they are narratively interesting, must be problematic (a hardboiled protagonist who will “never hit a woman” is foiled on several fronts, not least by wicked women who take advantage of him); furthermore, prescriptive codes of ethics also don’t age well, particularly now that widespread and fast communications across demographics have brought about a nearly scientific style of inspection of moral and ethical issues in the public sphere. An everyman whose abilities are unknown to him at the start, the lone gunman can become an aspirational figure for those who have no skills but suspect that they may discover that they too can mow down faceless waves of military police if given the opportunity. Finally, the lack of interiority in the lone gunman figure — the reliance on a supernatural luck, the lack of planning or aspirations, and the absence of intellectual rather than material challenges — is easily mistaken for unflappable cool: it is not that the lone gunman is unflappable out of some internal wellspring of strength, but instead because there is nothing inside him to flap.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I for one appreciate your resistance to cutting down your articles.]]></title>
            <link>https://medium.com/@enkiv2/i-for-one-appreciate-your-resistance-to-cutting-down-your-articles-60ea45c60b59?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/60ea45c60b59</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 17 Oct 2016 17:08:03 GMT</pubDate>
            <atom:updated>2016-10-17T17:08:03.678Z</atom:updated>
            <content:encoded><![CDATA[<p>I for one appreciate your resistance to cutting down your articles. I like to read deep, informative writing, and your work here on medium is some of the best.</p><p>There’s a trend toward short (~500 word) articles here; it’s a trend that won’t survive, since it alienates people who want a less casual approach to learning.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[In defense of contempt]]></title>
            <link>https://hackernoon.com/in-defense-of-contempt-c563a8e4449?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/c563a8e4449</guid>
            <category><![CDATA[javascript]]></category>
            <category><![CDATA[programming]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 14 Oct 2016 14:37:20 GMT</pubDate>
            <atom:updated>2016-10-14T14:37:20.756Z</atom:updated>
            <content:encoded><![CDATA[<p>A response to <a href="http://blog.aurynn.com/contempt-culture">a popular article</a></p><p>The article in question suggests that the habitual tribalism &amp; combative style in communication within the tech community is toxic, particularly to minorities; I do not dispute this point. The article in question also suggests that criticism of languages and technologies should be avoided because it often discourages community diversity, and this is where the author and I part ways.</p><p>The state of the programming community is poor, with regard to diversity, and this leads to all sorts of systematic problems that are self-perpetuating. However, the state of the programming ecosystem is also poor, and the perception of acceptability given to bad tooling and bad habits leads to systematic and self-perpetuating problems of its own. The way to increase acceptance of outsiders into the community is not by sacrificing the very worth of the enterprise the community exists to engage in; indeed, it’s entirely unnecessary to do so.</p><p>The author decries the tribalism of the community with regard to tooling, but differences of opinion when it comes to preferred tools is not a meaningless aesthetic distinction. The prevalence of overflow-related vulnerabilities in real software ultimately comes down to the popularity of C over Pascal historically; as many exfiltrations of password files and other sensitive data are owed to the use of outdated PHP best practices as can be attributed to SQL injection (and thus, lack of input validation); the poor state of Windows security prior to 2001 when compared to competitors at the time ultimately comes down to the decision to avoid taking full and proper advantage of hardware memory management, setting up a proper system of user privileges, and other common practices in the domain of network-connected multi-user OSes — in other words, Windows was a leaky sieve and prime target for over a decade because lazy habits that were acceptable for single-user isolated machines with no real multitasking were being applied to a huge number of interconnected boxes.</p><p>The results of using a poor tool or using a good tool poorly are a lot like the results of ignoring modern medical science: in isolation, they might be acceptable for a handful of people who don’t have it rough, but in aggregate they result in epidemics. Someone who writes ostensibly production-ready code in PHP or Perl should be treated like someone who refuses to vaccinate their children: their behavior should be considered acceptable only if they are extremely careful and they have a very good excuse. Someone who promotes the use of tools that encourage the production of bug-prone insecure code outside the context of isolated personal experiments should be treated the same way we treat antivaxxers: as a perhaps well-meaning but deluded person whose misinformation is resulting in major destruction.</p><p>When someone has different aesthetic preferences, it’s natural to accept that. But, when a group that is already marginalized disproportionately adopts a set of tools that are well-known to be destructive and then dedicates enormous resources to the use of those tools, we don’t decide that those tools must be acceptable on aesthetic grounds despite their known destructive potential: we instead try to discourage that group from associating with those tools and figure out what forces are creating that association.</p><p>Poor tools are often the domain of beginners, and those who dedicate sufficient time and effort eventually graduate from those poor tools to better tools. (I first learned to program in QBasic.) That time and effort isn’t free, so people who are already under other extra constraints (including people who have extra social or financial pressure) often never move on.</p><p>There’s another factor here, however: good tools in some ways often become poor because they become popular with beginners. Most tools are optimized for a small set of problem domains, work acceptably in some others, and work horribly in every other domain. A beginner, having experience with only one tool, will apply this tool to every domain; if problems in some domain are harder to solve with this tool, the beginner, unless properly instructed, will believe the problems in this domain are simply inherently harder to solve. As a tool becomes popular with beginners, experts become difficult to identify in the crowd, and slightly elevated beginners begin to become treated like experts simply because there are many more slightly elevated beginners than experts; these pseudo-experts will popularize poor habits in the community, and these habits beocme associated with the tool itself. An expert who uses many tools will have less say in the community surrounding one tool than the many enthusiastic beginners who are unaware of or reject all other tools. To some degree, the most toxic tribalism is that of beginners who don’t think of programming languages or techniques as tools and identify themselves with their preferred tools.</p><p>We should separate criticism of tools based on legitimate concerns from criticism of tools based on tribal or class issues. Plenty of tools can be used well but largely aren’t because most of their devotees are beginners (see: Java, C, C++, Python). Other tools are fundamentally flawed, and while using them well is not impossible, it is a trick that takes a great deal of experience and is beyond the scope of nearly all of its audience (see: PHP, Perl, Javascript). Some tools have lost a great deal of respect because most of their ecosystem is populated by tooling that’s orders of magnitude worse than their original design, compounding flaws (see: Java, Javascript, Ruby). Other tools are perfectly fine for what they were designed to do but are almost always used for things they’re terrible at (see: Perl, Javascript, Lua, TCL). The popularity of a tool with beginners can certainly negatively affect the suitability of that tool in genuine and valid ways if the beginners are given sufficient control over the tool’s later evolution, so it’s not as though a tool’s popularity with beginners is inherently irrelevant, but a good tool can be used well even as most people use it poorly.</p><p>There’s another interesting tendency with regard to the popularity of certain tools with beginners, and it’s one that’s wrapped up with institutions and politics. This is the matter of pedagogy. Java is currently extremely popular, but its popularity owes little to its attributes and much to the fact that it has become part of a standard; there is a curriculum surrounding Java focusing on a Java-centric view of object orientation, and this curriculum forms the basis of both the AP Computer Science curriculum in the United States and various certification and accreditation rules for university programs. In other words, if you live in the United States and you are not an autodidact your first programming experience (barring a bootcamp) will probably be in Java, combined with a curriculum that focuses on UML, inheritance, and the details of Java-style encapsulation, while completely ignoring performance concerns and systematically denying that some problems are not easily represented in an object oriented model. Prior to Java, these programs centered on C++, with a similar set of foci. In other words, for several decades, students with no prior programming experience have been taught that there is one language (Java or C++) and one technique (Java-style OO) that is the best at everything, and as they filter into industry they work with other people who went through the same indoctrination and continue to produce huge ugly monoliths of inefficient Java and C++ “enterprise” code. This is the end-game of letting an echo chamber of like-minded beginners dictate the state of an industry.</p><p>So, what do I recommend, with regard to the problem of balkanization in tech pushing out minorities?</p><p>I consider this really to be an issue of beginners graduating to higher levels of understanding (and systematic pressure making it harder for certain groups to graduate out of the beginner classification), and one way to help this is to be extremely clear in your criticisms about the nature of the problems you criticize — in other words, rather than saying “PHP users are dumb”, say “PHP is a deeply flawed language, and PHP users should be extremely careful when using these particular patterns”.</p><p>Another way is to make it clear that using a single language is not acceptable in a professional context: any serious developer has a large toolbox already, and if beginners understood that language preference is not a reasonable basis for long-term tribal divisions because any professional belongs to multiple tribes, the toxic identity-based hostility between programming language communities would mostly go away, allowing concrete and issue-based critiques to become more visible.</p><p>Also, seasoned developers who frequently work in many languages and have a deep understanding of the positive and negative aspects of many tool designs should become more vocal about tooling: even-handed discussions about this subject make it easier for beginners to graduate into well-rounded developers and avoid making common mistakes that lead to wide-scale disaster.</p><p>Finally, standardized programs for computer science education should include language survey courses earlier and feature them more prominently, while removing some of the pro-OO bias that currently characterizes them: nobody should be able to graduate with a CS degree without being truly competent in at least five or six very different languages, rather than the typical gamut of Java, Javascript, and SQL, and they shouldn’t graduate without non-trivial exposure to twenty or thirty more.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Javascript won’t save the web. Javascript is part of the problem.]]></title>
            <link>https://medium.com/@enkiv2/javascript-wont-save-the-web-javascript-is-part-of-the-problem-6da71ec073c9?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/6da71ec073c9</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 14 Oct 2016 17:52:35 GMT</pubDate>
            <atom:updated>2016-10-14T17:52:35.398Z</atom:updated>
            <content:encoded><![CDATA[<p>Javascript won’t save the web. Javascript is part of the problem.</p><p>The existence of HTML (and any embedded markup) is part of the problem, and generating all elements with Javascript won’t help. CSS didn’t save the web from HTML because the CSS/HTML division misunderstood the problem: content chunking is inherently part of presentation, not content, and any presentation layer should be an external (rather than embedded) markup that can style and rearrange arbitrary spans of content (presumably based on byte or character indices).</p><p>HTTP is part of the problem. HTTP doesn’t distinguish between dynamic and static documents, and while it has facilities for representing redirects, moved files, and other potentially useful features, nobody implements or uses any parts of HTTP other than the behavior of codes 200, 404, and (occasionally) 500; even very useful features like partial download requests and file time requests are inconsistently supported.</p><p>HTTPS is part of the problem. Hierarchical certificate signing chains will always be vulnerable to leaked top-level certificates, and poor support for certificate revocation will continue to slow adoption of improved hash algorithms.</p><p>DNS is part of the problem. The association between hostnames and IPs is only useful from the perspective of a machine (or a programmer thinking at the machine level); the association that is useful to users is one between names and chunks of data, or sometimes between names and services.</p><p>Javascript in a web context will never save the web, in the same way that a tumor will never cure cancer. The problems with the web go a whole lot deeper than the front-end concerns that Javascript can address.</p><p>If you want to know what *might* save the web, take a look at IPFS &amp; IPNS, then take a look at Project Xanadu.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I switched to NaNoGenMo because of similar commitment problems.]]></title>
            <link>https://medium.com/@enkiv2/i-switched-to-nanogenmo-because-of-similar-commitment-problems-207d817323da?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/207d817323da</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 13 Oct 2016 14:44:01 GMT</pubDate>
            <atom:updated>2016-10-13T14:44:01.842Z</atom:updated>
            <content:encoded><![CDATA[<p>I switched to NaNoGenMo because of similar commitment problems.</p><p>Pros:</p><ul><li>You will probably produce much more than one novel. (I usually produce one during the first half-hour of November 1st just to get it out of the way, and then work on more interesting / complicated projects afterward)</li><li>There’s a pretty active community, with deep and precise discussions of things like structure and themes, because computer generation of long-form narratives that remain interesting to humans over the course of 90+ pages is a hard problem.</li></ul><p>Cons:</p><ul><li>You need to know how to code</li><li>The novels you generate will be even less likely to be salable than the hurried work of an amateur human novelist</li><li>Explaining the concept to people who aren’t familiar with it is even harder than explaining NaNoWriMo, because a lot of people are somehow unaware that computers can write books</li></ul>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[You’re struggling with some of the same conundrums as I am.]]></title>
            <link>https://medium.com/@enkiv2/youre-struggling-with-some-of-the-same-conundrums-as-i-am-2693c6315b29?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/2693c6315b29</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 12 Oct 2016 18:03:40 GMT</pubDate>
            <atom:updated>2016-10-12T18:03:40.555Z</atom:updated>
            <content:encoded><![CDATA[<p>You’re struggling with some of the same conundrums as I am.</p><p>For some years, I’ve been playing with automated text generation. After seeing the coverage of the gaming of short Kindle erotica, I verified that erotica was easy to generate. But, while I would have very little problem “scamming amazon”, I definitely would like to avoid scamming amazon’s customers. So, I was wondering what I could possibly do to separate machine-generated erotica for people who get a kick out of the idea of machine-generated erotica from machine-generated erotica designed to be passed off as human-generated erotica until after the sale. Does clear disclosure in the book summary and author summary constitute sufficient cover? Does clear disclosure mean I get banned by Amazon due to their mysterious content policies? I’m enough of a tightwad myself that I’d be mortified if somebody spent $0.99 on an ebook of mine without knowing beforehand that it was 300 pages of algorithmic churn.</p><p>Interesting work keeps getting done in the margins, and some gems (like Tingle) appear in the thieves’ quarter, so distinguishing oneself from the thieves in at least intent is very important. But, if you do a thing that scammers do, does disclosing it make you no longer a scammer? And, in whose eyes?</p><p>I think often, the people who pay for content farm extruded erotica aren’t themselves being scammed: they got what they expected to get, and considered the gonad-tickling suitable for what they paid; instead, the scammed party is perhaps Amazon (who would prefer to have a better reputation), or the workers on Mechanical Turk (who decided to accept this but maybe should be making at least minimum wage), or nebulous other parties even less directly affected.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Upending the system requires effort and planning.]]></title>
            <link>https://medium.com/@enkiv2/upending-the-system-requires-effort-and-planning-c6b34e7adeb3?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/c6b34e7adeb3</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 11 Oct 2016 18:50:45 GMT</pubDate>
            <atom:updated>2016-10-11T18:50:45.929Z</atom:updated>
            <content:encoded><![CDATA[<p>Upending the system requires effort and planning. Electing a moron is going to produce business-as-usual-with-extra-drama, which is not an improvement over business-as-usual-with-extra-efficiency.</p><p>Actual improvement has to come from someone with a knowledge of the mechanisms of government and how they can be subverted. We don’t have time for a fuzzing attack on government — by the time such an attack has any meaningful results we’ll be long dead. We need someone to exploit known vulnerabilities.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The way I think of it, trying to learn computer science without learning C is like being a medieval…]]></title>
            <link>https://medium.com/@enkiv2/the-way-i-think-of-it-trying-to-learn-computer-science-without-learning-c-is-like-being-a-medieval-da597a925b8b?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/da597a925b8b</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 11 Oct 2016 12:41:07 GMT</pubDate>
            <atom:updated>2016-10-11T12:41:07.363Z</atom:updated>
            <content:encoded><![CDATA[<p>The way I think of it, trying to learn computer science without learning C is like being a medieval scholar trying to learn medicine without first learning Latin: whether or not you *like* it doesn’t matter, because it’s simply the language everything has been written in since the 70s; while you can get by without learning any one specific minor language (read: pretty much everything but C is a minor language), no matter what language you prefer to write in you will need to be able to read C.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[You missed one *big* factor in why SV isn’t good to emulate: SV is mostly “show business” — big…]]></title>
            <link>https://medium.com/@enkiv2/you-missed-one-big-factor-in-why-sv-isnt-good-to-emulate-sv-is-mostly-show-business-big-2f4bb38c1c7?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/2f4bb38c1c7</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 10 Oct 2016 16:49:01 GMT</pubDate>
            <atom:updated>2016-10-10T16:49:01.591Z</atom:updated>
            <content:encoded><![CDATA[<p>You missed one *big* factor in why SV isn’t good to emulate: SV is mostly “show business” — big phantom valuations for vaporware, etc. SV’s startup culture is systematically absurdly prone to being taken in by BS, compared to all the places where a “tech startup” is just called a “small business”.</p><p>It’s one thing to mimic a system that’s truly been shown to work once. It’s another thing to mimic the simulacrum described in the marketing materials of a system that, like a ponzi scheme, pulls in wave upon wave of fresh meat to dash against the rocks in order to produce the raw material used to prop up a handful of names that can be passed off as “success stories” in later brochures. Because of the enormous amount of churn and hype, it’s often hard to tell that SV has in many ways an abnormally high failure rate, with even its successes still failing to make money; after all, real success is boring and undramatic: real success is the family laundromat on the corner that’s been running for eighty years, not the social network for dogs that gets a six billion dollar valuation on paper because the VC had the hots for one of the presenters and then crashes six months later because nobody wanted it.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Please badmouth CSS more in developer talks]]></title>
            <link>https://hackernoon.com/please-badmouth-css-more-in-developer-talks-bf2afeca1a27?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/bf2afeca1a27</guid>
            <category><![CDATA[css]]></category>
            <category><![CDATA[web-development]]></category>
            <category><![CDATA[programming]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 06 Oct 2016 12:57:51 GMT</pubDate>
            <atom:updated>2016-10-06T12:57:51.165Z</atom:updated>
            <content:encoded><![CDATA[<p><em>A response to a </em><a href="https://www.christianheilmann.com/2016/10/05/can-we-stop-bad-mouthing-css-in-developer-talks-please/"><em>popular article</em></a><em>.</em></p><p>The appropriate response to a perceived competence gap between web development and application development is not to fake admiration for the worst tools of web developers, but instead a concerted effort to improve tools and knowledge in both communities. If someone’s complaints about CSS make you feel like your skills are being belittled — well, that’s probably an indication that you need to improve your skills, and learning why your preferred tool is bad is a good first step.</p><p>The fact that some people are capable of making impressive things with a tool does not make the tool good. Making impressive things with bad tools (or with good tools that are intended for a completely different purpose) is a tradition in the tech community; it’s called hacking. Writing a text adventure in postscript is impressive only because doing so is a terrible idea. Likewise, modern web development is impressive because HTML and CSS are limited enough to make most things that would be easy in other domains very difficult in a browser. This is not a point in favor of CSS; it is a point against it. A tool is good if easy things are easy in it and hard things are only slightly harder; CSS fails this test.</p><p>Normalizing the use of a poor tool in which a great deal of effort is necessary to solve common problems has knock-on effects. If an absolute beginner can’t perform extremely common tasks (in other words, if new users are buried under an avalanche of gotchas), those tasks are pushed onto intermediate users; more difficult tasks are relegated to advanced users; difficult tasks that need to then operate consistently and reliably — well, that’s just something nobody has time with. And, if you cut corners and bring on somebody who is slightly less skilled than is necessary, you’re more likely to get inconsistent and unreliable results even for simple tasks, because the difficulty curve is all screwed up and beginners don’t know the snags they haven’t researched yet. This is a pattern that will happen with any poorly-designed, over-complicated, inconsistent tool: anything created with the tool will be systematically slightly worse than anything created by someone of similar competence with a well-designed tool.</p><p>Pretending a bad set of tools is good lowers the bar for good tooling. It encourages an environment where bad tools are the norm, and encourages people to learn only bad tools. Just as the web is an absolute horror show (ultimately just because Tim Berners Lee cut a bunch of corners in 1992), we have big groups of people who think using hadoop &amp; hive is a good idea when a single unix command line running on one core will do the same amount of processing in 1/80th of the time, and we have academic fields where significant numbers of statistical errors in published papers are resulting from bugs in Microsoft Excel. Bad tools should be shamed, and use of bad tools should be limited and careful.</p><p>Computer programmers have spent a lot of their history in the sandbox. In the 60s and 70s most of the interesting things being done on computers didn’t have to be stable or reliable; our modern programmer culture derives mostly from the group that “shot from the hip”, rather than from the serious and conservative professionals who were crunching numbers on IBM boxes during this era. From the late 70s through to the mid 90s, personal computers were mostly not networked, and for part of that time permanent storage was limited — the cost of a mistake was that the end user had to reboot the machine, usually, and even though hardware memory protection facilities existed on PCs after 1987, they remained unused for the next ten years. Meanwhile, those who used the internet were universally technical and could expect to fix their own problems. Sloppy development, and development tools that made non-sloppy development difficult, became normal. But, we aren’t in the sandbox anymore; poor decisions made for toy projects in the early 90s are coming back to bite us daily. Poor tools and sloppy decisions are no longer acceptable.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[You had me up until “short but complete”. Lessons of less than ten minutes? Come on.]]></title>
            <link>https://medium.com/@enkiv2/you-had-me-up-until-short-but-complete-lessons-of-less-than-ten-minutes-come-on-737478993492?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/737478993492</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 06 Oct 2016 12:08:30 GMT</pubDate>
            <atom:updated>2016-10-06T12:08:30.726Z</atom:updated>
            <content:encoded><![CDATA[<p>You had me up until “short but complete”. Lessons of less than ten minutes? Come on.</p><p>Typical video lessons, like typical classroom lessons, contain a bit at the beginning that’s a review of previous material relevant to the current lesson, and a bit at the end that gives an overview of the current lesson and a teaser for the next. While the teaser portion can be omitted, an overview of previous relevant material cannot be eliminated: people frequently view these things out of order, or zone out through part of them, or misunderstand which points are central. Ten minutes isn’t nearly long enough to cover enough content to be worthwhile if we also have these overviews.</p><p>In domains with practical application, like the programming-related domains you focus on in your article, there’s a place for extremely short chunks of information. Specifically, after finishing a course or initially learning the material some other way, a person may need a quick reminder while actually applying the material. A video or audio lesson is a terrible match for this use case: finding and skipping to the relevant information is slow and error-prone. For short chunks of information, text is ideal. Audio and video based courses, however, have the edge in introducing new material to a partly or mostly passive audience.</p><p>Your other points generally make sense. But, I’d argue in favor of 1–2 hour audio/video lessons plus textual review/summary sheets.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[If your graphic design is optimized for impact at a distance without scrolling, your use case is…]]></title>
            <link>https://medium.com/@enkiv2/if-your-graphic-design-is-optimized-for-impact-at-a-distance-without-scrolling-your-use-case-is-493967a12b7?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/493967a12b7</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 05 Oct 2016 17:38:45 GMT</pubDate>
            <atom:updated>2016-10-05T17:38:45.296Z</atom:updated>
            <content:encoded><![CDATA[<p>If your graphic design is optimized for impact at a distance without scrolling, your use case is advertising (or something like it).</p><p>The typical use case for the web should not be an ad.</p><p>Maximizing the amount of legible text on the screen encourages people to create informationally dense content — it means that a short article like yours looks lonely and empty, while longer articles seem like a more natural fit. This seems like a pretty good thing to encourage; I certainly prefer long, in-depth writing to shorter, shallower stuff.</p><p>To the extent that designers should be allowed to control default text size, for primarily written content, ten pixels is probably the upper limit for what I’d consider acceptable; any more artificially inflates the perceived size of a piece of writing. However, web designers have a lot more control over the way that sites look and act than they probably should for accessibility reasons: if I set my browser’s default text size to six, websites should accept that, the same way they should if someone with poor vision sets their default text size to thirty.</p><p>An increased default size for body text points to a set of values that are already far too common on the web: a preference for flashy showmanship over well-delivered content. Good design steps aside and becomes invisible; the exhibitionist design-masturbation of huge body text never can.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I wish I could recommend this article multiple times.]]></title>
            <link>https://medium.com/@enkiv2/i-wish-i-could-recommend-this-article-multiple-times-dbbad1a478e6?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/dbbad1a478e6</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 05 Oct 2016 15:36:23 GMT</pubDate>
            <atom:updated>2016-10-05T15:36:23.342Z</atom:updated>
            <content:encoded><![CDATA[<p>I wish I could recommend this article multiple times.</p><p>Here’s the thing. I read a lot of news articles on technical subjects, and so I’m extremely aware of all these patterns (so much so that I expected, before reading this article, that I would have a lot to add); but, I can’t possibly be reading as many of these as the people who write them for a living. Occasionally I see an author whose work I respect move to a different context and start making these mistakes. Are they being enforced? Are they just popular because they are easy?</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[How to shoot yourself in the foot with good worldbuilding: two methods]]></title>
            <link>https://medium.com/@enkiv2/how-to-shoot-yourself-in-the-foot-with-good-worldbuilding-two-methods-c28834a45ad9?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/c28834a45ad9</guid>
            <category><![CDATA[writing]]></category>
            <category><![CDATA[storytelling]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 03 Oct 2016 17:40:06 GMT</pubDate>
            <atom:updated>2016-10-03T17:40:06.646Z</atom:updated>
            <content:encoded><![CDATA[<p>Sometimes, in the course of telling one story, you make changes to the imagined world you’re creating that opens up the possibility of telling a much more interesting story. This story can’t be told without moving focus away from the characters you’re currently involved with. No matter; there’s no way that these main characters are more interesting to your reader than they are to you, and if there’s demand for them, you can explore what’s going on with them later.</p><p>Always tell the most interesting story going on in your world.</p><p>Sometimes, you are telling the most interesting story going on in your world, but readers are losing interest: a formerly rabidly creative fandom has stopped writing fanfiction, complaining that the new installments feel hollow. You told the most interesting story in your world, but you limited your world so that the story you were telling was the only interesting story to be told.</p><p>Always make sure that someone smarter than you can tell a more interesting story in your world than you can imagine.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I agree that “For You” used to have a much better signal to noise ratio.]]></title>
            <link>https://medium.com/@enkiv2/i-agree-that-for-you-used-to-have-a-much-better-signal-to-noise-ratio-147996a6ded4?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/147996a6ded4</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 03 Oct 2016 12:43:04 GMT</pubDate>
            <atom:updated>2016-10-03T12:43:04.516Z</atom:updated>
            <content:encoded><![CDATA[<p>I agree that “For You” used to have a much better signal to noise ratio. I’m tempted to blame the increased size of Medium’s user base — after all, with a small user base it’s a lot easier to tweak the algorithm for good results, a small sample set is a good enough proxy for recommendation quality, and few people are going to be trying to game the system, while all of those things grow worse at at least a geometric rate as the number of users grows.</p><p>That said, I’m seeing a particular kind of bad post pop up much more frequently on Medium in the past ~2 years than previously: the short post that should be much shorter. I see a lot of medium posts that are two paragraphs long, making a point that would be clearer as a tweet, along with a couple huge and irrelevant images and somebody’s affiliate link.</p><p>I used to see these mostly as HN links (since I browse HN’s “newest”), and chalked it up to the culture of shallow self-promotion that’s all too common on HN (combined with the fact that, like Blogger a decade ago, Medium provides people who have no technical skills with a free blog that looks relatively professional). Because I rarely interact with such posts other than viewing them, I doubt that my feed is full of them due to this early exposure; instead, I suspect that this behavior has become normalized — it’s now expected to post “one minute reads” that are actually ten second reads, and my darling “twenty minute reads” and “eighty minute reads” are seen as bad for business, creating a low view to read ratio — nevermind the fact that there aren’t any ads on Medium (other than native ones) so impression metrics don’t really matter.</p><p>Another possible source is following people who have lower standards for recommendations than I do. Such people may typically write nice, long, well-considered posts, but yet recommend all the crap they agree with, whether or not it’s worth reading. Medium doesn’t distinguish between following somebody for their posts and following them for their recommendations.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Good vs iconic art]]></title>
            <link>https://medium.com/@enkiv2/good-vs-iconic-art-913732cea272?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/913732cea272</guid>
            <category><![CDATA[film]]></category>
            <category><![CDATA[anime]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 03 Oct 2016 12:10:16 GMT</pubDate>
            <atom:updated>2016-10-03T12:10:16.654Z</atom:updated>
            <content:encoded><![CDATA[<p>When it comes to narrative forms of art (film, literature, comics), there’s often a great disconnect between works that are highly influential (and thus become ‘classics’) and works that are well-executed. I don’t think this is an accident.</p><p>Well-executed works (hereafter, “good”) don’t particularly need to be novel. Whether they are high art or low art doesn’t matter — someone working in a “low” genre (say, harem anime) can be skilled enough to produce a truly shining example of that genre. Like good design, good art disappears: it is a complete and flawless implementation of expectations, and only upon close examination does the skill and effort involved in executing the expected attributes of the genre become visible.</p><p>As an example of unambiguously “low” art being extremely well executed, consider Monster Musume — a harem show involving young women who are mythological creatures. It seeks to sate essentially puerile desires: the goal is to have sexually-charged slapstick humor involving attractive women who are part animal. It is not the first show to do this by a long shot, but it may be the best: nearly all elements outside those that add to that goal are invisible, and it reaches its goal admirably, but at the same time it has a good and well-planned justification for nearly everything that happens (by combining the idea of diplomatic relations, corrupt/lazy officials, and a largely hostile population, you get an interesting take on the fantasy harem genre that can be seen as a stealth satire of racial politics and international relations), and it furthermore satirizes its own genre admirably (the protagonist’s name is never spoken in the show and rarely in the source material, and his facial features are often left blank; in other words, he is an exaggerated form of the self-insert character).</p><p>While “good” art may be popular in the short term, it is rarely influential: mostly, it subsumes itself in its own influences. Iconic works are by definition influential; they often come from outsiders and break best practices. While iconic works are memorable, it is rare that an iconic work is superior to those works that copy it. Consider Dracula and Frankenstein — both extremely iconic works, both widely adapted, and both (in their original form) nearly laughably incompetently constructed by the standards of both our time and theirs. It is not the high standards of craftsmanship that make Dracula and Frankenstein iconic; it’s not their popularity, either, although both were popular. Instead, each brought into being a particular collection of ideas that fit into a missing slot in the culture; this undigested piece of mental matter was sized upon and as these works were adapted or influenced other works the core interesting idea was progressively isolated from its trappings, until the point at which it becomes fully assimilated and no longer numinous. Dracula is no longer numinous to us: we have a mental image of Bela Lugosi in a cape, and we forget that he was supposed to have hairy palms, and we forget about Doctor Von Hellsing being a blood expert, and we forget about Lucy being obsessed with wax cylinder audio recording; while all of those elements are more interesting to us now, the iconic elements of that story are sufficiently captured by Bela Lugosi in a cape, to the point that this view of vampires as nobility (which did not originate in Dracula but really had its purest representation in the 1933 Universal Studios adaptation of Dracula that has become the most iconic one) has become dominant. The idea of permanently young and beautiful blood-sucking aristocrats afraid of the sun is one that resonated with the early twentieth century American culture very strongly, even as Max Schreck’s portrayal of Orlock in Nosferatu is a more accurate representation of how Dracula was portrayed in the book. Likewise: Frankenstein’s Monster originally looked far more human, and was highly intelligent (speaking several languages); we have made an icon out of an ugly Frankenstein’s Monster incapable of speech or complex thought and a Victor Frankenstein with a god complex and boundless ambition, rather than a beautiful but slightly unnerving monster and a Dr Frankenstein who wouldn’t be out of place at a My Chemical Romance concert because the former was a closer fit for exactly what was (and no longer is) unnerving about the story. Iconic works allow us to identify the unheimlich and integrate it into ourselves and our society in a disarmed form; or, to be more cynical: the Spectacle uses iconic works as an early warning system telling it what to consume next. Of course, as highly iconic figures become fully integrated, they cease to have the impact they otherwise would: recent Godzilla and King Kong movies flopped for the same reason that new viewers wouldn’t watch the originals, which is to say that these monsters have been integrated and are no longer monstrous.</p><p>Iconic works don’t need to be bad in order to be iconic, but even if they display technical excellence, they will face initial rejection. Consider Neon Genesis Evangelion: certainly iconic, and hardly poorly made, this show garnered very little interest during its initial run. Part of the reason is that it aired on an incorrect slot: this show, with its dense references to media from the 70s and its complex character dynamics and psychosexual undertones, was airing in a time slot that normally was geared toward ten year old boys. But, it’s more than that: Evangelion remains highly divisive, and remains relevant more than twenty years after it first aired, because its iconic elements have not yet been fully assimilated. Evangelion didn’t introduce the unwilling soldier (in fact, this element is part of why Gundam was iconic); it didn’t introduce the idea of a complex and incestuous conspiracy between a private high-tech defense organization and various government and religious authorities. But, Evangelion took upon itself the task of examining attributes of the mech genre realistically, and did so by taking a bunch of characters who border on archetypal and spending a great deal of effort trying to make their behavior and characterization realistic. Evangelion is still relevant because we haven’t figured out what makes it relevant yet: every post-Evangelion mech show is in some way a response to Evangelion in the same way that every post-Dracula vampire novel was a response to Dracula, yet even as some individual creators have done several generations of responses, none are a sufficient substitute for the original. For instance, Yoji Enokido, after working on Evangelion, went on to work on Utena (a non-mech show with certain very visible Evangelion references), Rah Xephon (a mech show that has been seen as an Evangelion clone), Star Driver (a mech show very similar to Rah Xephon with a more typical mecha protagonist), and Captain Earth (another mech show with a more typical mecha protagonist, which has some scenes directly lifted from Rah Xephon); while his vision has diverged from Evangelion proper, he’s still chewing a piece of the same cud.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I completely understand the desire to make big changes.]]></title>
            <link>https://medium.com/@enkiv2/i-completely-understand-the-desire-to-make-big-changes-9e16f86f6b4e?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/9e16f86f6b4e</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 30 Sep 2016 18:26:36 GMT</pubDate>
            <atom:updated>2016-09-30T18:26:36.633Z</atom:updated>
            <content:encoded><![CDATA[<p>I completely understand the desire to make big changes. I don’t find the current system sufficient. (The term closest to describing my political sentiments is “anarchist”.) That said, I can’t stand by the idea that a “middle finger vote” is justified, particularly when it’s unlikely to result in real change; breaking down a complex and resilient system like a government requires a strategy.</p><p>If you want someone to tear the system down, you will probably want to elect someone like Gary Johnson: he has a clear idea of which parts of the system he would like to remove and how to remove them.</p><p>Trump is unlikely to tear it all down. He has no reason to want to perform major restructuring; he doesn’t have enough understanding of the current structure to know how to disassemble it; even if he did, he probably couldn’t keep his attention focused on the task of tearing down government for long enough for it to happen. A Trump presidency will be comparable to that of Bush: more of the same, but with more mistakes.</p><p>To tear a system down requires more than bringing in an unpredictable wildcard. While someone like that is unpredictable in the short term, the distribution of their behavior is predictable at scale: a random walk seldom goes very far and often returns to the center, not despite but because of its randomness.</p><p>With regard to the negative sides of the status quo, I think even this favors Clinton. She will avoid war and torture whenever possible — after all, they have bad PR — and to the extent that she condones them at all she will do so very carefully. Trump will not avoid war: he will act in accordance with momentary displays of dominance, rather than in accordance with risk.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I was taking executive orders into account, here.]]></title>
            <link>https://medium.com/@enkiv2/i-was-taking-executive-orders-into-account-here-eed09c8f1348?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/eed09c8f1348</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 30 Sep 2016 16:47:37 GMT</pubDate>
            <atom:updated>2016-09-30T16:47:37.839Z</atom:updated>
            <content:encoded><![CDATA[<p>I was taking executive orders into account, here. I don’t doubt that Trump would issue plenty of executive orders, but I doubt that they would be effective in doing whatever he intended them to do, and I suspect that many of them would do things he didn’t expect.</p><p>Ignoring the difference between legislation &amp; executive order in terms of how much cooperation is involved, we have two candidates neither of whom have any particular deeply held convictions by which we could predict their behavior. One of these is a highly efficient and effective administrator whose desire for power and recognition drives her behavior in very predictable ways, and who can easily be manipulated into effectively administering the country in ways that are desirable if minor. The other has behaviors that cannot be influenced or predicted, but, luckily, he’s never been terribly effective at giving orders or convincing people to do things, so to the extent that he is likely to make sweeping changes, it will be in completely arbitrary, unpredictable ways.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The political post I’ve been avoiding writing]]></title>
            <link>https://extranewsfeed.com/the-political-post-ive-been-avoiding-writing-7e8d4ee75679?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/7e8d4ee75679</guid>
            <category><![CDATA[politics]]></category>
            <category><![CDATA[2016-election]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 29 Sep 2016 12:44:17 GMT</pubDate>
            <atom:updated>2016-09-29T12:44:17.882Z</atom:updated>
            <content:encoded><![CDATA[<p>This is a post about the current election. I didn’t want to write it, for several reasons. One is that none of my insights are my own, and I expected to see lots of other people making them. Another is that I don’t particularly like making or seeing political posts — even political posts that I generally agree with make me irrationally angry, because they stir up all that stressful tribal instinct. The third reason is that posting about american elections doesn’t and can’t really shed any light on my genuine political positions, because I’ve never seen a political system that really lent itself to the way I feel about politics. However, because somehow nobody is making the arguments that seem obvious to me, I’m going to have to make them, with the caveat that readers probably shouldn’t take this as an indication of my alignment outside the particular and very unusual circumstances that constitute this election.</p><p>My position is that, <em>no matter your opinions on any political issues</em>, Clinton is more likely to be a better candidate than Trump in terms of implementing them. No matter where you fall on the various political spectra, you have a better shot with Clinton. If you’re a marxist, or a neocon, or a neonazi, or a randian libertarian, or you really want the united states to become a zoroastrian theocracy, you’re better off voting for Clinton.</p><p>Here’s the thing. Trump isn’t very good at *doing* things. No matter what he tries to do, he’s pretty likely to fail; not only that, but he’s unlikely to be able to realize that he’s failed. His mental model of the universe is so disconnected from reality that he believes himself to be a successful businessman. So, if you already agree with his positions, you can’t expect him to successfully implement them. On the off chance that he succeeds in some task, it’s difficult to determine which task it will be, and once he starts something, he can not be dissuaded from continuing. In other words, voter opinion can not influence him. His positions are arbitrary and change often, but they are quite importantly not based on any kind of outside influence: if he accidentally stumbles upon some policy that’s, say, a war crime (as he has), he won’t be convinced out of it; likewise, if he stumbles upon a highly unpopular policy, its unpopularity won’t convince him to abandon it. A Trump presidency is like electing a random number generator: it’s unpredictable, can’t be reasoned with, and although it’s technically unbiased the best possible case is that it will be entirely ineffective.</p><p>Compare this to Clinton. Hillary is extremely effective as an administrator, and seems to want power for the sake of demonstrating her ability to wield it rather than for any particular end. While effectiveness in of itself is a double-edged sword in a politician, Hillary has a couple other attributes that make her power much more likely to be wielded for good. Specifically, she has a tendency to make her positions mirror that of the general population — in other words, to flip-flop in order to mirror popular sentiment (if you want to paint it negatively) — and she’s concerned in a fairly realistic way with how history will remember her. By following public opinion, she’s unlikely to perform actions that are terribly unpopular based on some kind of flawed personal conviction; however, her concern with posterity lowers the rate at which she would advocate things that may be popular in the moment but will almost certainly end up seeming terrible to future generations. To use a concrete example, she’ll publicly support gay marriage even if she privately disagrees because she knows that gay marriage is only going to continue to grow in support, but she will never support legislation like that proposed by Trump to ban the immigration of muslims (even though this would not be illegal per-se &amp; has precedent in the Alien Act) even if it’s highly popular with the electorate because such bans will always look bad at some point in the future.</p><p>While people criticize the candidates for being weak in either confidence or implementation, there’s really only one circumstance in which a leader that has a set of strongly held positions that they implement effectively is desirable: when you agree with all those positions to a greater degree than the leader does. A strong leader with unpopular positions is a disaster of a dictator; we would rather a leader with positions with which we disagree be ineffective, because then his or her decisions would be irrelevant. Alternately, a leader whose policies are flexible but whose ability to enact policy is good can be bent to the will of the people, and becomes a tool of the people: an even better result. In a sense, to the degree that leaders are strong, we wish them to be corrupt in a very specific way: weak to the forces of popular sentiment now and in the future, but strong against the kind of organizations that exist to warp politicians’ sense of what positions have popular support (industry lobbying groups and such).</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Trump doesn’t know what he wants, or how to get it.]]></title>
            <link>https://medium.com/@enkiv2/trump-doesnt-know-what-he-wants-or-how-to-get-it-f60040a04f3f?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/f60040a04f3f</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 29 Sep 2016 13:54:56 GMT</pubDate>
            <atom:updated>2016-09-29T13:54:56.723Z</atom:updated>
            <content:encoded><![CDATA[<p>Trump doesn’t know what he wants, or how to get it. Best case, he gets nothing done; expected case, he does something by accident based on a half-considered remark and it turns out to be something nobody wants.</p><p>Clinton, on the other hand, is likely to be “more of the same” — in other words, a general extension of the right-center policies that characterized the Bush and Obama administrations (and indeed Bill Clinton’s). She’s a known quantity, with enough experience to avoid stumbling into a big dumb war.</p><p>Clinton is a strong enough leader to execute the plans she has, which are, essentially: avoid pissing off voters, and otherwise change as little as possible. This makes her “conservative” in the traditional sense, and hers is likely to be an uninteresting and unmemorable presidency (like Carter’s).</p><p>Trump will either be considered a failure, or will succeed at something that will be considered a huge mistake. A failure would be preferable — but that just brings him down to slightly below Clinton’s expected behavior.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A method and device for becoming a property owner himself]]></title>
            <link>https://medium.com/@enkiv2/a-method-and-device-for-becoming-a-property-owner-himself-1c9488790f80?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/1c9488790f80</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 20 Sep 2016 18:09:06 GMT</pubDate>
            <atom:updated>2016-09-20T18:09:06.616Z</atom:updated>
            <content:encoded><![CDATA[<p>A method and device for becoming a property owner himself</p><p>ABSTRACT</p><p>A method and device for becoming a property owner himself. The devices comprises an old system, a mere instrument, a militant working, a Polish edition, an international product, a present system, a big factory, an other working, an eight-hour working, a Danish edition, an indispensable cloak, a first edition, a democratic newspaper, a English edition, a German edition, a whole system, an entire surface, a European working, a feudal system, a social stronghold, a revised edition, a chief load, a German working, a whole article, a bribed tool, a last resort, an own working, a transcendental robe, a modern working, an essential product, a 23-page pamphlet, a Russian edition, a mighty weapon, a second edition, a collective product, a present edition, a respective working, a subsequent edition, a great factory, an other article, a mechanical loom, a poor stock-in-trade, an own house, a sentimental veil, a parliamentary stronghold, a new machine, a representative system, a heavy artillery, a previous edition, a gigantic broom, a common platform, a European system, a capitalist system, a rough sketch, a whole working</p><p>BRIEF DESCRIPTION OF THE DRAWINGS</p><p>Figure 1 is a diagrammatical view of the progressive historical development of the proletariat.</p><p>Figure 2 is a schematic drawing of the first revolution in which the working class.</p><p>Figure 3 is a schematic drawing of a certain stage in the development.</p><p>Figure 4 is a schematic drawing of a corresponding political advance of that class.</p><p>Figure 5 illustrates the first conditions for the emancipation.</p><p>Figure 6 is a diagrammatical view of the influential bourgeoisie during the French revolution.</p><p>Figure 7 is a cross section of an independent section of modern society.</p><p>Figure 8 is a perspective view of all political action on the part.</p><p>Figure 9 is an isometric view of an exaggerated form of the ancient struggle.</p><p>Figure 10 is a diagrammatical view of the main consequences of the abolition.</p><p>Figure 11 is a block diagram of the same pace at which the progress.</p><p>Figure 12 is a perspective view of the working-class parties of every country.</p><p>Figure 13 is a cross section of the rural producers under the intellectual lead.</p><p>Figure 14 is a cross section of the vanished status of the workman.</p><p>Figure 15 is a schematic drawing of the great factory of the industrial capitalist.</p><p>Figure 16 is a diagrammatical view of the inevitable impending dissolution of modern bourgeois property.</p><p>Figure 17 is a cross section of the necessary offspring of their own form.</p><p>Figure 18 is a schematic drawing of the miraculous effects of their social science.</p><p>Figure 19 is a cross section of the historical movement as a whole.</p><p>Figure 20 is a diagrammatical view of the old system of manufacture or industry.</p><p>Figure 21 is a block diagram of the miserable character of this appropriation.</p><p>Figure 22 schematically illustrates the whole range of old society.</p><p>Figure 23 is a schematic drawing of the political form at last discovered.</p><p>Figure 24 schematically illustrates the icy water of egotistical calculation.</p><p>Figure 25 is an isometric view of a national bank with state capital.</p><p>Figure 26 is a diagrammatical view of the holy water with which the priest.</p><p>Figure 27 schematically illustrates the positive form of that republic.</p><p>Figure 28 is an isometric view of all other branches of the administration.</p><p>Figure 29 is a diagrammatical view of a rough sketch of national organisation.</p><p>Figure 30 is a perspective view of The essential conditions for the existence.</p><p>Figure 31 is a perspective view of a new proletarian line during the discussion.</p><p>Figure 32 is a diagrammatical view of The first direct attempts of the proletariat.</p><p>Figure 33 illustrates The proper form of their joint-stock government.</p><p>Figure 34 is a perspective view of the proletarian differ from the serf.</p><p>Figure 35 is a cross section of a fantastic conception of its own position.</p><p>Figure 36 is an isometric view of a powerful coefficient of social production.</p><p>Figure 37 is a cross section of a clear understanding of the character.</p><p>Figure 38 illustrates the actual position of first class.</p><p>Figure 39 is a cross section of a comprehensive formulation of the proletarian movement.</p><p>Figure 40 is a cross section of the rapid development of Polish industry.</p><p>Figure 41 is a block diagram of the momentary interests of the working class.</p><p>Figure 42 is an isometric view of the physical force elements of the old government.</p><p>Figure 43 is a perspective view of the senile mountebank at its head.</p><p>Figure 44 is a cross section of the healthy elements of French society.</p><p>Figure 45 is a diagrammatical view of the ultimate general results of the proletarian movement.</p><p>Figure 46 is a schematic drawing of the classical works of ancient heathendom.</p><p>Figure 47 is a perspective view of a mighty weapon in its struggle.</p><p>Figure 48 is an isometric view of The first , fundamental condition for the introduction.</p><p>Figure 49 is a perspective view of these philosophical phrases at the back.</p><p>Figure 50 is a diagrammatical view of an agrarian revolution as the prime condition.</p><p>Figure 51 illustrates no other nexus between man and man.</p><p>Figure 52 is a block diagram of the whole superincumbent strata of official society.</p><p>Figure 53 is a perspective view of the economic and political sway of the bourgeois class.</p><p>Figure 54 schematically illustrates the same course as its predecessor.</p><p>Figure 55 is a schematic drawing of every other employer in the search.</p><p>Figure 56 is a block diagram of the disastrous effects of machinery and division.</p><p>Figure 57 is a diagrammatical view of all numerous vanguard of scientific socialism.</p><p>Figure 58 is a perspective view of the social power of the nobility.</p><p>Figure 59 is a cross section of the first time in the introduction.</p><p>Figure 60 illustrates the individual workers so that the worker.</p><p>Figure 61 is an isometric view of the social character of the property.</p><p>Figure 62 is an isometric view of the economic progress of the country.</p><p>Figure 63 is an isometric view of the last great reserve of all European reaction.</p><p>Figure 64 is a schematic drawing of a new proof of the inexhaustible vitality.</p><p>Figure 65 illustrates the oracular tone of scientific infallibility.</p><p>Figure 66 is a diagrammatical view of the necessary condition for whose existence.</p><p>Figure 67 illustrates the civilized countries of the world.</p><p>Figure 68 illustrates the French criticism of the bourgeois state.</p><p>Figure 69 schematically illustrates the immediate demands of the movement.</p><p>Figure 70 illustrates the first class of the country.</p><p>Figure 71 is a diagrammatical view of the scattered state of the population.</p><p>Figure 72 is a diagrammatical view of a considerable part of the population.</p><p>Figure 73 is a diagrammatical view of the entire bourgeois society on its trial.</p><p>Figure 74 is an isometric view of the intellectual development of the working class.</p><p>Figure 75 is a schematic drawing of the first radical attack on private property.</p><p>Figure 76 illustrates the free movement of , society.</p><p>Figure 77 is a diagrammatical view of the latter stands at a higher stage.</p><p>Figure 78 is a schematic drawing of a new collection of the work.</p><p>Figure 79 is an isometric view of the Communistic abolition of buying and selling.</p><p>Figure 80 is a block diagram of a supplementary part of bourgeois society.</p><p>Figure 81 is a diagrammatical view of the economic conditions for its emancipation.</p><p>Figure 82 illustrates The political rule of the producer.</p><p>Figure 83 is a block diagram of the special privileges of the nobility.</p><p>Figure 84 is a schematic drawing of a revised edition of this earlier draft.</p><p>Figure 85 is a cross section of the full development of every previous revolution.</p><p>Figure 86 is a diagrammatical view of the true originators of the war.</p><p>Figure 87 is a diagrammatical view of the necessary consequence of the creation.</p><p>Figure 88 illustrates a 23-page pamphlet in a dark green.</p><p>Figure 89 is a block diagram of the revolutionary element in the tottering feudal society.</p><p>Figure 90 schematically illustrates the bombastic representative of the petty-bourgeois.</p><p>Figure 91 schematically illustrates an undeveloped state of both agriculture.</p><p>Figure 92 is a diagrammatical view of no other conclusion that the lot.</p><p>Figure 93 is a block diagram of a new guarantee of its impending national restoration.</p><p>Figure 94 is a schematic drawing of the socialist movement spreads among them and the demand.</p><p>Figure 95 is a perspective view of the entire surface of the globe.</p><p>Figure 96 is a schematic drawing of a decided progress of Polish industry.</p><p>Figure 97 is a perspective view of the true conditions for working-class emancipation.</p><p>Figure 98 is a block diagram of the other countries of the world.</p><p>Figure 99 is a perspective view of the same pace as the growth.</p><p>Figure 100 is a block diagram of the bourgeois sense of the word.</p><p>Figure 101 is an isometric view of the gradual , spontaneous class organisation of the proletariat.</p><p>Figure 102 is an isometric view of the programme document in the course.</p><p>Figure 103 is a block diagram of the political and intellectual history of that epoch.</p><p>Figure 104 is a schematic drawing of a full and substantial exposition of the new revolutionary.</p><p>Figure 105 is a schematic drawing of The undeveloped state of the class.</p><p>Figure 106 illustrates the first instinctive yearnings of that class.</p><p>Figure 107 schematically illustrates a progressive phase in the class.</p><p>Figure 108 illustrates the bold champion of the emancipation.</p><p>Figure 109 is an isometric view of the right man in the right place.</p><p>Figure 110 is a perspective view of the intellectual development of the mass.</p><p>Figure 111 is a perspective view of the same time markets for the sale.</p><p>Figure 112 illustrates the absolute monarchy as a counterpoise.</p><p>Figure 113 schematically illustrates these first movements of the proletariat.</p><p>Figure 114 is a diagrammatical view of the Italian proletariat as the publication.</p><p>Figure 115 is an isometric view of the little workshop of the patriarchal master.</p><p>Figure 116 is a cross section of the working class of the 19th century.[vi.</p><p>Figure 117 is a perspective view of all coercive measures against the working class.</p><p>Figure 118 is a diagrammatical view of the continued existence of bourgeois society.</p><p>Figure 119 schematically illustrates the agricultural population on the land.</p><p>Figure 120 is an isometric view of the real action of the working class.</p><p>Figure 121 illustrates a necessary condition of communist association.</p><p>Figure 122 is a perspective view of the practical absence of the family.</p><p>Figure 123 is a cross section of The rural communities of every district.</p><p>Figure 124 is a schematic drawing of the leading body of the Paris circle.</p><p>Figure 125 is a schematic drawing of The productive forces at the disposal.</p><p>Figure 126 is a perspective view of a final stage in the reorganisation.</p><p>Figure 127 is a schematic drawing of the misty realm of philosophical fantasy.</p><p>Figure 128 is a cross section of the ultimate disappearance of private property.</p><p>Figure 129 is an isometric view of the exact contrary of its real character.</p><p>Figure 130 schematically illustrates the big industry of our own day.</p><p>Figure 131 is a diagrammatical view of the self-conscious , independent movement of the immense.</p><p>Figure 132 illustrates the savage warfare of Versailles outside.</p><p>Figure 133 schematically illustrates the further consequences of the industrial revolution.</p><p>Figure 134 schematically illustrates a national bank with State capital.</p><p>Figure 135 is a diagrammatical view of the sleeping partner of the capitalist.</p><p>Figure 136 is a cross section of the final approval of the programme.</p><p>Figure 137 is a cross section of the ultimate form of the state.</p><p>Figure 138 is a cross section of the great struggle of the day.</p><p>Figure 139 is a cross section of all local markets into one world.</p><p>Figure 140 is a schematic drawing of the first step in the revolution.</p><p>Figure 141 illustrates the upper stratum of the working class.</p><p>Figure 142 is a schematic drawing of the international union of the proletariat.</p><p>Figure 143 is a diagrammatical view of every villainous meanness of this model.</p><p>Figure 144 illustrates the various wards of the town.</p><p>Figure 145 schematically illustrates the last remnants of their independence.</p><p>Figure 146 is a perspective view of the hallowed co-relation of parents and child.</p><p>Figure 147 is an isometric view of a full member of a guild.</p><p>Figure 148 is an isometric view of a vast association of the whole nation.</p><p>Figure 149 is a perspective view of the political liberation of the proletariat.</p><p>Figure 150 schematically illustrates the political conditions of the Continent.</p><p>Figure 151 illustrates The new draft for the programme.</p><p>Figure 152 is a block diagram of the peaceful abolition of private property.</p><p>Figure 153 is a cross section of the front the common interests of the entire proletariat.</p><p>Figure 154 is a perspective view of the peculiar mysteries of the Picpus nunnery[xxii.</p><p>Figure 155 is a schematic drawing of the immediate consequences of the industrial revolution.</p><p>Figure 156 is a schematic drawing of the same way in which a foreign language.</p><p>Figure 157 is a schematic drawing of the social and political aspirations of the European working.</p><p>Figure 158 is a block diagram of the first Paris Revolution in which the proletariat.</p><p>Figure 159 is a block diagram of the second paragraph of point 9 and the last sentence.</p><p>Figure 160 is a cross section of the secret societies of the time.</p><p>Figure 161 illustrates a vague aspiration after a republic.</p><p>Figure 162 is a perspective view of the direct or indirect dominance of the proletariat.</p><p>Figure 163 is a diagrammatical view of The individual members of this class.</p><p>Figure 164 schematically illustrates the proletarian differ from the handicraftsman.</p><p>Figure 165 is a diagrammatical view of the full consciousness of their historic mission.</p><p>Figure 166 is a cross section of a bribed tool of reactionary intrigue.</p><p>Figure 167 is a block diagram of the monarchical form of class rule.</p><p>Figure 168 is a diagrammatical view of the common cause with the party.</p><p>Figure 169 schematically illustrates An oppressed class under the sway.</p><p>Figure 170 is a cross section of the motley feudal ties that bound man.</p><p>Figure 171 schematically illustrates The inner organisation of this primitive communistic society.</p><p>Figure 172 is a cross section of the historical conditions for the time.</p><p>Figure 173 is a cross section of the feudal organisation of agriculture and manufacturing.</p><p>Figure 174 is a perspective view of the great mass of the proletariat.</p><p>Figure 175 schematically illustrates the hostile antagonism between bourgeoisie and proletariat.</p><p>Figure 176 is a diagrammatical view of The bourgeois clap-trap about the family.</p><p>Figure 177 is a block diagram of the commercial crises that by their periodical.</p><p>Figure 178 schematically illustrates the other political parties of our time.</p><p>Figure 179 schematically illustrates the basic conditions of this society.</p><p>Figure 180 is a schematic drawing of the old cries of the restoration.</p><p>Figure 181 illustrates the reactionary character of their criticism.</p><p>Figure 182 schematically illustrates a new onslaught upon the power.</p><p>Figure 183 is a block diagram of any distinctive social validity for the working class.</p><p>Figure 184 is a perspective view of the first part of the book.</p><p>Figure 185 is an isometric view of the central seat of the old governmental power.</p><p>Figure 186 is a schematic drawing of a shameless display of gorgeous , meretricious and debased luxury.</p><p>Figure 187 is a diagrammatical view of the proletarian differ from the slave.</p><p>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</p><p>The present invention is a 23-page pamphlet in a dark green. The present invention grows emancipation struggle of the proletariat. The present invention examines the movement of the working class. The invention constitutes the last great reserve of all European reaction.</p><p>In accordance with an alternative specific embodiment, the present invention found their only salvation from the proletariat. The device becomes the signal for a proletarian revolution. The device constitutes the foundation for the political and intellectual history. The present invention prepares the way for a more complete insight. The present invention brings out a book with the name. The present invention reflects the history of the modern working-class movement. The device is the act of the working class. The present invention attains its emancipation from the sway. The invention has again gathered sufficient strength for a new onslaught.</p><p>According to another embodiment, the device reflects the history of the modern working-class movement. The device is the task of the working class. The device is no better witness than this day. The invention regards their position as the working class. The invention indicates a decided progress of Polish industry. The invention is a necessity for the harmonious collaboration. The invention is the work of the working class. The device achieves the international union of the proletariat. The invention is itself the product of a long course. The invention remains no other nexus between man and man. The present invention finds its fitting complement in the most slothful indolence. The invention creates a world after its own image. The invention puts the existence of the entire bourgeois society.</p><p>In accordance with an alternative specific embodiment, the present invention endangers the existence of bourgeois property. The invention becomes an appendage of the machine. The present invention is the self-conscious , independent movement of the immense. The present invention layers the foundation for the sway. The device abolishes the right of personally acquires property. The present invention is the groundwork of all personal freedom. The present invention is the miserable character of this appropriation. The invention is the non-existence of any property. The invention deprives no man of the power. The invention finds its complement in the practical absence. The invention alter the character of that intervention. The device keeps even pace with the dissolution.</p><p>The present invention is the most radical rupture with traditional property. The device is the condition for the free development. The invention comprehends the march of modern history. The device is the necessary offspring of their own form. The present invention conceals the reactionary character of their criticism. The present invention has Clerical Socialism with Feudal Socialism. The invention is the head of this school. The device reversed this process with the profane French literature. The present invention expresses the struggle of one class. The device presupposed the existence of modern bourgeois society. The present invention is the object of the pending. The device serves the government as a weapon. The present invention proclaims its supreme and impartial contempt of all class. The invention secures the continued existence of bourgeois society. The present invention keeps even pace with the development. The present invention improves the condition of every member. The invention is a final stage in the reorganisation. The invention is the result of the whole. The invention prepares the way for your community. The invention does the proletarian differ from the slave. The device is the property of one master. The invention does the proletarian differ from the serf. The invention has the use of a piece. The invention does the proletarian differ from the handicraftsman.</p><p>According to another embodiment, the device joins the movement of the proletariat. The invention is the theory of a liberation. The device defend the cause of the proletariat. The device is the political liberation of the proletariat.</p><p>In accordance with an alternative specific embodiment, the present invention guarantees the subsistence of the proletariat. The present invention prepares the way for its transformation. The present invention is that stage of historical development. The invention is a revised edition of this earlier draft. The device draws up a programme in the form. The invention drafts a programme in the form. The device does not draw profit from any kind. The invention reduced the activity of the individual worker. The invention does this sale of the labor. The present invention accomplishes the liberation of their respective working. The present invention makes itself the first class of the country. The device annihilated the power of the aristocracy. The present invention is a lack of the necessary capital. The device takes the form of constitutional monarchy. The present invention renders the condition of the proletariat.</p><p>The present invention follow the same course as its predecessor. The invention characterizes the revolution in the whole social order. The invention is the necessary consequence of the creation. The present invention is the course of this revolution. The device is the victory of the proletariat. The present invention ensures the livelihood of the proletariat. The device requires an entirely different kind of human material. The device controlled by society as a whole.</p><p>In accordance with an alternative specific embodiment, the present invention is the influence of communist society. The present invention is the stage of historical development. The device establishes the rule of the aristocracy. The invention makes the common cause with the party.</p><p>The present invention facilitates the unification of the proletariat. The present invention popularise this programme document during the revolution. The device become the property of the state. The invention regulates the credit system in the interest. The device substitutes paper money for gold and silver. The invention become the property of the state. The present invention serves nascent bourgeois society as a mighty weapon. The present invention intensified the class antagonism between capital and labor. The invention marks a progressive phase in the class. The present invention is a regime of avowed class.</p><p>According to another embodiment, the device opens an abyss between that class. The present invention professed to rest upon the peasantry. The device upholds their economic supremacy over the working class. The device transfers the supreme seat of that regime.</p><p>According to a beneficial embodiment, the invention is the positive form of that republic. The invention is the suppression of the standing. The device becomes a reality by the destruction. The device is the embodiment of that unity.</p><p>According to a preferred embodiment, the invention serves every other employer in the search. The present invention puts the right man in the right place.</p><p>According to a preferred embodiment, the invention clogs the free movement of , society. The device supplies the republic with the basis. The present invention regulates national production upon common plan. The device takes the management of the revolution. The device is the first revolution in which the working class. The invention have put enlightenment by the schoolmaster. The device solves in favor of the peasant. The present invention stops the spread of the rinderpest. The invention display their patriotism by organizing police. The present invention is the abolition of the nightwork. The present invention hampered the real action of the working class. The device retraces this dissolution in The Origin. The present invention carries brazen historical irony as a result. The device is the seat of the emigr� government.</p><p>What is claimed is:</p><p>1. A method for becoming a property owner himself, comprising:<br> a previous edition; <br> a 23-page pamphlet; and <br> a German edition.</p><p>2. The method of claim 1, wherein said previous edition comprises the sleeping partner of the capitalist.</p><p>3. The method of claim 1, wherein said 23-page pamphlet comprises the further consequences of the industrial revolution.</p><p>4. The method of claim 1, wherein said German edition comprises the special privileges of the nobility.</p><p>5. A device for becoming a property owner himself, comprising:<br> a feudal system; <br> a mechanical loom; <br> an own house; and <br> a parliamentary stronghold.</p><p>6. The device of claim 5, wherein said feudal system comprises a national bank with State capital.</p><p>7. The device of claim 5, wherein said mechanical loom comprises the political form at last discovered.</p><p>8. The device of claim 5, wherein said own house comprises the bold champion of the emancipation.</p><p>9. The device of claim 5, wherein said parliamentary stronghold comprises the main consequences of the abolition.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A device and method for escaping the universal truth]]></title>
            <link>https://medium.com/@enkiv2/a-device-and-method-for-escaping-the-universal-truth-eaaf19182fd3?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/eaaf19182fd3</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 20 Sep 2016 18:06:03 GMT</pubDate>
            <atom:updated>2016-09-20T18:06:03.096Z</atom:updated>
            <content:encoded><![CDATA[<p>A device and method for escaping the universal truth</p><p>ABSTRACT</p><p>A device and method for escaping the universal truth. The devices comprises a panoptic system, an inverse mirror, a universal system, a whole edifice, a whole system, an original book, an uninterrupted circuit, an artificial mosaic, a nervous system, a single gadget</p><p>BRIEF DESCRIPTION OF THE DRAWINGS</p><p>Figure 1 schematically illustrates the critical obsession with its aura.</p><p>Figure 2 is an isometric view of The other aspect of this process.</p><p>Figure 3 schematically illustrates no strategic stakes at this conjuncture.</p><p>Figure 4 is a block diagram of an unforeseen twist of events and an irony.</p><p>Figure 5 is a perspective view of The machine-readable form of the input.</p><p>Figure 6 is a block diagram of any other symptom in classical medicine.</p><p>Figure 7 is a block diagram of the discrete charm of the gravity.</p><p>Figure 8 is a schematic drawing of the logical evolution of a universal system.</p><p>Figure 9 is a schematic drawing of the second sentence of the epigraph.</p><p>Figure 10 illustrates the same time by the cartographer.</p><p>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</p><p>The present invention witnesses the end of the negative form. The present invention separates one pole from the very swing. The invention seals the end of the abolition. The invention is the slope of a false problem. The invention is the truth of this new age. The device signifies a setback in the sense. The invention makes any sense of a conventional , restricted perspective.</p><p>The present invention is an escalation of the whole edifice. The present invention produces nothing but the discrete charm of the gravity.</p><p>What is claimed is:</p><p>1. A device for escaping the universal truth, comprising:<br> an original book; and <br> a universal system.</p><p>2. The device of claim 1, wherein said original book comprises the discrete charm of the gravity.</p><p>3. The device of claim 1, wherein said universal system comprises an unforeseen twist of events and an irony.</p><p>4. A method for escaping the universal truth, comprising:<br> a single gadget; <br> a universal system; <br> an inverse mirror; and <br> an uninterrupted circuit.</p><p>5. The method of claim 4, wherein said single gadget comprises the discrete charm of the gravity.</p><p>6. The method of claim 4, wherein said universal system comprises the logical evolution of a universal system.</p><p>7. The method of claim 4, wherein said inverse mirror comprises The other aspect of this process.</p><p>8. The method of claim 4, wherein said uninterrupted circuit comprises The machine-readable form of the input.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A Qualified Defense of Jargon & Other In-Group Signifiers]]></title>
            <link>https://medium.com/@enkiv2/a-qualified-defense-of-jargon-other-in-group-signifiers-2fe2cd37b66b?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/2fe2cd37b66b</guid>
            <category><![CDATA[programming]]></category>
            <category><![CDATA[tech]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 01 Sep 2016 13:43:25 GMT</pubDate>
            <atom:updated>2016-09-01T13:57:29.988Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p>This essay is in part a response to an article I read this morning. I won’t link to the article, in part because I don’t want to diminish it by talking over it, and in part because the story that this article tells is pretty common — plenty of people have complained about exactly the same thing, myself included. The article in question told the story of a self-taught programmer whose unfamiliarity with certain terms and historical figures theoretically irrelevant to her work marked her as an outsider &amp; made her uncomfortable in a professional environment. I sympathize — after all, I too was once a self-taught developer in over my head, and I’ve gone through the process of trying to work in an environment where my unfamiliarity with the shibboleths marked me as an outsider. I also don’t want to imply that her situation is justified — accidents of biology &amp; history like gender, ethnicity, and childhood cultural background can make the bar for fitting into particular groups much higher than it should be. What I’d like to avoid is the shallow idea that we can just reject shibboleths altogether and solve all problems.</p><p>Jargon is a clear cut example of when a tool that’s instrumental for competency also acts as a shibboleth. Most fields with complicated forms of technical knowledge also have specialized vocabulary or specialized meanings for particular words; the general consensus surrounding the meaning of a particular word stands in for a vast chunk of shared knowledge that would be complicated to explain in non-specialized language. When someone says “O(n²)”, they are making a claim that, in order to be understood, implies a familiarity with the calculus of derivatives, instruction counting, how loops work, and the idea of worst case versus expected case outcomes. Working with someone whose familiarity with foundational concepts in your field is at the level of an outsider is nearly impossible: you need to act the part of professor more often than you do real work; if someone lacks familiarity with the terminology, your handle for figuring out their knowledge level is no longer usable. Autodidacts are already at a disadvantage here: the set of things they know is not the same as that taught by a degree program, and they can have large conspicuous gaps in their knowledge even when it comes to relevant material. When an autodidact is unfamiliar with a term, it’s hard to tell whether or not that indicates a gap in their competence that needs to be filled, taking up time and effort that could otherwise be applied to the ostensible end goal.</p><p>Even when a piece of jargon isn’t of direct relevance, familiarity with jargon is indicative of a shared cultural experience that reflects shared values and habits — some pieces of which can be highly relevant. Using a term like “dot file” when referencing a hidden configuration file indicates familiarity and comfort with the unix environment, which might extend to a familiarity with pipes, standard unix tools, shell scripting, basic unix system administration, the history of the free software and open source movements, unix-style development toolchains, a preference for classic text editors like vi &amp; emacs over graphical IDEs, an understanding of the unix philosophy of small modular programs working together on text streams, a familiarity with and preference for irc over other similar communication systems, a fondness for beards, and the ownership of toys shaped like penguins or tennis shoe wearing demons. Someone who just says “config file” will not open the floodgates of spurious cultural associations. (Likewise with “home directory” versus “user directory” or “my documents”.) All of these associations are fuzzy: not everyone has equal immersion in the cultural ephemera related to some technology. However, there’s a set of expectations associated with use of terminology: kinship with a set of tribes with clear centers and fuzzy boundaries.</p><p>Similarly, familiarity with certain historical figures has cultural relevance that extends to philosophy with meaningful applications in work environments. Somebody familiar with Djikstra who only learned about him in school probably only knows about him in the context of graph traversal, but someone familiar with Djikstra’s mythology is likely to be familiar with a couple quotes: “asking if a computer can think is like asking if a submarine can swim” and “premature optimization is the root of all evil”. Even if misattributed &amp; misunderstood, both those quotes have impacts on the way someone develops software that go far beyond familiarity with graph traversal algorithms. Someone who quotes Postel’s Law, similarly, has a particular philosophy that’s easy to identify. All of these philosophies have impact, though the value of this impact depends on the application: Postel’s Law was instrumental in both the widespread adoption of the world wide web and the horrible security shitshow that the world wide web can’t extract itself from.</p><p>This is all to say that culture matters and signifiers matter. If you’re working alone, it’s fine to focus only on the precise technical ideas that stand between you and your immediate goal; as soon as you start working with a group, an inability to code switch means your coworkers can’t predict your behavior, communicate with you efficiently about important things, or figure out what you need to know in order to do your job effectively. Hiring an autodidact is a big risk, which is why lots of places don’t bother — it’s not that a degree implies a high level of competence, but instead that a degree is a hedge against a low level of competence that would cost the company a lot of money; hiring an autodidact with big gaps in their understanding of jargon and culture is not merely a risk but an almost-guaranteed cost, even if the person in question has significantly above-average technical skills and work ethic.</p><p>All of this is a huge problem, because the tech industry has a number of problems related to a lack of diversity — particularly cultural diversity. We need to shake this industry up with outside ideas, and part of that is bringing in autodidacts who have experiences unlike those systematically manufactured by degree programs or accelerators. We need people who can point at the inconsistencies and stupidities that are passively accepted as normal by the monoculture. But, we need those people to speak the language.</p><p>If we don’t throw away shibboleths entirely, what are we to do?</p><p>My recommendation is: outsiders, know your enemy. If you’re learning to code on your own, pay attention to the mythology. Read the <em>Jargon File</em>. Read <em>The Devouring Fungus</em>. Read <em>Hackers</em> &amp; <em>Where Wizards Stay Up Late</em>. Make sure that you have enough understanding of the history and culture to pass as a precocious newbie.</p><p>As for insiders: be conscious of the way shibboleths are being used. Just because someone doesn’t know the term you used doesn’t mean they are totally unfamiliar with the concept. Make sure you aren’t leaning too heavily on spurious associations: playing Tempest doesn’t really have anything to do with understanding depth-first searches, Stallman’s association with Linux isn’t much more than a series of accidents that don’t meaningfully impact the syntax of awk, and LISP’s vast mythology is mostly the product of it being really popular at MIT fifty years ago rather than some deep truth about lambda calculus. Make sure that, to the extent that you are using shibboleths as a proxy for competence, you are not doing so in a way that unfairly prevents competent outsiders from contributing meaningful work. And, especially, give the benefit of the doubt to anyone who isn’t a cultural fit for reasons beyond their control: assume that women &amp; people who are neither white nor asian are competent, because everyone else in their lives will assume they are incompetent.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[That’s sort of my point: there’s no technical reason why feature length film budgets should be…]]></title>
            <link>https://medium.com/@enkiv2/thats-sort-of-my-point-there-s-no-technical-reason-why-feature-length-film-budgets-should-be-d3a2d855b8c6?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/d3a2d855b8c6</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 31 Aug 2016 14:55:18 GMT</pubDate>
            <atom:updated>2016-08-31T14:55:18.649Z</atom:updated>
            <content:encoded><![CDATA[<p>That’s sort of my point: there’s no technical reason why feature length film budgets should be increasing rather than decreasing; instead, it’s a purely social reason: specifically, people (falsely) believe that a big budget is necessary to make something with any kind of audience. Demonstrating that a worthwhile feature-length film can be made with a budget in the tens of dollars instead of in the millions is probably the best way to counter this.</p><p>In the 90s, plenty of pictures were made for ten thousand dollars or so. That number has stuck in people’s minds as the low-end estimate, but in reality, that refers to the cost of a low-end film camera, plenty of film, and film editing equipment — or a low-end camcorder, a bunch of tapes, and a video toaster. But, today, most americans have video cameras in their pockets that knock the mid-range 90s camcorders out of the water. We need to redefine the idea of the “shoestring budget” for film from $10k to twenty bucks.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[On second thought, the article is slightly above the average stupidity of a tech article on medium.]]></title>
            <link>https://medium.com/@enkiv2/on-second-thought-the-article-is-slightly-above-the-average-stupidity-of-a-tech-article-on-medium-d3b64f6a9eb9?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/d3b64f6a9eb9</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 30 Aug 2016 20:17:55 GMT</pubDate>
            <atom:updated>2016-08-30T20:17:55.680Z</atom:updated>
            <content:encoded><![CDATA[<p>On second thought, the article is slightly above the average stupidity of a tech article on medium. The epoch should have tipped me off :)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I’m unfamiliar with Schiffer.]]></title>
            <link>https://medium.com/@enkiv2/im-unfamiliar-with-schiffer-96fbe02dde60?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/96fbe02dde60</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 30 Aug 2016 20:00:07 GMT</pubDate>
            <atom:updated>2016-08-30T20:00:07.718Z</atom:updated>
            <content:encoded><![CDATA[<p>I’m unfamiliar with Schiffer. Her post seemed typical of tech-related posts on medium with the exception of a fairly common typo being emphasized in a pull quote, so I figured it was an honest mistake — many authors on medium are not native english speakers.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Nope! Changing ‘responsive’ to ‘reactive’ doesn’t explain why we’d specify a server-side Microsoft…]]></title>
            <link>https://medium.com/@enkiv2/nope-changing-responsive-to-reactive-doesn-t-explain-why-we-d-specify-a-server-side-microsoft-1fcfb64e7be6?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/1fcfb64e7be6</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 30 Aug 2016 19:38:51 GMT</pubDate>
            <atom:updated>2016-08-30T19:38:51.481Z</atom:updated>
            <content:encoded><![CDATA[<p>Nope! Changing ‘responsive’ to ‘reactive’ doesn’t explain why we’d specify a server-side Microsoft stack in the context of a client-side problem on a blog about CSS, nor does it explain why we would drop words &amp; punctuation in this context. It still seems more likely to me that the author meant “ASAP” in its conventional sense. Since she appears to be active in this thread, perhaps she can clarify.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[What?]]></title>
            <link>https://medium.com/@enkiv2/what-9d25c4497368?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/9d25c4497368</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 30 Aug 2016 18:40:01 GMT</pubDate>
            <atom:updated>2016-08-30T18:40:01.915Z</atom:updated>
            <content:encoded><![CDATA[<p>What?</p><p>It’s difficult to tell if you’re serious. Are you honestly unfamiliar with the colloquial use of “ASAP”, or are you just failing to make a joke?</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[So, you think the tail end of that pull quote was intended to be “we need to stop building…]]></title>
            <link>https://medium.com/@enkiv2/so-you-think-the-tail-end-of-that-pull-quote-was-intended-to-be-we-need-to-stop-building-69853dc1535d?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/69853dc1535d</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 30 Aug 2016 18:18:39 GMT</pubDate>
            <atom:updated>2016-08-30T18:18:39.065Z</atom:updated>
            <content:encoded><![CDATA[<p>So, you think the tail end of that pull quote was intended to be “<em>we need to stop building responsive web pages active server active pages as possible</em>”? If that was the intent, then there’s still a typo here — we’re missing a conjoiner &amp; some punctuation. In other words, “<em>we need to stop building responsive web pages using ASAP, as possible</em>” would make sense (even if it’s very awkward phrasing), but it would imply that only one set of technologies (the Microsoft ASP stack) is at fault. This is a very strange interpretation, considering the rest of the article is complaining about reactive web design in general.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ASAP stands for As Soon As Possible.]]></title>
            <link>https://medium.com/@enkiv2/asap-stands-for-as-soon-as-possible-dcf5998fab44?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/dcf5998fab44</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 30 Aug 2016 18:10:27 GMT</pubDate>
            <atom:updated>2016-08-30T18:10:27.459Z</atom:updated>
            <content:encoded><![CDATA[<p>ASAP stands for As Soon As Possible.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The gatekeeper idea you mention is one of these elements that I feel is self-reinforcing.]]></title>
            <link>https://medium.com/@enkiv2/the-gatekeeper-idea-you-mention-is-one-of-these-elements-that-i-feel-is-self-reinforcing-fb6764166e57?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/fb6764166e57</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 30 Aug 2016 17:49:31 GMT</pubDate>
            <atom:updated>2016-08-30T17:49:31.645Z</atom:updated>
            <content:encoded><![CDATA[<p>The gatekeeper idea you mention is one of these elements that I feel is self-reinforcing. Despite filmmaking equipment getting progressively cheaper, even indie budgets are growing, &amp; the whole industry is getting more and more insular, with low acceptance for spec scripts &amp; a lot of big-budget low-risk franchise flicks. From the 70s straight through the 90s, even though film cameras were an expensive specialty item &amp; editing equipment was difficult to use &amp; to afford, we had people dropping lots of money trying to make (mostly awful) films. Today, when it’s possible for someone in the lower middle class in the west to make a feature length film with only the phone &amp; the computer they already have (paying nothing for software), we still have big-budget theoretically-indie youtube channels, rather than an explosion in amateur narrative films.</p><p>I used to run something called the “No Budget Film Contest”. We’d take submissions of films, rank them, &amp; give small (less than $10) cash prizes to the top 3. For a film to be eligible, the creator of the film could not have paid for anything specifically for the film, with the exception of camera rental — no paid actors, no set pieces or props, no expensive editing software. The goal was to demonstrate that one could make reasonably interesting movies using no resource other than time: in other words, that small scale productions can be valuable, and that you don’t need to get studio involvement or a successful kickstarter to make a film. It’s been a while since I hosted one of those, but it might be time again.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[“ASAP as possible” is redundant.]]></title>
            <link>https://medium.com/@enkiv2/asap-as-possible-is-redundant-2c54961883?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/2c54961883</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 30 Aug 2016 17:13:11 GMT</pubDate>
            <atom:updated>2016-08-30T17:13:11.857Z</atom:updated>
            <content:encoded><![CDATA[<p>“ASAP as possible” is redundant. (I’m surprised you didn’t notice this typo when you went to stick it in a pull quote.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I have to agree with all of your points here.]]></title>
            <link>https://medium.com/@enkiv2/i-have-to-agree-with-all-of-your-points-here-2fc5a2b71d0f?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/2fc5a2b71d0f</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 29 Aug 2016 13:27:11 GMT</pubDate>
            <atom:updated>2016-08-29T13:27:11.838Z</atom:updated>
            <content:encoded><![CDATA[<p>I have to agree with all of your points here. But, at the same time, on the scale set by the other TOS reboot films, this one is the closest to Star Trek — in the sense that it has an interesting and complex plot, ensemble cast drama, &amp; elements of the utopian subtext that characterized TOS. The other two have leaned much closer to generic-sci-fi-action — though Star Trek movies have always been a lot more action-oriented and a lot less talky than the shows.</p><p>Was the jokeyness a bit out of character for a Trek film? Sure, particularly for the reboot franchise; on the other hand, the other films in this group have been particularly over-serious grimdark fare (even as they used absurd plotlines that made “Spock’s Brain” and “Move Along Home” look normal), and so expanding upon the only redeeming quality of previous scripts — one-off jokes — is justified. (This is hardly out of line for Trek films; after all, the best — or at least most interesting — Trek film is The Journey Home, which is also the silliest.)</p><p>I more or less agree with MovieBob’s review here: Star Trek Beyond is, as a sci-fi action film, passable; as a Trek film it’s mediocre; as a Trek film in the reboot franchise, it’s surprisingly good, and would have been indicative of a worthwhile series had it been the first film. Because it’s the third, and because we’ve already lost some of the cast, the reboots as a whole probably won’t be able to recover, because even if the general improvement in quality continues, it doesn’t have enough remaining installments to become worthwhile as a whole.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[It’s a mistake to consider Wikileaks as a media organization, because they are generally anti…]]></title>
            <link>https://medium.com/@enkiv2/its-a-mistake-to-consider-wikileaks-as-a-media-organization-because-they-are-generally-anti-30dfa981ed2f?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/30dfa981ed2f</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 22 Aug 2016 18:10:04 GMT</pubDate>
            <atom:updated>2016-08-22T18:10:04.713Z</atom:updated>
            <content:encoded><![CDATA[<p>It’s a mistake to consider Wikileaks as a media organization, because they are generally anti-curation. There’s little rhyme or reason to the leaks they host, because they put up anything that’s submitted that they have reason to believe is legitimate. This makes them closer to a repository for leaked information — which is, of course, what they’ve been claiming to be the whole time. To the extent that they perform any kind of extra work — from redaction to supporting internal search (as they did with the cables) — it’s because they had something of such great importance that they felt the need to improve accessibility even if it damaged the correctness in minor ways. This should be seen as a divergence from their goals, rather than part of their core goal set.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[An alternate wizard/cleric distinction]]></title>
            <link>https://medium.com/@enkiv2/an-alternate-wizard-cleric-distinction-4d9620a2d1a8?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/4d9620a2d1a8</guid>
            <category><![CDATA[magic]]></category>
            <category><![CDATA[roleplaying]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 26 Aug 2016 14:52:32 GMT</pubDate>
            <atom:updated>2016-08-26T14:52:32.380Z</atom:updated>
            <content:encoded><![CDATA[<p>I’ve been reading <em>Playing the World</em>, Jon Peterson’s scholarly history of the origins of Dungeons &amp; Dragons. Peterson elucidates the circumstances around the wizard/cleric distinction well, explaining that such a distinction had very little basis in fantasy literature (and none in Chainmail, Gygax’s predecessor to the D&amp;D ruleset) but instead appears to come from Gygax’s religious background &amp; various complaints about the absence of religion in medieval &amp; fantasy wargaming. As a result, while magic users are fully irreligious, we have a separate class that is essentially a specialist magic user whose domain of abilities is based on a credulous reading of christian miracle-work — along with a dynamic involving power level being limited by a fall from grace. This is wholly at odds with the essentially pagan attitude elsewhere in the extruded fantasy product tradition that D&amp;D in many ways codified: a universe where a thief can be lawful good is not in any way a christian universe, even in terms of the secularized pseudo-christian morality that binds clerics. Instead, since we’re talking magic systems, we might look at historical occult traditions and classifications: specifically, the thelemic conception of left-hand versus right-hand path.</p><p>Talking to magick practitioners about the left hand and right hand paths is like talking politics at a family gathering: it’s a recipe for broken hearts. For the sake of this essay, I’m going to use a strict and simplified division: left-hand magic is performed using the abilities of the magic practitioner directly, and comes down to a set of rules and mechanics; right-hand magic, on the other hand, relies upon no special abilities in the practitioner, but instead a knowledge of means by which the practitioner can convince supernatural entities to perform tasks. This is certainly not the only way to interpret left-hand vs right-hand traditions, but the major alternative (which applies a moral gloss, considering left-hand to be synonymous with black magic) is less useful for the purpose of role playing systems &amp; ultimately redundant; I would furthermore claim that conflating the two (as many traditions do) is at best an indication of anti-secular bias.</p><p>Untangling left-hand and right-hand mechanisms in historical occult practices is difficult, in part because non-secular traditions perform theological gymnastics to reclassify seemingly left-hand practices as right-hand practices, thereby avoiding anti-left-hand bias. This is particularly common in monothesistic contexts: the use of kaballistic formulae whereby the magician manipulates letters or numbers representing the state of the world in order to manipulate the world appears fairly left-hand, but by identifying the material world with an aspect of the divine and invoking predestination, we can treat it as a form of prayer — that most representative form of right-hand magic. For the sake of this essay I would like to avoid these kinds of tricks entirely, and consider only those magical techniques that directly interact with a supernatural entity as right-hand.</p><p>And so, what does this give us? It gives us a richer domain for the cleric, reallocating some of what would otherwise be the domain of wizards. In a clearly polytheistic context, the low-level cleric also takes on some aspects of bards, being capable of granting boons to particular attributes by prayer or sacrifice to gods associated with those attributes. Contracts with gods, as in voodoo, are the domain of clerics; control of elementals, summoning of &amp; contract with demons, and invocation and evocation of any non-humanoid ‘monster’ likewise. Rather than needing to keep up a kind of pseudo-christian morality, a cleric would need to merely act in a way in line with the gods he or she actually interacts with. (Many polytheistic pantheons contain a god of communication who acts as a gatekeeper: Legba in voodoo, Ganesha in hinduism; any cleric would need to act in a way that pleases the gatekeeper deity, or risk losing access to the whole pantheon, but what this means is very different between pantheons: what is fine with Mercury is unlikely to be acceptable to Ganesha.)</p><p>This would require moving many of the healer &amp; support roles to another class; after all, the cleric redefined in this way would be significantly more powerful as an offensive class at higher levels and would not have special healing abilities at lower levels.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OK. There’s a pretty big gap between scheduling the announcement of a leak to maximize press (and…]]></title>
            <link>https://medium.com/@enkiv2/ok-theres-a-pretty-big-gap-between-scheduling-the-announcement-of-a-leak-to-maximize-press-and-2aaea02a590f?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/2aaea02a590f</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 24 Aug 2016 13:55:53 GMT</pubDate>
            <atom:updated>2016-08-24T13:55:53.724Z</atom:updated>
            <content:encoded><![CDATA[<p>OK. There’s a pretty big gap between scheduling the announcement of a leak to maximize press (and thus maximize donations to your non-profit organization) and trying to manipulate the election of a foreign country in favor of your ideological enemy, though.</p><p>Why would a collection of mostly european anarchists want a Trump presidency? I don’t see any traces of accelerationist rhetoric going on; if anything, Wikileaks appears to take the attitude that transparency in general will improve governance, rather than the idea that discrediting the idea of government in general is desirable. Julian Assange is not Nick Land; his outlook is a lot more utopian.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I don’t think Wikileaks is choosing their timing.]]></title>
            <link>https://medium.com/@enkiv2/i-dont-think-wikileaks-is-choosing-their-timing-fe7bd0c75dd9?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/fe7bd0c75dd9</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 22 Aug 2016 18:12:42 GMT</pubDate>
            <atom:updated>2016-08-22T18:12:42.917Z</atom:updated>
            <content:encoded><![CDATA[<p>I don’t think Wikileaks is choosing their timing. They are not, and have never claimed to be, a journalistic outfit: if they were, they would assert control over their material and choose particular material to release (which they do not).</p><p>They are a repository for leaked material. The value of the leaked material is occasionally useful as a PR strategy to get more support, but they have no particular problem hosting uninteresting leaks — which is most of what they supply.</p><p>Don’t compare them to the New York Times; instead, compare them to MegaUpload.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Saving the magic system of Familiar of Zero from itself]]></title>
            <link>https://medium.com/@enkiv2/saving-the-magic-system-of-familiar-of-zero-from-itself-869685db4ae9?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/869685db4ae9</guid>
            <category><![CDATA[magic]]></category>
            <category><![CDATA[game-design]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 22 Aug 2016 15:28:36 GMT</pubDate>
            <atom:updated>2016-08-22T15:28:36.882Z</atom:updated>
            <content:encoded><![CDATA[<p>Familiar of Zero isn’t just a 2006 anime — it is the most 2006 anime I’ve ever seen. It’s the kind of uninspired extruded-fantasy-harem-crap we always complain about, in its purest and most unadulterated form. Its protagonist is without any particular traits, other than an over-the-top lecherousness that while it sticks out now was more or less par for the course a decade ago for harem shows. The romantic lead is the kind of poor-little-rich-girl tsundere we wouldn’t see properly fleshed out and given characterization until Toradora. There’s a large supporting cast of generic archetypes. The most interesting and original character may be Colbert, a plot device of a balding, kindly but boring professor who is also prone to chasing after myths — kind of like if your high school social studies teacher spent his free time trying to find Atlantis — but he is mostly notable for how little he resembles Stephen Colbert. It’s a spectacularly forgettable show, notable mostly for how stupid every single character appears to be. But what it does have is an interesting and well fleshed-out magic system.</p><p>That is, until the plot starts.</p><p>You see, the way magic works in this world is that each spell works with one of the four classical greek elements. Even simple spells that are theoretically identical are completely different between elements: the spell to illuminate the tip of a wand would have nothing in common in the mechanics of casting between a method using air and a method using earth, even though the result would be identical. A ward or seal created by fire magic can only be undone by fire magic. This creates a pretty stable set of parameters. Imagine this from the perspective of game design for some MMORPG: even if every player character is a mage, you would expect a party to by necessity contain a member specializing in each type of magic. To the extent that attack spells are used, they are undone by attack spells from an opposing element, usually — fire can be defeated by water or redirected by wind, etc.</p><p>And then, we’re introduced to the fifth element, void, which is incredibly powerful and can beat anything. Because that’s the only way our protagonists can be put into interesting situations: by deus ex machina.</p><p>Ignoring void magic, we have the possibility of multi-classing. The idea is that extremely talented people can reach the limit of advancement in one form of magic and then start from the bottom in another form. If you can master three of the four forms of magic, you become a triangle mage, and can cast spells that weave together the three elements in such a way that it would be very difficult for three high level mages of the individual elements to undo; only a triangle mage specializing in the same three elements, or a square mage who has mastered all four, can undo it.</p><p>Void magic is in-born, can’t be properly studied, operates mostly by intuition, and is incompatible with all the other forms. So it breaks everything.</p><p>The world in which this show takes place is a kind of extension of feudal europe, in which all those capable of magic are considered a part of the aristocracy, and where rival kingdoms are in politically precarious situations, with webs of secret alliances, spies infiltrating each other’s kingdoms, and aristocrats trying to foment populist uprisings among the peasantry. In other words, a fairly realistic depiction of a society where a whole class of people have magic powers passed on along the bloodline. We have plenty of call-outs to actual historical events, including a revolution in the britain-expy called Albion wherein a guy named Cromwell kills a prince named Wales and turns the country into a dictatorship. Adding intrigue are various magical devices that can temporarily animate corpses or cause people to act against their will while in line of sight.</p><p>And then, the void magic is powerful enough to kill all the conspirators. Accidentally. With the help of a world war two era fighter plane. This show keeps generating promise and then screwing it up.</p><p>Without the main characters, we have the setup for a really interesting game or story here. We have a complex but internally consistent set of rules for magical warfare — one that rewards teamwork at the lower levels and rewards achievement at the endgame, encouraging people to max out their level up to four times. We have interesting sets of alliances and conflicts: nations at war with each other and themselves, spy networks, the double-cross system. We have devices that have interesting abilities and limitations: the ability to temporarily control a corpse, the ability to control a living being at short range and under line of sight. We have an interesting combat system, with familiars tanking for mages and an interaction between elements. I could imagine something similar to a cross between WoW and Planetside — an ongoing war of small-scale conquest along the edges of domains, powered by a steady supply of fresh blood from strongholds where mages in training follow quest lines to develop their skills.</p><p>All we need is somebody to take advantage of this, instead of breaking it in the name of making a generic hero’s journey story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Zizek (along with a handful of other figures in media criticism that are full of ideas but short on…]]></title>
            <link>https://medium.com/@enkiv2/zizek-along-with-a-handful-of-other-figures-in-media-criticism-that-are-full-of-ideas-but-short-on-eea7190c3d19?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/eea7190c3d19</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 22 Aug 2016 14:41:51 GMT</pubDate>
            <atom:updated>2016-08-22T14:41:51.292Z</atom:updated>
            <content:encoded><![CDATA[<p>Zizek (along with a handful of other figures in media criticism that are full of ideas but short on consistency, like McLuhan) are, I find, best viewed from the same lens as divinatory bibliomancy or generative or surrealist writing-games. In other words, the juxtapositions they create can help externalize and elucidate insights that come within us, but we should not attribute those insights to the ostensible authors, because for every ‘true’ insight we get from those texts, the direct opposite can be supported equally well by the same material. Rather than a string of words containing clear meaning, I see these authors as creating a string of vague associations with strong resonances — and we as readers can cherry-pick particular ideas and complete them ourselves, just as Burroughs did with his cut-ups, or a tarot card reader does with his spread.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Caffeine takes about 20 minutes to metabolize to the point where it can suppress adenosine reuptake…]]></title>
            <link>https://medium.com/@enkiv2/caffeine-takes-about-20-minutes-to-metabolize-to-the-point-where-it-can-suppress-adenosine-reuptake-4c9615a0ff4b?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/4c9615a0ff4b</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 22 Aug 2016 14:21:30 GMT</pubDate>
            <atom:updated>2016-08-22T14:21:30.823Z</atom:updated>
            <content:encoded><![CDATA[<p>Caffeine takes about 20 minutes to metabolize to the point where it can suppress adenosine reuptake. This is how people do “coffee naps”.</p><p>Twenty minutes is plenty of time to write down 10 original ideas. Why not chug your coffee (or use caffeine pills), then spend the following 20 minutes writing your ideas? Alternately, sip your coffee while writing your ideas — and take advantage of the much slower ramp-up in the effects.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The trademark issue is pretty cut and dried: a trademark holder must show due diligence in…]]></title>
            <link>https://medium.com/@enkiv2/the-trademark-issue-is-pretty-cut-and-dried-a-trademark-holder-must-show-due-diligence-in-88adaa107117?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/88adaa107117</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 22 Aug 2016 14:17:34 GMT</pubDate>
            <atom:updated>2016-08-22T14:17:34.394Z</atom:updated>
            <content:encoded><![CDATA[<p>The trademark issue is pretty cut and dried: a trademark holder must show due diligence in protecting its trademarks or else it loses control of the trademark permanently; as a result, a trademark holder has every incentive to send nasty messages to anybody they might have reason to believe might be seen by future courts as infringing upon their trademark, lest they be suspected of not protecting it well enough. (Basically, the law incentivizes trademark holders to be assholes &amp; go overboard, which is why Disney sues day care centers for having Disney-owned characters on murals.)</p><p>As for linking: you may not remember, but the court case regarding the legal status of links was a *big* deal, and old media companies are likely to still be pretty sore about it. It was only twenty years ago that the question of whether or not deep linking was a form of infringement; similar mechanisms (like the use of frames to wrap ads around other people’s sites) were ruled against. It doesn’t really matter if the NYT is planning to make a bot: they didn’t want to give up on suing Google &amp; anybody else who does deep links, and now that they have to, they have every intention to prevent that verdict from being generalized to slightly different circumstances.</p><p>Furthermore, you can make the argument that use of the API might, in certain cases, lower the number of ad views they get or screw up their progressive paywall system. While I’m not convinced that either system is making them bank in the way that they might hope (and both are easily &amp; regularly bypassed), they have a financial incentive to label and shun anything that might conceivably be used to circumvent these mechanisms — particularly if the product is not commercial.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I’ve always been suspicious of how much companies that brand themselves as “tech companies” are…]]></title>
            <link>https://medium.com/@enkiv2/ive-always-been-suspicious-of-how-much-companies-that-brand-themselves-as-tech-companies-are-a61ff71bb427?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/a61ff71bb427</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 22 Aug 2016 13:38:15 GMT</pubDate>
            <atom:updated>2016-08-22T13:38:15.634Z</atom:updated>
            <content:encoded><![CDATA[<p>I’ve always been suspicious of how much companies that brand themselves as “tech companies” are drinking their own kool-aid, and how much is a calculated PR/branding move chosen specifically to provide an “in” for avoiding regulations. Uber can hardly be considered anything other than a taxi service — but by claiming to be a tech company they have an excuse to use this Randian mythic form to reframe any circumvention of labor regulations as a battle of smart renegade heroes of industry against an oppressive government, rather than the narrative of a large corporation systematically abusing its employees (which would be more natural if Uber identified as a tech company).</p><p>Given the trend toward creating service companies employing mostly contractors and claiming them as “tech companies” because of their use of employee management software, the suggestion that this is some kind of organic misunderstanding rather than a canny manipulation seems increasingly absurd — although it’s not unusual for intellectually incestuous communities to become prone to episodes of truly monumental mass delusion, so we shouldn’t expect the silicon valley VC industry to fare any better than the judicial system of eighteenth century Salem, nor for those forced by circumstance to implement those delusions to fare any better than the poor of any community in the middle of a witch- or werewolf-hunt.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[There’s another path here that you haven’t mentioned: take advantage of content generation…]]></title>
            <link>https://medium.com/@enkiv2/theres-another-path-here-that-you-haven-t-mentioned-take-advantage-of-content-generation-d05ee735e34c?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/d05ee735e34c</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 06 Jul 2016 13:55:18 GMT</pubDate>
            <atom:updated>2016-07-06T13:55:18.711Z</atom:updated>
            <content:encoded><![CDATA[<p>There’s another path here that you haven’t mentioned: take advantage of content generation technology and combine it with your own efforts. (This isn’t a new idea: a few months ago, at least two or three ‘creative autosuggestion’ projects were floating around; Burroughs edited the output of cutups, as did Bowie; after Deep Blue became the world’s best chess player, top-tier players started playing ‘centaur’ or ‘cyborg’ chess wherein they collaborated with chess programs.)</p><p>That said, being a part of the generative writing community, I think you slightly overstate the state of the art. Generative poetry is pretty good, in part because poetry is pretty flexible and unusual stylistic choices are typically seen as meaningful: generative writing does well in forms that are either extremely experimental or extremely formulaic. Machine-generated short articles performing numbers-driven reporting of factual events (such as sport or financial stories) are more or less indistinguishable from human-written stories of the same type, but also represent a fairly uninteresting application of this technology (in part because, while the AP and other news wires started using this technology only recently, it’s been possible for even a mediocre programmer to implement this kind of thing since the 50s). Long-form narrative-driven works don’t tend to be readable, although in the past few years there’s been a lot of progress (for instance, there was an entry in National Novel Generation Month in 2015 called MARYSUE that generated pretty convincing pastiches of bad Star Trek fanfiction, most of which is not much worse than human-written bad Star Trek fanfiction).</p><p>There are certain things that generative writing systems are very good at. These systems are capable of being intensely creative (in the sense that they can generate juxtapositions of ideas that could never occur to a human being), but lack any good approximation of human taste: as a result, writing systems can be used as a creativity prosthesis, where human judgement isolates good ideas from bad ideas while the machine performs the heavy work of producing ideas. Likewise, these systems are good at being exhaustive: it’s trivial to take a couple corpora and a format and produce every possible variation on a theme, if someone is willing to wade through the output looking for the interesting material. Human editing makes machine-generated writing much more feasible for even long-form work.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Spoiler alert: I don’t hate you for being immune from spoilers; in fact, to the extent that this…]]></title>
            <link>https://medium.com/@enkiv2/spoiler-alert-i-dont-hate-you-for-being-immune-from-spoilers-in-fact-to-the-extent-that-this-a68121b7961a?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/a68121b7961a</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 17 Aug 2016 18:03:10 GMT</pubDate>
            <atom:updated>2016-08-17T18:03:10.173Z</atom:updated>
            <content:encoded><![CDATA[<p>Spoiler alert: I don’t hate you for being immune from spoilers; in fact, to the extent that this has actually been empirically tested, the general consensus appears to be that <a href="http://phys.org/news/2016-05-spoiler-alertspoilers-stories.html">spoilers improve the enjoyment of media</a>.</p><p>What is lost to spoilers? Only the shock value of sudden plot twists — in other words, the cheapest and most evanescent emotional effect of the laziest narrative constructions. Media that can be “spoiled” by spoilers is media that isn’t worth repeat viewing, continued thought, or discussion. For everything else, spoilers improve enjoyment.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[As much as I hate to rain on your parade, I’m afraid I can’t agree at all with your premises.]]></title>
            <link>https://medium.com/@enkiv2/as-much-as-i-hate-to-rain-on-your-parade-im-afraid-i-can-t-agree-at-all-with-your-premises-6d88cb5c68d0?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/6d88cb5c68d0</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 05 Jul 2016 15:11:42 GMT</pubDate>
            <atom:updated>2016-07-05T15:11:42.456Z</atom:updated>
            <content:encoded><![CDATA[<p>As much as I hate to rain on your parade, I’m afraid I can’t agree at all with your premises. This article itself argues against you.</p><p>You’ve written a short article that shallowly rehashes ideas that were already long past their expiration date in the 70s, when they were being summarized in Future Shock. You cite studies that don’t support your findings, and complain about trends that are mostly imaginary. Ultimately, you’ve projected your own subjective feeling of burn-out onto the world at large, channeling it into a pastiche of what is essentially now a popular subgenre of theoretically non-fiction op-eds: the anti-internet thinkpiece.</p><p>Have you constructed a media diet for yourself that negatively impacts your life? Clearly. Is this common? Sure. Is it new? Not remotely. You’ve taken perfectly good tools and used them to cut your limbs off, and now you’re complaining that the tools are dangerous.</p><p>The only part of this article that is non-trivially correct is the part about multitasking &amp; unfinished task cues. But, the idea that this mechanism should be used as an excuse to do some kind of internet detox is absurd. Instead, be mindful of your own cognitive biases, and take advantage of this effect as incentive to perform the tasks you intend to perform.</p><p>Easy access to information makes shallow understanding possible but does not encourage it; after all, it also makes much deeper understanding possible. If this access makes you tend toward shallowness, that’s an indication of your own intellectual laziness, not a reflection of the innate tendencies of the tools at your disposal. Practice some discipline, and these tools will help you gain more depth. (Without much discipline and with only a little foresight, it would have demonstrated to you that there is nothing original in this essay; in Medium’s daily recommendation email alone, I see three of this type a day, though they are often shorter and have fewer reviews or recommendations. You could have saved time by recommending some of those, rather than writing this yourself.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[It’s important to note that Wikileaks itself doesn’t choose what information to grab & host; in…]]></title>
            <link>https://medium.com/@enkiv2/its-important-to-note-that-wikileaks-itself-doesn-t-choose-what-information-to-grab-host-in-97192ef94da3?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/97192ef94da3</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 03 Aug 2016 13:53:02 GMT</pubDate>
            <atom:updated>2016-08-03T13:53:02.809Z</atom:updated>
            <content:encoded><![CDATA[<p>It’s important to note that Wikileaks itself doesn’t choose what information to grab &amp; host; in terms of editorial control, it sits somewhere between pastebin &amp; the New York Times: it mostly receives unsolicited leaks, and it will spend extra effort cleaning up &amp; making accessible things that have wide appeal, but will more or less host anything. Looking at the raw list of leaks makes this clear: there are a lot of items along the lines of the membership list of Condoleeza Rice’s sorority (which is fairly uninteresting).</p><p>Does the wikileaks administration reject some submissions? Probably — after all, there are plenty of people who, given a place that will host anything, will use it to pirate hollywood movies &amp; child porn. But, if somebody offers wikileaks an email dump, whether or not they will host it is not even a question: of course they will host it, because that’s what they see as their mission.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[tl;dr verison: original article is a dumb rehash of stuff that was proven wrong thirty years ago…]]></title>
            <link>https://medium.com/@enkiv2/tl-dr-verison-original-article-is-a-dumb-rehash-of-stuff-that-was-proven-wrong-thirty-years-ago-cad142b03ac0?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/cad142b03ac0</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 03 Aug 2016 12:10:29 GMT</pubDate>
            <atom:updated>2016-08-03T12:10:29.165Z</atom:updated>
            <content:encoded><![CDATA[<p>tl;dr verison: original article is a dumb rehash of stuff that was proven wrong thirty years ago, and the author’s shallowness has nothing to do with the internet &amp; everything to do with being lazy.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I don’t know where you got any of the ideas in this article.]]></title>
            <link>https://medium.com/@enkiv2/i-dont-know-where-you-got-any-of-the-ideas-in-this-article-a469369df6a6?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/a469369df6a6</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 01 Aug 2016 12:55:14 GMT</pubDate>
            <atom:updated>2016-08-01T12:55:14.528Z</atom:updated>
            <content:encoded><![CDATA[<p>I don’t know where you got any of the ideas in this article.</p><p>Copyright is not a protection against communism. The concept of copyright predates communism by a few centuries, and was initially formed as a means of mediating conflicts between publishing guilds and thus making censorship of printed materials easier. When the intellectual property framework of the united states was being designed, it became reframed in the same terms as patents: as a means of guaranteeing a temporary monopoly in order to encourage people to donate ideas to the public domain. This would be the 1790 formulation you were talking about — fifty years prior to the first ideas we could reasonably consider part of ‘communism’. In fact, we can consider copyright (along with other time limited forms of IP like patents, as opposed to trade secrets) to be a tool in support of ‘communist’ ideas in the sense that it is specifically intended to feed the pool of publicly owned ideas.</p><p>Copyright has definitely changed. For instance, in countries that are signatories to the Berne Convention (which the United States has been since 1957), all copyrightable materials are automatically implicitly under copyright — copyright registration is purely for the sake of expediting a suit by providing evidence from a trusted third party. During the middle of the twentieth century, implicit copyright was introduced to the United States in several different ways, and there was a short period wherein unregistered works were only implicitly copyrighted if they had a copyright statement attached (which is why Night of the Living Dead is in the public domain); this is no longer the case. In 1998, the Digital Millenium Copyright Act introduced the notion of safe harbour provisions in order to grant partial protection to websites hosting arbitrary third party content; this is a major break from all prior copyright legislation. When anti-circumvention clauses were added to the DMCA, that’s another major change. The idea of the FBI actively investigating breach of copyright is another recent change not in line with the historical spirit of IP law (which, since it is civil law, should theoretically only be investigated in the case of a suit).</p><p>I understand that you’re trying to push a product here. But, before trying to push a product relating to copyright law, try doing at least a modicum of research. I agree that copyright is currently benefitting mostly large corporations; however, this is not because of the cost of registration (because registration is not necessary) but because of a general lack of understanding on the part of regular people about the nature of IP law; this post perpetuates the worst of these misunderstandings.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A lot of the ideas about OO that are mentioned in Mr Scalfani’s essay were pushed and popularized…]]></title>
            <link>https://medium.com/@enkiv2/a-lot-of-the-ideas-about-oo-that-are-mentioned-in-mr-scalfanis-essay-were-pushed-and-popularized-deb54a087c2c?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/deb54a087c2c</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 25 Jul 2016 12:39:28 GMT</pubDate>
            <atom:updated>2016-07-25T12:39:28.112Z</atom:updated>
            <content:encoded><![CDATA[<p>A lot of the ideas about OO that are mentioned in Mr Scalfani’s essay were pushed and popularized by academic materials for teaching Java and C++ as first languages; to the extent that they are true in those languages, they are mostly true of toy examples. These materials hammer home these benefits as ideals while also pushing OO as a panacea, &amp; are aimed at naive beginners, who lack the experience to argue coherently against them.</p><p>Using OO when and where it is appropriate, and using languages like Smalltalk that do OO ‘right’, is fine. It’s not fine to tell 15 year old newbies that OO is the best tool for every job, and that all Java code is OO — and that’s what practically every introductory Java textbook will do, because it’s literally part of the standardized APCS curriculum &amp; part of the accreditation process for university computer science programs.</p><p>It’s not that OO should be attacked because it’s inherently terrible. Instead, there’s a fantasy idea of OO promoted by a whole industry, and that fantasy needs to be attacked because it is systematically producing incompetent programmers who write bad code.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I always make this argument, and it usually falls on deaf ears.]]></title>
            <link>https://medium.com/@enkiv2/i-always-make-this-argument-and-it-usually-falls-on-deaf-ears-98e02299ee97?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/98e02299ee97</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 26 Jul 2016 17:14:22 GMT</pubDate>
            <atom:updated>2016-07-26T17:14:22.360Z</atom:updated>
            <content:encoded><![CDATA[<p>I always make this argument, and it usually falls on deaf ears. But, this is a cultural and industry-norm-driven pattern — and Netflix is in prime position to upset industry norms (as it’s already done by releasing whole seasons at once).</p><p>In the anime industry, outside of a handful of long-running high-profit and usually every episodic shows aimed at younger audiences, there’s a very different attitude toward extending series. In the US, we tend to make new seasons of a show until it gets so bad that it gets cancelled; in Japan, because cancellation is such a big deal (it’s so rare that I’ve only ever seen one cancelled show), you have a very different pattern: a single season is planned out and made, and if it’s sufficiently popular and the source material allows for it, a decision is made about whether or not to create a sequel, usually several years later. The average show is between 12 and 26 episodes long; most shows have exactly one season, and when new seasons appear, whether or not they are a continuation of the same story depends heavily upon whether or not the show is an adaptation of a continuing story in another medium. As a result, a season is like a miniseries: good shows are finely crafted single-season stories that are never revisited, and a show with more than three seasons is almost always considered mediocre at best.</p><p>If Netflix adopted this style, they could push a change in the industry. After all, television has already changed: serious character-driven stories with complex ongoing narratives have become valued only in the past fifteen years or so, displacing the normal highly-episodic series well-adapted to syndication by channels that only license a small portion. If the expected form of television changed in this way, we’d see fewer shows that follow the pattern of Buffy — you know, an excellent first season followed by increasingly mediocre and convoluted follow-up seasons designed to pander to an obsessive core fanbase.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[General purpose, in my view, is an overstatement.]]></title>
            <link>https://medium.com/@enkiv2/general-purpose-in-my-view-is-an-overstatement-422d7a8d58e1?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/422d7a8d58e1</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 25 Jul 2016 14:10:11 GMT</pubDate>
            <atom:updated>2016-07-25T14:10:11.914Z</atom:updated>
            <content:encoded><![CDATA[<p>General purpose, in my view, is an overstatement. (That said, maybe I work with an atypical set of problems.)</p><p>OO is appropriate when the least complicated way of modelling a problem is in terms of agents with internal states communicating. In other words, something like a physics engine is a natural fit for OO.</p><p>I mostly work with processing large amounts of text data between formats, occasionally doing analysis. (This is, as far as I can tell, a pretty typical programming job.) This kind of work lends itself well to multiple parallel stages with relatively little state, much of which is short-lived. In other words, it fits well with the UNIX pipeline model, and both OO and FP would be a poor fit. (I’ve had to work with other people’s attempts to shoehorn this kind of process into an OO framework; when I can get away with it, I replace a few thousand lines of Java with two or three lines of shell.) In other words, this is the ‘general case’ for my line of work.</p><p>I occasionally come across a circumstance where OO makes sense. I wrote an OS in D, and because D’s object system is similar to C’s structs and unlike C++’s objects, I was able to make excellent use of inheritance &amp; polymorphism for wrapping abstraction around memory-mapped devices like VGA memory; I also made heavy use of object orientation when modeling some novel data structures for Project Xanadu. However, in none of these cases was it convenient or sensible to go full-OO — all of these cases were ‘mixed paradigm’ with a lot of procedural and functional code, and even when I wrote OO, I violated encapsulation whenever I needed to &amp; barely took advantage of inheritance.</p><p>I understand why pedagogy around OO is so popular. After all, human beings deal with objects with internal state in real life all the time, so these concepts are familiar to non-programmers. Likewise, inheritance hierarchies mimic the form that every naive cataloguer produces. But, like John Wilkins in his Essay Towards a Real Character and the imaginary Chinese philosopher in Borges’ Celestial Emporium, we quickly find that reality doesn’t neatly conform to either a hierarchy of relation or a conception of objects with attributes.</p><p>In other words, OO is a convenient stepping stone to other paradigms, and is useful in of itself when a mapping of the problem space to a set of objects is either immediately obvious or (in the case of physics engines) provided in the literature, but its most useful attribute is the way in which it demonstrates its own limits. Despite this, because most formally trained software engineers have only ever had serious experience with so-called OO languages &amp; with material that promotes OO to the exclusion of other paradigms, there is the (false, but widespread) belief that the problems introduced by trying to shoehorn the wrong problems into OO are problems of programming in general and are irreducible. The idea that there is such a thing as a general purpose programming paradigm that is ‘good enough’ for anything, while convenient for casual developers who would like to avoid learning more than the basics of a single language, supports this essentially artificial set of problems.</p><p>The current boom in interest in functional programming is hardly unexpected: you teach people that the one true paradigm is a bastard mix of OO and procedural programming for twenty years and that it’s the end of history, and as soon as they are exposed to an alternative they’ll jump all over it: most problems introduced by OO are artifacts of OO and dissolve as soon as you break out of it, but FP has similar artifacts.</p><p>Poor CS pedagogy is a bit of a hobby horse for me. OO is as it is, and I don’t have anything against it as such, but the idea that OO is generally applicable (or, more generally applicable than some other given paradigm) is getting in the way of professors and authors realizing that all serious developers need to have a full toolbox. The current miserable state of the development world is a result of every developer having a pair of vice grips &amp; nothing else — and while you can solve pretty much any problem after a fashion with a pair of vice grips and a few hours of fiddling, you end up with a lot of mangled screws and bloodied fingernails.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[One small complaint: you mention Moore’s Law as one of the reasons ML is having a rennaisance…]]></title>
            <link>https://medium.com/@enkiv2/one-small-complaint-you-mention-moores-law-as-one-of-the-reasons-ml-is-having-a-rennaisance-b091491daba1?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/b091491daba1</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 23 Jun 2016 12:28:24 GMT</pubDate>
            <atom:updated>2016-06-23T12:28:24.578Z</atom:updated>
            <content:encoded><![CDATA[<p>One small complaint: you mention Moore’s Law as one of the reasons ML is having a rennaisance; while it’s true that there’s an exponential growth trend involved, the trend in question is not actually Moore’s Law (which ended sometime between 2005 and 2007 depending on who you ask). Moore’s Law has to do with the number of transistors that can be fit on a single die — a number whose hard limit we’re bumping up against (because of the size of atoms); mechanisms to get around this limit don’t involve transistors as such and so the moniker doesn’t apply to them.</p><p>In popular science writing, Moore’s law has become a shorthand for all forms of exponential growth that affect performance-per-dollar or performance-per-inch of computer hardware. CS people sometimes use it this way, but (when it matters) make distinctions — and there are a number of other “laws” that are essentially similar in nature but apply to different metrics: Kryder’s law for storage density, Koomey’s Law for performance per watt. And then, there’s Englebart’s Law (which all these other accelerating performance laws are arguably a special case of): that the performance of human beings increases exponentially in all sorts of contexts and domains.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Bots are wonderful.]]></title>
            <link>https://medium.com/@enkiv2/bots-are-wonderful-8c890f179283?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/8c890f179283</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 11 Jul 2016 18:13:14 GMT</pubDate>
            <atom:updated>2016-07-11T18:13:14.351Z</atom:updated>
            <content:encoded><![CDATA[<p>Bots are wonderful. But, for a variety of reasons that should be so obvious as to not merit mentioning, if you’re trying to make money by creating a bot you’re making a huge mistake. (Because people haven’t managed to get the memo, I’ve gone over these reasons three or four times on Medium alone. But, spending a few minutes thinking about the situation should suffice.)</p><p>Of course, if somebody expects to make money off of phone apps they’re already laboring under a huge set of delusions. Rather than disabuse them of specific ones, I would recommend they instead switch to a more lucrative career in problem gambling and/or attempting to be struck by lighting for the insurance money.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Have you determined how much non-book content you are reading during the day?]]></title>
            <link>https://medium.com/@enkiv2/have-you-determined-how-much-non-book-content-you-are-reading-during-the-day-a8d93a1a9154?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/a8d93a1a9154</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 08 Jul 2016 12:07:55 GMT</pubDate>
            <atom:updated>2016-07-08T12:07:55.279Z</atom:updated>
            <content:encoded><![CDATA[<p>Have you determined how much non-book content you are reading during the day? During a typical day, I end up reading several books worth of articles, not to mention emails. I’m loath to value books over other forms of written content impulsively: after all, books are often crap and articles are often quite good.</p><p>Is it valuable to be self-aware about the way in which notifications and consumption of short-form content performs operant conditioning on you? Sure; this is why I have notifications off on my devices, avoid broadcast television entirely, and try to avoid reading any article that takes less than five minutes (with articles taking 20 minutes or more to read taking precedence).</p><p>But, a “book” has a lot of cultural and structural baggage: books are associated with traditional publishing pipelines (meaning that a book is written about a year and a half before anybody who isn’t a professional author, editor, or reviewer reads it), with a particular structure (several multi-page sections called chapters, organized either by topic or chronology, numbered) and attributes (even ebooks are usually paired with paper equivalents, and so features like internal hyperlinks, interactive sections, and direct feedback should be avoided; updates, to the extent that they exist at all, are limited to later editions which must be bought separately; a book is rarely less than 90 pages long and rarely longer than 500, because otherwise binding it would be prohibitively expensive for an approximately seven USD price point). How many of these attributes of a book are, in of themselves, valuable? How many of them, for a particular subject, are desirable constraints rather than undesirable ones? When we consider that books might also need to be audio books, we add more constraints: no diagrams, no extensive use of homophonic puns or homoglyphic puns, write nothing that is inherently unpronounceable.</p><p>I love books. But, when we uncritically value the book format we sacrifice ourselves to a kind of shallow reactive traditionalism that ultimately runs counter to precisely the kind of attributes that book-loving people ascribe value to: deep consideration and intellectual bravery. A book is a tool, and to consider it preferable for jobs for which it is unsuitable for reasons of habit and social signalling is to devalue it.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Novelty, Perversity, and Randomness]]></title>
            <link>https://medium.com/@enkiv2/novelty-perversity-and-randomness-307158924298?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/307158924298</guid>
            <category><![CDATA[writing-tips]]></category>
            <category><![CDATA[writing]]></category>
            <category><![CDATA[books]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 01 Jul 2016 18:17:08 GMT</pubDate>
            <atom:updated>2016-07-01T18:17:08.439Z</atom:updated>
            <content:encoded><![CDATA[<p>I recently read a blog post (never mind which one, since this is a pretty common position) railing against “rules of thumb” for writers that make generalizations about readers. This post made the argument that a readership, because it is heterogeneous, cannot be generalized about. Such an argument is untrue (one can take the mean, median, and mode of extremely diverse data sets and still get somewhat valuable information from that), but more crucially, it’s untrue in a boring way. It’s true that rules of thumb that make generalizations about readership are problematic, but this is the case for a much more interesting reason that I’ve never seen articulated.</p><p>First, I’d like to get something out of the way. These rules of thumb and generalizations about readers exist for a reason: specifically, they are useful to two different groups of authors. One group is expressly commercial: people whose primary or sole goal is to maximize their sales will want to optimize for a large readership, and will therefore want to model their readership and appeal to this model. The second group is the aspiring amateur: someone with no experience and no model at all of a readership or of the way in which one goes about writing benefits greatly from the confidence provided by any direction at all, even if the direction in question is anecdotal, misleading, limiting, or false; arbitrary advice benefits these people.</p><p>The real reason why rules of thumb are a problem is that readers read in order to satisfy a hunger for perversity. By this I mean that readers are looking for a special kind of novelty: within a constrained system (such as a fictional world, a genre, a style of argument or of writing, or a set of themes), a path through this domain is created that is plausible but surprising. The author is an engineer of subversion, creating expectations and then delighting the reader by perverting them. Rules of thumb, whether or not they correspond to tendencies desirable to readers, are best understood (as TvTropes notes) as a set of rules or expectations in the mind of the reader — in other words, as the starting point of subversion.</p><p>However much a reader may love some trope, the reader will love an interesting perversion of that trope more.</p><p>Writers, like readers, are human beings, unfortunately. Human beings are a bit too good at categorizing and finding connections: this is a liability when it comes to producing novel ideas or determining how novel an idea is once produced. Randomness-driven “writing machines” like cut-ups, bibliomancy, Cards Against Humanity, and similar techniques can introduce novelty unlikely to be produced by a human mind unaided; constraints like those in Oulipolian writing games or those used by Dr Seuss can force novelty from the reader’s perspective by warping the environment the writer is navigating: the most straightforward choice of words for a writer unable to use the letter ‘e’ will seem very strange to a reader not accustomed to playing the same game.</p><p>It is important to note that the novelty of a work is a property of the mind of the reader, not a property of the work itself. In other words, an experienced reader has more discerning taste as an inevitable consequence of that experience: anything is novel to a tabula rasa and nothing is novel to an omniscient being. As a result, the game of writing can never be won. Every set of expectations is the end result of someone subverting previous expectations. Furthermore, we can divide up groups of people by what expectations they have (and thus, what they find novel), essentially based on what they’ve already been exposed to.</p><p>A work like The Last Ringbearer is in dialogue with Lord of the Rings, but more importantly, it is a perversion of expectations created by Lord of the Rings; its value is lost on anyone who isn’t familiar with the original work. To a lesser extent, a work like Neuromancer is explicitly a perversion of the expectations set up by golden age SF: where Asimov would have given the protagonist role to someone in a role of power or authority, Gibson gave the protagonist role to someone incapable of changing even his own destiny, explicitly on the verge of being killed by minor criminals with the implication that he wouldn’t even be remembered, whose role in the story is that of a convenient tool for powers beyond reckoning; where Heinlein would have given us a wise-cracking Bill Murray protagonist and Asimov would have given us a Spock, Gibson gives us Case as Shinji Ikari; where any golden age author would have described only the important parts of the environment and shown us a gleaming, streamlined future, Gibson fixates on the tiny dents in the table of a diner and the smell of decaying newspaper piled in the entryway of a dilapidated storefront; where golden age governments are noble or evil, Gibson shows a world where government ranges from minor corruption to complete irrelevance. Similarly, Dune goes out of its way to pervert all our expectations: we have an aristocracy whose power is based on access to resources instead of an aristocracy based on the idea of genius loci and the divine right of kings as in most extruded fantasy product; we have faster than light space travel and a multi-planet civilization in a world without computers wherein most fighting is done using knives; our far-future society’s great new social and political movement is driven by an offshoot of Islam invented by an ecologist and practiced by desert nomads who ritually consume psychedelic drugs and drink their own urine. While these works can be consumed by people without the understanding of the context they are in dialogue with, the enjoyment gained by such readers is limited to that of intratextual perversion (i.e., plot twists), free-floating novelty (“what a cool idea!”), and expectations based on other domains like the real world; rather than being a lazy new trend by people trying to push cinematic universes, intertextual perversion is the primary defining factor in whether or not a creative work is considered seminal or culturally important within a genre. To use marxist dialectic terminology, a seminal work is one that is the antithesis of all that has come before it, and forces the genre thereafter to synthesize it. Every work in a genre is a reaction to each seminal work in that genre: either supporting it or reacting against it.</p><p>We can consider a genre to be defined by the parameters of its conventions: in other words, what attributes do its seminal works have in common? The domain of any interesting work in that genre, then, is in probing the unexamined assumptions of readers who have internalized these conventions: what things are these readers currently incapable of considering, and how can we surprise them by causing them to consider these ideas unexpectedly? Authors, being human, are probably also going to have a hard time considering unknown unknowns; they are advised to use machinery to aid them, since machinery has no problem being creative and original.</p><p>It is not that following the “rules” of a genre is foolishly stifling the wonderful underlying free creative spirit of the writer: any author who thinks that their underlying free creative spirit is something special never to be tamed is encouraged to look at their pile of rejection letters and reconsider a career outside the arts. Instead, following the “rules” misses the point entirely: the “rules” exist in order to make the game more interesting. Breaking the spirit of the law without breaking the letter, and vice versa, is the very manner in which writing is creative.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[There’s a difference between the Lake Woebegone effect and the Dunning Kreuger effect.]]></title>
            <link>https://medium.com/@enkiv2/theres-a-difference-between-the-lake-woebegone-effect-and-the-dunning-kreuger-effect-f1f5a8053f22?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/f1f5a8053f22</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 23 Jun 2016 15:16:23 GMT</pubDate>
            <atom:updated>2016-06-23T15:16:23.397Z</atom:updated>
            <content:encoded><![CDATA[<p>There’s a difference between the Lake Woebegone effect and the Dunning Kreuger effect. While the Lake Woebegone effect means that we tend to rank ourselves above average more often than is possible, the Dunning Kreuger effect has to do with scale: the degree to which we overestimate our abilities is inversely proportional to our actual skill level.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Regarding the ‘preferred music service’ example, it’s a bit funny that Amazon is not extending the…]]></title>
            <link>https://medium.com/@enkiv2/regarding-the-preferred-music-service-example-it-s-a-bit-funny-that-amazon-is-not-extending-the-a960a692bb65?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/a960a692bb65</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 23 Jun 2016 15:11:48 GMT</pubDate>
            <atom:updated>2016-06-23T15:11:48.403Z</atom:updated>
            <content:encoded><![CDATA[<p>Regarding the ‘preferred music service’ example, it’s a bit funny that Amazon is not extending the (Android/Palm) concept of ‘intents’ with simple fallback logic (“alexa, play me song X” can be handled by this list of three skill providers in preference order, so search the first and if it can’t play this song then fall back to searching the second).</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The author of this piece managed to write an entire article about the concept of slack without once…]]></title>
            <link>https://medium.com/@enkiv2/the-author-of-this-piece-managed-to-write-an-entire-article-about-the-concept-of-slack-without-once-5e38a32cb7a9?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/5e38a32cb7a9</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 13 Jun 2016 13:20:13 GMT</pubDate>
            <atom:updated>2016-06-13T13:20:13.925Z</atom:updated>
            <content:encoded><![CDATA[<p>The author of this piece managed to write an entire article about the concept of slack without once mentioning the Church of the Subgenius, and the long history of interplay between the philosophies of half-serious irreligions and hacker culture. Hell, he didn’t even mention Slackware.</p><p>In analyzing what slack means and why people care, it’s important to understand the other aspects of the slack memeplex: specifically, it’s important to understand the Church of the Subgenius, what aspects of the world it specifically satirizes, and its interplay with Discordianism. One reason is that, if anything, the CoS’s satire is becoming more and more relevant — and was always a great deal more on-point and meaningful than more mainstream variations like pastafarianism.</p><p>Where Discordianism sets its sights on control freaks by mixing eastern philosophy with greek mythology and creating a religion venerating chaos, the Church of the Subgenius sets its sights on capitalism and The Spectacle by combining evangelical christianity with UFO cults and creating a systematic veneration of laziness (which they call slack).</p><p>The messiah of the Church of the Subgenius is L. ‘Bob’ Dobbs, an idiot-savant con-man who can “sell anybody anything”, and he was tasked with leading the descendents of yetis to a pleasure planet. Membership costs thirty dollars, and eternal salvation is guaranteed “or triple your money back”. This is the matrix of ideas from which the concept of ‘slack’ emerged, and this is why it’s important: slack is an essentially subversive concept that stands simultaneously with and opposed to all the tacky late-night-tv Ed-Woods glory of ironic ad-worshipping hipsterism that substitutes bigfoot for Chuck Norris as an icon of ancestral masculine virility.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Another possibility: do nothing, and allow ad quality to degrade.]]></title>
            <link>https://medium.com/@enkiv2/another-possibility-do-nothing-and-allow-ad-quality-to-degrade-5b7874a0ee78?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/5b7874a0ee78</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 06 Jun 2016 14:26:49 GMT</pubDate>
            <atom:updated>2016-06-06T14:26:49.276Z</atom:updated>
            <content:encoded><![CDATA[<p>Another possibility: do nothing, and allow ad quality to degrade. Much as email spam &amp; phishing messages are intentionally unconvincing to factor out the possibility of intelligent and savvy people caught in the net and causing trouble, one can intentionally ensure one’s ads are removed by ad blockers and then specifically target groups that are unlikely to understand the very concept of ad blockers (seniors, children, the terminally unaware).</p><p>I’m not convinced that advertising as an industry can ever be saved from its downward quality trajectory: this trajectory is built in to the concept of advertising, and while the drop can be slowed or even backed up slightly, it cannot be stopped. We are living in the era of Late Advertising (by analogy to Late Capitalism), and like the Accelerationists, our best bet is to make advertising as bad as possible in order to hasten its total irrelevance.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[This isn’t a feature of some new revision of UML.]]></title>
            <link>https://medium.com/@enkiv2/this-isnt-a-feature-of-some-new-revision-of-uml-af08b7ab159e?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/af08b7ab159e</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 17 May 2016 18:10:07 GMT</pubDate>
            <atom:updated>2016-05-17T18:10:07.895Z</atom:updated>
            <content:encoded><![CDATA[<p>This isn’t a feature of some new revision of UML. This is one of the things UML was being used for in the late 90s. Most Java textbooks, for instance, use UML to describe Java syntax.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[If you’re going to replace regex half-way with UML and expect people to use a graphical editor, why…]]></title>
            <link>https://medium.com/@enkiv2/if-youre-going-to-replace-regex-half-way-with-uml-and-expect-people-to-use-a-graphical-editor-why-7645c58b3ef6?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/7645c58b3ef6</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 16 May 2016 15:48:20 GMT</pubDate>
            <atom:updated>2016-05-16T15:48:20.588Z</atom:updated>
            <content:encoded><![CDATA[<p>If you’re going to replace regex half-way with UML and expect people to use a graphical editor, why not just use real UML and generate regex from it? Anyone who finds your visualization more accessible than regex is already more familiar with UML than with regex, after all, and probably already has a preferred UML editor; anyone who uses a console-based editor (which is to say, a whole lot of serious developers) won’t be able to use this (and will be philosophically unwilling to anyhow).</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[How Bots Were Born From Spam]]></title>
            <link>https://howwegettonext.com/how-bots-were-born-from-spam-62f6c621351f?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/62f6c621351f</guid>
            <category><![CDATA[talking-with-bots]]></category>
            <category><![CDATA[artificial-intelligence]]></category>
            <category><![CDATA[messaging]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 06 May 2016 14:07:22 GMT</pubDate>
            <atom:updated>2016-05-09T06:30:54.403Z</atom:updated>
            <cc:license>https://creativecommons.org/licenses/by-sa/4.0/</cc:license>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*3Ws7Zi52yHaB6hgTX3DgvA.gif" /></figure><p>The first commercial spam message was sent in 1994—at least that’s the general consensus. <a href="https://web.archive.org/web/20071125201904/http://w2.eff.org/legal/cases/Canter_Siegel/c-and-s_summary.article">Lawrence Canter and Margaret Siegel</a> had a program written that would post a copy of an advertisement for their law firm’s green card lottery paperwork service to every Usenet news group — about 6,000 of them.</p><p>Because of the way the messages were posted, Usenet clients couldn’t filter out duplicate copies, and users saw a copy of the same message in every group. At the time, commercial use of internet resources was rare (it had only recently become legal) and access to Usenet was expensive. Users considered these commercial-seeming messages to be crass—not only did they take up their time, but they also cost them money.</p><p>In reaction to the “green card” incident, Arnt Gulbrandsen created the concept of a “cancelbot,” which compared the content of messages to a list of known “spam” messages and then, masquerading as the original sender, sent a special kind of message to “cancel” the original message, hiding and deleting it. Two months after the original spam postings, Canter and Siegel did it again — upon which the combined load of spam and cancel messages crashed many Usenet servers. Anti-spam measures, it seems, had themselves become spam.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/972/1*gfXZQq6ajsmyNGr1qnXhCQ.png" /><figcaption><strong>A Usenet client, showing message groupings. A message cross-posted to multiple groups would only appear once.</strong> Image credit: <a href="https://commons.wikimedia.org/wiki/File:FreeXP.png">Public domain</a></figcaption></figure><p>While this was the beginning of commercial Usenet spam, this was not the beginning of <a href="http://www.templetons.com/brad/spamterm.html">Usenet spam</a> in general. Prior to April of 1994, a poster known as <a href="http://www.nyupress.org/netwars/pages/chapter11/ch11_03.html">Sedar Argic</a> would automatically reply to any message containing the word “turkey” with a lengthy rant denying the Armenian genocide. This, of course, made discussions of Thanksgiving celebrations difficult.</p><p>The thing about all of these early forms of Usenet spam is that the messages were always identical. Cancelbots worked because the messages they were canceling were either identical or changed very infrequently — they could be compared to a human-maintained list of spam messages (a “corpus” of spam).</p><p>But even during this era there were Usenetters using a new technology that would upset this and future countermeasures: <a href="https://blog.codinghorror.com/markov-and-you/">Markov chains</a>, which are a popular tool among modern bot-makers. Invented in 1913 by Russian mathematician <a href="https://en.wikipedia.org/wiki/Andrey_Markov">Andrey Markov</a>, a Markov chain works by combing through text, looking at which words tend to follow each other, and assembling new sentences, paragraphs, and pages using the resulting statistics. Want to try it? <a href="http://www.schmipsum.com/">Here’s a website</a> that generates filler text from Shakespeare, Jane Austen, the Nixon Tapes, college essays, and even the Bible.</p><p>It didn’t take long for spammers to realize that cancelbots could be stumped by adding random junk to the end of messages. At the same time, spammers were moving beyond Usenet into email, just as regular people all over the United States and western Europe were suddenly learning what a modem was and signing up for web access.</p><p>By this time, people dedicated to identifying and fighting spam (a problem that had barely existed six months earlier) had already started creating “honeypot” email accounts. These were accounts that no human being would have any reason to send messages to, created for the purpose of accumulating <a href="http://untroubled.org/spam/">a large corpus of spam</a>, with the goal of researching spammer behavior and developing new spam-fighting techniques. With so many spammers carrying different messages, and random junk being newly added to the end of messages (or beginning, or middle), spam-filtering technology had to get smarter. Programmers began to look at <a href="https://web.archive.org/web/20130704143650/http://www.netpoetic.com/2010/06/computer-science-for-poets-n-gram-language-models/">word statistics</a> and Markov models to identify the spammers.</p><p>But spammers quickly figured out that they could use the same Markov chain technology against the filters: By creating Markov chains out of clearly non-spammy material (usually derived from <a href="https://www.gutenberg.org/">Project Gutenberg</a>, a collection of out-of-copyright e-books), spammers could add legitimate-sounding but nonsensical phrases to the end of their messages, making the job of the filters harder. That technique is called “<a href="https://en.wikipedia.org/wiki/Bayesian_poisoning">Bayesian poisoning</a>” and is the origin of <a href="http://www.spampoetry.org/">spam poetry</a>.</p><p>Unfortunately for spammers, Bayesian poisoning tends to make messages too unconvincing: Long strings of unrelated words don’t sell. But there’s another way to get around blacklists based on a corpus of text—a technique that became all too common when people started including comment sections on the nascent web. In the spam community, it’s called “<a href="http://alexking.org/blog/2013/12/22/spam-comment-generator-script">spinning</a>.” The rest of us know it as “generative grammar.” Spinning uses variations on phrases in an existing message to create large numbers of semantically identical but distinct messages. Like Markov chains, it’s popular within the bot-making community, and you can try it for yourself <a href="http://www.crystalcodepalace.com/traceryTut.html">here</a>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/924/1*yaHnapVUo4APEj9wmUz2fA.gif" /></figure><p>Shortly after email and web browsing became the norm, instant messaging followed. While chat services date back to the early 1970s, large-scale internet-based chat systems like <a href="https://en.wikipedia.org/wiki/Internet_Relay_Chat">IRC</a> appeared in the late 1980s. As people started growing up with internet access in their households, commercial services like AOL Instant Messenger boomed in popularity.</p><p>On IRC in the 1990s, a lot of what had happened on Usenet repeated itself. People wrote Markov chain bots for amusement; other people wrote bots to paste pre-written diatribes in response to particular keywords. Some spambots existed that posted advertisements automatically. But the IRC community, like Usenet, quickly developed technical countermeasures.</p><p>Commercial instant messaging services, on the other hand, skewed young and nontechnical. Whereas IRC and Usenet were used and run mostly by programmers, AOL was targeted toward families. When bots appeared on AOL Instant Messenger, AOL had no incentive to stop them; when bots began sending misleading messages to AOL users, the company didn’t have enough experience with spam to be cautious of where this might lead.</p><p>Meanwhile, some AOL bots like <a href="https://motherboard.vice.com/read/a-history-of-smarterchild">SmarterChild</a> and <a href="https://medium.com/cuepoint/radiohead-s-googlyminotaur-ee91cd600a4a">GooglyMinotaur</a> were officially sanctioned. Despite the commercial angle, these bots wouldn’t message people without provocation and, thus, arguably were not spambots. Still, their underlying technology was identical, and their attempts to act human represent not merely a precursor to similar systems like Siri, but also a less sinister version of what instant messaging bots at the time did to trick naive teenagers.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/455/1*z2xpqwRFo3DLPZGY98JYoQ.png" /><figcaption><strong>A conversation with SmarterChild.</strong> Image credit: <a href="https://commons.wikimedia.org/wiki/File%3APidgin-2.0.0b7-winxppro-conv.png">TheFirstM</a></figcaption></figure><p>If you’ve ever used Twitter, many of the spam techniques I’ve mentioned above will be familiar. You already know that users who post links only are unlikely to be human, particularly if they have a supermodel avatar. At some point, you’ve probably inadvertently mentioned some buzzword (iPad, Bitcoin, etc.) only to be swarmed by tangentially related ads.</p><p>Other applications of these spam techniques on Twitter, however, are more interesting. Some, like <a href="https://twitter.com/redscarebot">RedScareBot</a>, are subversive. Others, such as <a href="https://twitter.com/stealthmountain">StealthMountain</a>, are educational. Some use normally questionable time-wasting techniques for the greater good by redirecting abuse — such <a href="http://www.newstatesman.com/future-proof/2014/10/ultimate-weapon-against-gamergate-time-wasters-1960s-chat-bot-wastes-their-time">as an ELIZA implementation that engages people using Gamergate-related tags</a>, causing naive trolls to flame a bot rather than a human.</p><p>But there are many other modern use cases for these technologies, too. In the academic world, in response to a series of <a href="https://en.wikipedia.org/wiki/Sokal_affair">scandals</a> related to fraudulent conferences, <a href="http://pdos.csail.mit.edu/scigen/">a tool called SCIGen was developed</a> that used spinning to generate nonsense papers as a way of ensuring that journals and conferences were doing peer reviews. In 2014, <em>IEEE</em> and <em>Springer</em>, two major academic publishers, adopted the use of <a href="http://scigendetection.imag.fr/">a tool for automatically detecting nonsense papers</a> generated by SCIGen after it was revealed that <a href="http://www.nature.com/news/publishers-withdraw-more-than-120-gibberish-papers-1.14763">more than a hundred such papers had gotten around peer reviews</a>.</p><p>In 2010, Amazon opened its eBook store to self-publishing only to be <a href="http://www.reuters.com/article/us-amazon-kindle-spam-idUSTRE75F68620110616">flooded with e-books</a> made automatically by web scrapers. While <a href="http://www.theawl.com/2010/11/my-summer-on-the-content-farm">content farms for clickbait sites are mostly run by poorly paid humans</a>, The Associated Press is using spinning techniques to <a href="http://www.usatoday.com/story/money/business/2014/06/30/ap-automated-stories/11799077/">generate sports and finance articles</a>, and others are <a href="https://larseidnes.com/2015/10/13/auto-generating-clickbait-with-recurrent-neural-networks/">building bots that can write clickbait</a>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/720/1*z364KDE94DyaW_eL5GomsA.gif" /></figure><p>What this all leads to is unclear. Science fiction author Charlie Stross suggests, in his 2011 novel <em>Rule 34</em>, that the competition between spam and anti-spam technology might drive forward future AI research. In his novel, a superhuman AI evolves from an experimental spam-filtering technology and, as a side effect, has no internal sense of self: It projects its consciousness on some arbitrarily chosen user, because its intent is to determine what that user would consider spam.</p><p>Hugh Handcock, another science fiction author, <a href="http://www.antipope.org/charlie/blog-static/2016/04/rise-of-the-trollbot.html">suggests in a recent blog post</a> that the future of chatbots may have more in common with the spambots and mass-trolling of Anonymous and early-1990s IRC than with Siri. Chatbots, by design, might be more desirable to interact with than humans are — they could perpetuate rather than break down filter bubbles, becoming something to interact with without ever leaving one’s comfort zone. They might swarm around dissenting opinions. Handcock presents a world in which a human might know that all his friends are bots trying to sell him something—and simply not care.</p><p>Meanwhile, 1990s virtual reality pioneer Jaron Lanier, in his 2010 book <em>You Are Not a Gadget</em>, presents his concerns about current trends in publishing and media where the monetary value of artistic expression is tied to advertising. In his 2013 follow up, <em>Who Owns the Future</em>, he offers a possible end game for an advertising-driven society: one wherein physical spambots provide goods and services for free to people in their target market, while leaving everyone else to starve.</p><p>The second episode of the TV series <em>Black Mirror</em>, “Fifteen Million Merits,” dreams up a similar society—an economy based on the twin poles of entertainment and physical labor that extracts money from laborers and funnels it into the entertainment complex by using aggressive advertising that can only be accepted or dismissed using micro-transactions.</p><p>Lanier suggests that voluntary micro-transactions might be a way for artists to take back control of their work from the advertising industry and avoid an imminent fall of media from a middle-class to a lower-class position. The <em>Black Mirror</em> episode shows how as long as the entertainment industry is centralized, however, micro-transactions can be a tool for perpetuating class divides and systematically excluding people from participating in the creation and sale of art.</p><p>Personally, I suspect that with the new emphasis on conversational interfaces, we’ll begin to see hybrid spambots: Existing conversational interface systems like Siri and Echo, because they serve up data from third parties, might begin to be manipulated by some bot-equivalent of SEO to respond to certain queries with advertisements. In this environment, no automated methods exist for filtering out ads — and since conversational interfaces are often run by retailers, there is no incentive to do so. Rather than trying to outwit spam filters, the creators of these bots would need to be subtle enough to avoid alarming users.</p><p>As the landscape of the internet changes, and as countermeasures are put in place, one thing remains constant: So long as spambots can remain profitable, they won’t go away.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/300/1*X_wZMnqyLLsKNtNVJ1JvOA.gif" /></figure><p><em>This post is part of How We Get To Next’s </em><strong><em>Talking With Bots </em></strong><em>month in May 2016, looking at how chatbots will change our lives. If you liked this story, please click on the heart below to recommend it to your friends.</em></p><p><em>Read more from How We Get To Next on </em><a href="http://www.twitter.com/howwegettonext"><strong><em>Twitter</em></strong></a><em>, </em><a href="https://www.facebook.com/howwegettonext/"><strong><em>Facebook</em></strong></a><em>, or </em><a href="https://www.reddit.com/r/hwgtn/"><strong><em>Reddit</em></strong></a><em>, or sign up for our </em><a href="https://storythings.us7.list-manage.com/subscribe/post?u=ac3c63206e0226f0b2c43f01d&amp;amp;id=f18977f495"><strong><em>newsletter</em></strong></a><em>.</em></p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Bot capitalism will fail]]></title>
            <link>https://hackernoon.com/bot-capitalism-will-fail-6e7dede405fb?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/6e7dede405fb</guid>
            <category><![CDATA[bot]]></category>
            <category><![CDATA[bots]]></category>
            <category><![CDATA[chatbots]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 19 Apr 2016 19:52:28 GMT</pubDate>
            <atom:updated>2016-04-20T15:02:53.624Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p>Bot capitalism will fail</p><p>There’s been a lot of hype surrounding chat bots lately. I love bots, and usually I’m all for getting excited about the things I love, but I think the recent hype is very misguided. The reason is that the people contributing to the current hype bubble surrounding bots are not natural persons but corporate persons: they are excited about bots as products. Usually, when the spectre of money enters into a domain previously commercially nonviable, a lot of people get super excited about making money and miss the point <a href="https://en.wikipedia.org/wiki/Spectacle_(critical_theory)">spectacularly</a> (pun kind of intended), and this case is no different. However, it’s worth talking about this specific case nevertheless, because with bots, the commercial focus of yuppies and suits is fairly likely to ultimately convince everyone outside the core art-bot community that bots are something worse than useless: that they are supremely <em>uninteresting</em>.</p><p>The first thing I’m going to discuss is conversational interfaces. The reason is that the sudden increase in interest in bots is related to the fact that several companies have been shipping speech-based conversational interfaces, and a lot of current commercial bots are intended to be the equivalent of these speech-based interfaces run over existing text-based communications protocols.</p><p>I am largely unimpressed with conversational interfaces. They have a long history; many early and influential AI systems would be classified as conversational interfaces, and very simple conversational interfaces were a staple of books on learning to program for the BASIC set since the introduction of the first 8-bit home computers.</p><p>Ultimately, conversational interfaces fall into two categories: interfaces that try to keep up the illusion of intelligence and personality by ignoring most input and searching for particular keywords, and interfaces that are effectively special-purpose command lines with snarky or otherwise unprofessional error messages. The former type is epitomized by the search engine “Ask Jeeves”, which achieved its “flexibility” by implicitly inserting an OR operation between each term in the input (thus causing the term with the greatest TFIDF score to rise to the top of the results and become a de-facto keyword), although other examples include Alice and Eliza. The latter type is epitomized by the adventure game “Zork”, which had a somewhat english-like and very limited programming language it could understand and would mock you if you attempted to perform an invalid operation. Siri, Cortana, Echo/Alexa, and Google Now are all combinations of these two forms.</p><p>The thing about conversational interfaces of the former type is that they are inflexible and difficult to predict. A given input will produce some output, based on pattern-matching, but in order to prevent seeming as though the machine is not intelligent, the machine will be inclined to always respond with something — ideally, something somewhat randomized. A human being, without access to the source code, will eventually build up a folk-model of what patterns do or do not produce the desired result, but such a model has no guarantee of accuracy or completeness. A user may have some operation they desire that is built-in, but the complete list of available functions (though it is necessarily small, since each one has to be hand-written by a human being and given rules for invocation that don’t conflict with other functions) will never be distributed to prospective users because that would ruin the “magic” of a somewhat human-like interface. The ideal end-game for such an interface is for a user to memorize a handful of commonly used patterns in their most consise form and otherwise use it for its novelty value as a conversational partner — a world of people barking “MOVIE SHOWINGS BROOKLYN DEADPOOL” at their phones instead of typing the same query into google.</p><p>The thing about conversational interfaces of the latter type is that, by being english-like, the language understood by the interface will never be sufficiently minimal for a non-casual user, and by being ‘entertaining’, the error messages will never be sufficiently specific for a casual user to be able to trivially determine what he or she is doing wrong. The ideal end-game for such an interface is for a user to memorize a needlessly verbose and limited programming language and be able to type “FEED TROLL TO TROLL” with the expectation that doing so will cause the troll to eat himself and be defeated.</p><p>Taken to infinity, the ideal form of the first type is a search engine. Taken to infinity, the ideal form of the second type is a unix shell.</p><p>Commercial bots, to the extent that they are expected to reliably perform potentially dangerous operations like making purchases, editing calendar entries, and controlling home automation systems, are going to remain quite close to the second form. This is a shame, because there is absolutely nothing revolutionary about a shitty command line, and it doesn’t do justice to bots in general to imply that all of them are like that.</p><p>Consider the non-commercial bot: the art-bot. The art bot is varied in its form. The art bot, because it is a bot, is able to tirelessly perform intellectual tasks. The art bot, because it is art, focuses on tasks relating to recontextualizing ideas, words, images, and perceptions. The art bot is a meaning factory, producing brand new thoughts out of the interference pattern between a PRNG and an audience.</p><p>The art bot doesn’t buy anything, or if it does, <a href="http://randomshopper.tumblr.com/post/35454415921/randomized-consumerism">the fact that you can’t reliably tell it what to buy is part of the point</a>.</p><p>The art bot can write <a href="https://twitter.com/GraphicScoreBot">music</a>, or <a href="https://twitter.com/pentametron">poetry</a>, or <a href="http://twitter.com/unchartedatlas">paint pretty pictures</a>. If you don’t like the art that the art bot produces, too bad. The art bot doesn’t care. The art bot will produce a thousand other pieces while you are deciding whether or not you like that one.</p><p><a href="https://twitter.com/artassignbot">Some art bots tell you to do things</a>. Do you want to take commands from a robot? Maybe. <a href="https://twitter.com/artassignbot/status/721850750645706752">Sometimes the things it tells you to do can’t be done</a>.</p><p>Some art bots are funny. <a href="https://twitter.com/TwoHeadlines">Some are even intentionally funny</a>. Any <a href="https://twitter.com/makeusabotagain">image macro</a>, <a href="https://twitter.com/EveryMarxistTea">snow clone</a>, or <a href="https://twitter.com/HypernymBot">formula joke</a> is the potential domain of an art bot, who will <a href="http://twitter.com/botston">scour a dictionary to produce millions of variations</a>.</p><p>An art bot is not a shitty command line. Or, if it is, it’s intentionally shitty. An art bot might mock you for everything you tell it to do. Or, <a href="http://anxietybox.com">it might systematically break down your hopes and dreams</a>. Or <a href="https://twitter.com/lift_bot">support them</a>.</p><p>Freed from the shackles of needing to please a core user base and be immediately useful without ever screwing up, art bots are allowed to be interesting.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[It’s kind of funny that your way of dealing with branching narratives of this type is to play…]]></title>
            <link>https://medium.com/@enkiv2/it-s-kind-of-funny-that-your-way-of-dealing-with-branching-narratives-of-this-type-is-to-play-959b5f2f9c49?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/959b5f2f9c49</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 11 Apr 2016 16:08:23 GMT</pubDate>
            <atom:updated>2016-04-11T16:08:23.031Z</atom:updated>
            <content:encoded><![CDATA[<p>It’s kind of funny that your way of dealing with branching narratives of this type is to play through only once and treat your path as canon, since the norm (at least in VNs, which are generally shorter and contain fewer mechanical challenges) is to get 100% completion (to the extent that, in many games, the ending the creators consider ‘canon’ doesn’t even become unlocked until all the ‘normal’ paths are visited — see Everlasting Summer, for example, whose core plot is only vaguely hinted at until you slog through all the formulaic dating sim BS, or Sharin, which does something similar by unlocking whole new dimensions of meaning in throwaway lines from previous play-throughs in what is essentially an easter-egg route that nevertheless is necessary to play through in order to get completion).</p><p>I wonder if triple-A games, because of play time and budget and aspirations towards ‘cinematic experience’, don’t play this way — but games focusing on branching narratives as their primary or sole mechanic are often built with the assumption that players will engage with multiple routes, and reflect this thematically (with plotlines involving time loops, time travel, alternate universes, and so on — everything from Steins;Gate to Higurashi does this). This is a very different way to engage with a game. It’s not precisely leaning on the fourth wall, but instead, taking greater advantage of an already existing mechanic for thematic reasons, telling a story that is much more difficult to tell in non-branching media. (There are attempts to tell this kind of story in film. Run, Lola, Run, for instance, or Tatami Galaxy. They feel more like formal experiments than direct experience because the choices aren’t directed by the audience, and this detracts from their effect; less competent attempts are even less memorable because of this.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I’d like to point out that Project Xanadu (which, btw, is still going on) is, at its core, an…]]></title>
            <link>https://medium.com/@enkiv2/id-like-to-point-out-that-project-xanadu-which-btw-is-still-going-on-is-at-its-core-an-f2f37d77b17b?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/f2f37d77b17b</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 25 Apr 2016 19:05:13 GMT</pubDate>
            <atom:updated>2016-04-25T19:05:14.317Z</atom:updated>
            <content:encoded><![CDATA[<p>I’d like to point out that Project Xanadu (which, btw, is still going on) is, at its core, an attempt to solve this attribution problem permanently (at least for all good-faith actors) by focusing on quotation as a primary factor in composition (seeing editing as a form of selective quotation and rearrangement from previous drafts, for instance). Every so often I see articles like this (or articles on similar topics like music credits) that point out how necessary this tech still is — this clearly-skilled guy would still have his job if, by default, copy and paste between applications implicitly kept source attributions.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Bots are only interesting when they aren’t expected to be consistently useful or make money.]]></title>
            <link>https://medium.com/@enkiv2/bots-are-only-interesting-when-they-aren-t-expected-to-be-consistently-useful-or-make-money-b012f6bfa016?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/b012f6bfa016</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 25 Apr 2016 14:11:28 GMT</pubDate>
            <atom:updated>2016-04-25T14:11:28.941Z</atom:updated>
            <content:encoded><![CDATA[<p>Bots are only interesting when they aren’t expected to be consistently useful or make money. The constraint of productivity saps away the only interesting thing about interacting with bots: serendipity.</p><p>The current boom in interest in commercial bots is just another example of the Spectacle trying to look hip by consuming something that can’t be effectively productized.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Alternatives to advertising]]></title>
            <link>https://hackernoon.com/alternatives-to-advertising-7af0e32b8a8e?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/7af0e32b8a8e</guid>
            <category><![CDATA[media]]></category>
            <category><![CDATA[journalism]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 18 Sep 2015 14:19:17 GMT</pubDate>
            <atom:updated>2016-04-20T15:09:43.176Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p>Thinkpieces about the ethics of ad blocking are all over the news recently, because apparently things only become newsworthy when Apple stops banning them. The time to discuss ad-blocking is not now, really — after all, the largest tech companies make all their money from advertising now. <a href="http://mashable.com/2013/08/09/first-banner-ad/#Zcx1a3NovkkK">The time to discuss ad-blocking was 1994, when the first banner ad was introduced</a>.</p><p>That said, there are new (or at least new-ish) things to say about alternatives to ad-based monetization on the web, in part because during the past few years alternatives have been successfully implemented, and in part because intelligent people like Jaron Lanier have been writing at length about possible alternatives recently.</p><p>If you’re reading this, you — like most people — have probably heard the idea that advertising is justified as the sole alternative to paywalls and merchandise sales, and swallowed it completely. You probably didn’t quite realize that Kickstarter and Patreon were genuine alternatives to an ad-based revenue model. Allow this post to be an introduction to the variety of ways in which you can distribute media for free and still get paid.</p><h4>Why advertising is a bad model</h4><p>Some reasons why advertising on the web is bad are probably familiar to you: targeted advertising implies tracking, which eats up bandwidth and is a potential violation of privacy; advertisements are typically both irritating and irrelevant. Other reasons will be familiar to people who have hosted ads: click-through rates are incredibly low and ads have become devalued over the past ten years such that providers like Google pay fractions of a cent per click and nothing per exposure, meaning that only extremely popular sites can make more than pocket change through ads; even ads hosted through big providers like Google can be full of malware. The big one is the one you haven’t heard of, though: <a href="http://www.theatlantic.com/business/archive/2014/06/a-dangerous-question-does-internet-advertising-work-at-all/372704/">ads don’t work</a>. Depending upon advertising as the basis of the internet’s economy is like tying the value of paper money to tulip bulbs during the height of the Dutch tulip bubble; sooner or later the entire system will become devalued.</p><h4>A selection of alternatives</h4><p>This is, obviously, not a complete list. I’m going to address the most obvious and frequently-cited ones first.</p><ul><li>Subscriptions: rather than releasing your content for free, you charge for access. This monetization policy is very vulnerable to piracy — if there’s an alternative source, there’s no incentive to pay. It has low discoverability — if people can’t see your content without subscribing, they have no incentive to subscribe. It’s also not particularly sustainable unless you have a lot of high-quality content being released steadily — if the quality is too low, you lose subscribers; if the content isn’t released steadily enough or isn’t voluminous enough, subscribers feel cheated.</li><li>Paywalls: an attempt to solve the discoverability problem with subscriptions by releasing a certain amount for free. Paywalls are often easily circumvented in such a way that a subscription is never necessary. Furthermore, while discoverability is improved, the average quality of content must be high if the content released for free is to convince people to pay. Finally, and most damning: paywalls don’t even attempt to solve any of the problems of subscriptions other than discoverability.</li><li>Freemium: while most content is free, a subscription system exists that provides users with either extra content or extra functionality. Freemium systems walk a delicate balance: if the free version is too functional, nobody subscribes; if the free version is too incomplete, it’s considered crippleware (and somebody else with lower costs will undercut you).</li><li>Donations: fans pay on a fully voluntary basis while content is released for free. This is very sensitive to the size of a fan-base and to how much that fan-base feels like the creator is ‘in need’ — a popular franchise with a creator perceived to be wealthy will not get donations.</li><li>Merchandise: items are sold at a high markup with images tied into the media in question. This is essentially hiding a donation inside a purchase. Because of this, it’s easy for people to undercut your prices with merchandise similar to your own and take advantage of any fans who don’t realize that their purchase is a donation. Furthermore, the primary benefit over straight donation is that fans can advertise their association with the media in question — which requires a cohesive fan-base and a cohesive set of evocative symbols to make it profitable. A popular franchise without a fanbase that sees itself as set apart from the rest of the culture cannot reasonably benefit from merchandise, nor can a popular franchise with insufficiently iconic symbols.</li><li>Crowdfunding: fans donate money to pay for the creation of media not yet created, often with merchandise thrown in to encourage larger donations. Crowdfunding is sometimes extremely effective; however, franchises with large and cohesive existing fan-bases benefit more from it than others. Discoverability is low. Repeatability is low, since repeated fundraising runs will tire fans, meaning that this is ideal for one-off new additions to existing franchises. Generally, if merchandise works for you and you need to raise money from your existing fans for something big and expensive and non-repeating like a movie or a tour, crowdfunding will be ideal.</li><li><a href="https://www.schneier.com/paper-street-performer.html">The Street-performer protocol</a>: you create something and then use a crowdfunding-style fundraising round to finance it before releasing it. On the surface this looks strictly worse than crowdfunding; however, because the thing is already created, you can avoid the common crowdfunding pitfall wherein time estimates for completion are under-estimated and the product that was funded was never created. Furthermore, quite explicitly, in the street performer protocol, the resulting media is released free to everyone as soon as it is paid for; as a result, it’s highly piracy-resistant: nobody has a copy before it’s paid for except the creator, and afterwards everybody does. During the first iteration, discoverability can be a problem; however, discoverability becomes less of a problem the more iterations you go through. Because this was Bruce Schneier’s idea, there’s some mathematical formalism and technical detail to how trust is established between various parties, which I won’t discuss here.</li><li>Patreon-style funding: something akin to a marriage between the street-performer protocol and a subscription system. In patreon’s model, fans subscribe to a creator such that they pay a certain amount automatically upon the public/free release of a piece of media. Unlike the street performer protocol, the media isn’t created before people agree to fund it. Patreon provides a mechanism for incentivizing higher donations by allowing various donation tiers access to specific content not accessible to other tiers, but such content tends to be rough drafts and notes — in other words, content mostly interesting to hard-core fans who might donate anyhow, thus circumventing problems with a ‘freemium’ model.</li><li>Decision bidding: fans can pay for the ability to influence the end product. Occasionally this is integrated with another model — I’ve seen limited decision bidding as an element in patreon and kickstarter campaigns. However, by treating certain classes of decisions (like what to blog about) as auctions, you gain the possibility of bidding wars. This probably will only work if you have a very dedicated fanbase.</li><li>Decision futures: fans wager on decisions and in the process make those decisions. You can treat this as a variation of decision bidding, or an extension of the kind of decision-voting that blogs sometimes have (polls about which topic should be covered next, for instance). Fans pay some small amount to vote, and those who didn’t win get a refund. You can increase fairness and revenues by allowing multiple votes up to some limit.</li><li>Pay-for-privacy: in a service that remotely hosts user content, public hosting is free while private hosting costs money. Github uses this model.</li><li>Pay-to-remix: release media for free, but expect people who reuse or recontextualize it to send you some money. This is proposed in some versions of transcopyright, and implemented in some demo-scale systems like token-coin; it is also an implicit part of music industry licensing, in which artists pay a flat fee to release a cover song on a record, and in which writers and composers are paid royalties on their work regardless of who performs it.</li></ul>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Scene/Sequel: Post-Mortem of a Fiction Generator]]></title>
            <link>https://hackernoon.com/scene-sequel-post-mortem-of-a-fiction-generator-583ad51f3c1b?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/583ad51f3c1b</guid>
            <category><![CDATA[fiction]]></category>
            <category><![CDATA[generative]]></category>
            <category><![CDATA[generative-art]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 17 Dec 2015 22:38:55 GMT</pubDate>
            <atom:updated>2016-04-20T15:09:21.651Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p><strong>Abstract</strong><br>Fiction generators based on goal-directed planning in a simple state machine can produce reasonably human-like output without explicit modeling of multiple characters by treating the planner as the narrator and protagonist.</p><p><strong>Background</strong><br>Fiction generation using world models is not new. The same kind of planning used in <a href="http://hci.stanford.edu/~winograd/shrdlu/">SHRDLU (Winograd, 1972)</a> drove early planner-based fiction generators like <a href="http://eliterature.org/2006/01/meehan-and-sacks-micro-talespin/">TALE-SPIN (Meehan, 1976)</a>. This class of fiction generators is a middle ground between ‘simulationist’ models, wherein a large number of variables are modeled carefully and a story is extracted from the progression between states by dropping most of the information modelled, and ‘texture’ models, wherein large pieces of preexisting flavor text are pieced together. (An example of the former would be the history of the world produced by <a href="http://dwarffortresswiki.org/index.php/DF2014:Legends">Dwarf Fortress</a>, and an example of the latter would be <a href="http://articles.latimes.com/2000/may/28/news/mn-35062">BRUTUS (Bringsjord, 2000)</a>.) TALE-SPIN-like planner-based fiction generators have, historically, like TALE-SPIN, modeled a set of characters and modeled their interactions. The most interesting stories generated by these generators remain the “mis-spun tales”, wherein assumptions by the generator are flawed in a way that produces absurd violations of common sense; the remainder of tales are fairly mundane transcripts of interactions between characters. As demonstrations of a functional model, these transcripts are serviceable; as stories, they lack interesting forms of structured conflict.</p><p>Author Jim Butcher presents a model of plot construction I call the ‘<a href="http://jimbutcher.livejournal.com/2647.html">scene</a>-<a href="http://jimbutcher.livejournal.com/2880.html">sequel</a> model’ that diverges from the idea of the world as a perfect simulation and focuses on the kinds of stories readers find interesting. While Butcher’s interest is in human-written stories, his ideas <a href="https://github.com/dariusk/NaNoGenMo-2015/issues/155">lend themselves</a> to generative fiction more so than other seemingly more mechanical models of plot construction like <a href="https://archive.org/stream/plottonewmethodo00cook#page/n3/mode/2up">Plotto</a> and the <a href="http://www.savethecat.com/tools/the-blake-snyder-beat-sheet-the-bs2">BS2</a>. Quickly: within the scene-sequel model, a story has a single protagonist and consists of scenes (wherein the protagonist attempts to achieve his or her goal) and sequels (wherein the protagonist reacts to the content of the scene emotionally and performs his or her planning); scenes have scene-specific goals that are either achieved or not achieved and each scene may introduce complications that change the protagonist’s state.</p><p>Current work<br>For <a href="https://github.com/dariusk/NaNoGenMo-2015">NaNoGenMo 2015</a>, I present a <a href="https://github.com/enkiv2/scene-sequel">fiction generator</a> based on a simplified scene-sequel model for caper novels. In this model, there is only one character modeled: the protagonist, who is also the narrator. The content of the story is generated by the planner with the help of flavor text.</p><p>The story is generated by the planner from a ‘world model’, which is a state machine with associated flavor text. The world model consists of a list of state objects; each state object has a list of other states it can transition to (along with a probability for this transition to occur and optional flavor text for describing attempted, successful, and failed transitions). It furthermore contains a set of potential complications, which themselves are state names paired with probabilities.</p><p>The planner is provided with a world model, a weight for state transition success rate, a weight for complication accretion rate, a starting state, and a goal state. The planner keeps a ‘goal pool’ consisting of a set of state names and weights, and this goal pool is initially set to the goal state. Typically, the goal state is the overarching goal of the protagonist. As complications are accrued, they are added to the goal pool.</p><p>At each step, we perform a sequel followed by a scene.</p><p>The sequel consists of information produced by the planner, which (starting from the current state) performs a walk of the state space, depth-first, searching for the goal state. Because the world object contains cycles, the tree-walking portion of the planner is provided with a recursion depth limit. The planner, multiplying and adding probabilities, determines the immediate next state with the greatest composite likelihood of reaching each state in the goal pool — in other words, the likelihood of reaching each goal is determined, adjusted by its goal weight, and then a composite is produced for ranking purposes. During this tree-walking and goal-weighing process, at an adjustable rate, information about the planning process and the decisions being made is emitted in the style of first-person narration of planning in a caper novel:</p><blockquote>So, I thought, what if I tried to steal them jewels by trying to get a museum uniform… So, I thought, what if I tried to steal them jewels by trying to pass as a museum employee… So, I thought, what if I tried to steal them jewels by trying to go to the hospital… I’ll try to remember that.</blockquote><blockquote>So, I figured, if I tried to steal them jewels by trying to pass as a museum employee I’d have maybe a 35% chance of succeding. I’ll try to remember that.</blockquote><blockquote>If I’m trying to get a museum uniform, what if In order to steal them jewels, I tried to pass as a museum employee. That has about a 1 in 10 chance of working. So, I figured, if I tried to steal them jewels by trying to get a museum uniform I’d have maybe a 10% chance of succeding. I’ll try to remember that.</blockquote><blockquote>So, since I’m trying to go about it the obvious way I decided to steal them jewels by trying to get a museum uniform. So, I have to get a museum uniform. I also have to steal them jewels. Right now, I’m trying to go about it the obvious way.</blockquote><p>Once the planner has produced a candidate state, it uses the likelihood of success for the specific state transition and the global state transition weight to determine whether or not it succeeds, producing the appropriate flavor text (or a default if undefined), and then produces the set of complications to add. If the state transition is successful and the new state is the end goal state, the program stops here; if the state transition is successful and the new state is in the goal pool, that entry is removed from the goal pool.</p><p>Here is an example of the full output, using a world model about jewel theft:</p><blockquote>This is the story of that time I decided to try and steal them jewels.</blockquote><blockquote>So, I thought, what if I tried to steal them jewels by trying to get a museum uniform… So, I thought, what if I tried to steal them jewels by trying to pass as a museum employee… So, I thought, what if I tried to steal them jewels by trying to go to the hospital… I’ll try to remember that.</blockquote><blockquote>So, I figured, if I tried to steal them jewels by trying to pass as a museum employee I’d have maybe a 35% chance of succeding. I’ll try to remember that.</blockquote><blockquote>If I’m trying to get a museum uniform, what if In order to steal them jewels, I tried to pass as a museum employee. That has about a 1 in 10 chance of working. So, I figured, if I tried to steal them jewels by trying to get a museum uniform I’d have maybe a 10% chance of succeding. I’ll try to remember that.</blockquote><blockquote>So, since I’m trying to go about it the obvious way I decided to steal them jewels by trying to get a museum uniform. So, I have to get a museum uniform. I also have to steal them jewels. Right now, I’m trying to go about it the obvious way.</blockquote><blockquote>I failed to get a museum uniform while trying to go about it the obvious way. Bummer. Now I have to get a smaller gun. I still need to steal them jewels.</blockquote><blockquote>So, I thought, what if I tried to get a smaller gun by trying to get a museum uniform… So, I thought, what if I tried to get a smaller gun by trying to pass as a museum employee… So, I thought, what if I tried to get a smaller gun by trying to go to the hospital… So, I thought, what if I tried to get a smaller gun by trying to steal them jewels… I’ll try to remember that.</blockquote><blockquote>So, I thought, what if I tried to steal them jewels by trying to get a museum uniform… I already figured that if I tried to steal them jewels by trying to get a museum uniform I’d only have about a 1 in 10 chance of succeeding.</blockquote><blockquote>So, since I’m trying to go about it the obvious way I decided to steal them jewels by trying to get a museum uniform. So, I have to get a museum uniform. I also have to get a smaller gun. I also have to steal them jewels. Right now, I’m trying to go about it the obvious way.</blockquote><blockquote>I failed to get a museum uniform while trying to go about it the obvious way. Bummer. I still need to get a smaller gun. I also still need to steal them jewels.</blockquote><blockquote>So, I thought, what if I tried to get a smaller gun by trying to get a museum uniform… So, I thought, what if I tried to steal them jewels by trying to get a museum uniform… I already figured that if I tried to steal them jewels by trying to get a museum uniform I’d only have about a 1 in 10 chance of succeeding.</blockquote><blockquote>So, since I’m trying to go about it the obvious way I decided to steal them jewels by trying to get a museum uniform. So, I have to get a museum uniform. I also have to get a smaller gun. I also have to steal them jewels. Right now, I’m trying to go about it the obvious way.</blockquote><blockquote>I failed to get a museum uniform while trying to go about it the obvious way. Bummer. I still need to get a smaller gun. I also still need to steal them jewels.</blockquote><blockquote>So, I thought, what if I tried to get a smaller gun by trying to get a museum uniform… So, I thought, what if I tried to steal them jewels by trying to get a museum uniform… I already figured that if I tried to steal them jewels by trying to get a museum uniform I’d only have about a 1 in 10 chance of succeeding.</blockquote><blockquote>So, since I’m trying to go about it the obvious way I decided to steal them jewels by trying to get a museum uniform. So, I have to get a museum uniform. I also have to get a smaller gun. I also have to steal them jewels. Right now, I’m trying to go about it the obvious way.</blockquote><blockquote>I totally succeeded in my attempt to get a museum uniform by trying to go about it the obvious way. Yay! Now I have to get a smaller gun, again. I still need to steal them jewels.</blockquote><blockquote>So, I thought, what if I tried to get a smaller gun by trying to pass as a museum employee… So, I thought, what if I tried to steal them jewels by trying to pass as a museum employee… I already figured that if I tried to steal them jewels by trying to pass as a museum employee I’d only have about a 3 in 10 chance of succeeding.</blockquote><blockquote>So, since I’m trying to get a museum uniform I decided to steal them jewels by trying to pass as a museum employee. So, I have to pass as a museum employee. I also have to get a smaller gun. I also have to steal them jewels. Right now, I’m trying to get a museum uniform.</blockquote><blockquote>I failed to pass as a museum employee while trying to get a museum uniform. Bummer. I still need to get a smaller gun. I also still need to steal them jewels.</blockquote><blockquote>So, I thought, what if I tried to get a smaller gun by trying to pass as a museum employee… So, I thought, what if I tried to steal them jewels by trying to pass as a museum employee… I already figured that if I tried to steal them jewels by trying to pass as a museum employee I’d only have about a 3 in 10 chance of succeeding.</blockquote><blockquote>So, since I’m trying to get a museum uniform I decided to steal them jewels by trying to pass as a museum employee. So, I have to pass as a museum employee. I also have to get a smaller gun. I also have to steal them jewels. Right now, I’m trying to get a museum uniform.</blockquote><blockquote>I failed to pass as a museum employee while trying to get a museum uniform. Bummer. I still need to get a smaller gun. I also still need to steal them jewels.</blockquote><blockquote>So, I thought, what if I tried to get a smaller gun by trying to get a museum uniform… So, I thought, what if I tried to steal them jewels by trying to get a museum uniform… I already figured that if I tried to steal them jewels by trying to get a museum uniform I’d only have about a 1 in 10 chance of succeeding.</blockquote><blockquote>So, since I’m trying to go about it the obvious way I decided to steal them jewels by trying to get a museum uniform. So, I have to get a museum uniform. I also have to get a smaller gun. I also have to steal them jewels. Right now, I’m trying to go about it the obvious way.</blockquote><blockquote>I totally succeeded in my attempt to get a museum uniform by trying to go about it the obvious way. Yay! Now I have to get a smaller gun, again. I still need to steal them jewels.</blockquote><blockquote>So, I thought, what if I tried to get a smaller gun by trying to pass as a museum employee… So, I thought, what if I tried to steal them jewels by trying to pass as a museum employee… I already figured that if I tried to steal them jewels by trying to pass as a museum employee I’d only have about a 3 in 10 chance of succeeding.</blockquote><blockquote>So, since I’m trying to get a museum uniform I decided to steal them jewels by trying to pass as a museum employee. So, I have to pass as a museum employee. I also have to get a smaller gun. I also have to steal them jewels. Right now, I’m trying to get a museum uniform.</blockquote><blockquote>I totally succeeded in my attempt to pass as a museum employee by trying to get a museum uniform. Yay! Now I have to escape the museum. I still need to get a smaller gun. I also still need to steal them jewels.</blockquote><blockquote>So, I thought, what if I tried to get a smaller gun by trying to go to the hospital… So, I thought, what if I tried to escape the museum by trying to go to the hospital… So, I thought, what if I tried to steal them jewels by trying to go to the hospital… So, I thought, what if I tried to get a smaller gun by trying to steal them jewels… So, I thought, what if I tried to escape the museum by trying to steal them jewels… So, I thought, what if I tried to steal them jewels by trying to steal them jewels… It turns out there’s no way to steal them jewels by trying to go to the hospital after you already tried to pass as a museum employee.</blockquote><blockquote>So, since I’m trying to pass as a museum employee I decided to steal them jewels by trying to steal them jewels. So, I have to steal them jewels. I also have to get a smaller gun. I also have to escape the museum. Right now, I’m trying to pass as a museum employee.</blockquote><blockquote>I totally succeeded in my attempt to steal them jewels by trying to pass as a museum employee. Yay! Now I no longer need to steal them jewels. Now I have to heal my arm wound. Now I have to heal my chest wound, too. I still need to get a smaller gun. I also still need to escape the museum.</blockquote><blockquote>THE END</blockquote><p>Here is the world model that produced that story:</p><blockquote>world={}<br>world[“go about it the obvious way”]={“get a museum uniform”:{“probability”:0.5, “complications”:{“get a smaller gun”: { “probability”:0.9 }}}, “go to the ninja supply store”:{“probability”:1}, “go to the gun store”:{“probability”:1}}<br>world[“go to gun store”]={“get a smaller gun”:{“probability”:0.7, “complications”:{“find my stolen wallet”:{ “probability”:0.2}, “success_descr”:[“The gun store carried an antique gun intended for defending women on bicycles against dogs in the late nineteenth century. “, “The gun store carried a half-scale airsoft dart gun version of a Walther PPK, and poison darts. “]}, “descr”:[“The gun store was a tiny brick building by the side of the highway, in the bad part of town. “], “success_descr”:[“The owner glared at me, and then at my ID, and then back at me. Then he grunted, accepted my cash, and handed me the new gun. “], “failure_descr”:[“After banging on the locked door for ten minutes, I noticed a tiny sign at the lower left hand corner of the window embedded in the door. It had hours. It turns out, this store is closed on Tuesdays. “]}, “goal_reqs”:{“or”:[“get a smaller gun”]}}<br>world[“get a smaller gun”]={“go to gun store”:{“probability”:1}, “go about it the obvious way”:{“probability”:1}, “pass as a museum employee”:{“probability”:0.3}}<br>world[“get a museum uniform”]={“pass as a museum employee”:{“probability”:0.3, “complications”:{“heal my leg wound”:{ “probability”:0.2}, “escape the museum”:{ “probability”: 0.7} } }, “descr”:[“The costume shop was tucked into a strip mall down town, between a laundromat and a chinese take-out place. It smelled like soap. “], “success_descr”:[“There was a perfect museum employee uniform sitting on the rack to the left of the entrance. “], “failure_descr”:[“After looking through the racks several times, I finally decided to ask the cashier — a wrinkled but plump old woman with a puff of curly white hair — if she carried museum employee uniforms. She shook her head, and I left, dejected. “]}<br>world[“pass as a museum employee”]={“steal them jewels”:{“probability”:0.7, “complications”:{“heal my leg wound”:{ “probability”:0.3}, “heal my arm wound”:{ “probability”:0.3}, “heal my chest wound”:{ “probability”:0.3}}}, “go to the hospital”:{“probability”:0.9}, “reqs”:{“or”:[“get a museum uniform”]}}<br>world[“go to the ninja supply store”]={“get a smaller gun”:{“probability”:0.4, “success_descr”:[“In the glass display case, there was a poison dart gun that looked like a fountain pen. I bought six! “], “failure_descr”:[“The cashier claimed that they had a moral aversion to projectile weapons, and thus did not carry them. “]}, “purchase a black leather catsuit”:{“probability”:0.7, “success_descr”:[“A beautiful black leather catsuit greeted me from the rack to the left of the doorway. “], “failure_descr”:[“All the black leather catsuits they had in stock were sized for literal cats. “, “All the black leather cat suits they had in stock were way too big for me. “, “All their black leather catsuits were covered in shiny chrome studs and buckles, and wouldn’t help me disappear into the night at all. “]}, “purchase a grappling hook”:{“probability”:0.7, “success_descr”:[“There was a grappling hook with two hundred feet of rope sitting right behind the counter, on display. “, “I spent twenty minutes looking through the discount bin, before finding an absolutely perfect grappling hook for thirty cents. When I went up to pay for it, the cashier waved me off — no charge. “],”failure_descr”:[“\”Are there any grappling hooks in stock?\” The cashier, impassive behind his mask, shook his head slowly in response to my question. Then, after a moment of staring at me, he threw a smoke bomb at his feet. I found myself outside the shop, which was now locked. “]}, “descr”:[“The ninja supply shop was in the middle of the second floor of the mall, between a Hot Topic and a Zappo’s. It was dimly lit, and the scuffed floors had a fake tatami-pattern print. There was a wad of gum stuck to the doorway. “], “failure_descr”:[“The shutter was shut, and a great big lock hung from the side of it. “, “The door was shut and locked, and a sign said \”Back at 2:00\”. It was four. I waited until six. “],”success_descr”:[“As I entered, a machine emitted a little beep to indicate that customers were about. The cashier appeared out of a plume of smoke behind the counter. “]}<br>world[“purchase a black leather catsuit”]={“sneak into the museum at night”:{“probability”:0.8}, “go to the ninja supply store”:{“probability”:1}}<br>world[“purchase a grappling hook”]={“sneak into the museum at night”:{“probability”:0.9}, “go to the ninja supply store”:{“probability”:1}}<br>world[“sneak into the museum at night”]={“steal them jewels”:{“probability”:0.8, “complications”:{“heal my leg wound”:{“probability”:0.3},”heal my arm wound”:{ “probability”:0.3}, “heal my chest wound”:{ “probability”:0.3}}}, “go to the hospital”:{“probability”:0.9}, “reqs”:{“or”:[“purchase a black leather catsuit”, “purchase a grappling hook”]}}<br>world[“go to the hospital”]={“heal my leg wound”:{“probability”:0.9}, “heal my arm wound”:{“probability”:0.9}, “heal my chest wound”:{“probability”:0.7}, “escape the museum”:{“probability”:0.7},”goal_reqs”:{“or”:[“heal my leg wound”, “heal my arm wound”, “heal my chest wound”]}}<br>world[“heal my leg wound”]={“go to the hospital”:{“probability”:1}, “get a museum uniform”:{“probability”:1}, “get a smaller gun”:{“probability”:1}, “go to the ninja supply store”:{“probability”:1}}<br>world[“heal my arm wound”]={“go to the hospital”:{“probability”:1}, “get a museum uniform”:{“probability”:1}, “get a smaller gun”:{“probability”:1}, “go to the ninja supply store”:{“probability”:1}}<br>world[“heal my chest wound”]={“go to the hospital”:{“probability”:1}, “get a museum uniform”:{“probability”:1}, “get a smaller gun”:{“probability”:1}, “go to the ninja supply store”:{“probability”:1}}<br>world[“steal them jewels”]={“steal them jewels”:{“probability”:1, “complications”:{}}}<br>endGoal=”steal them jewels”</blockquote>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Paranoia as a design choice]]></title>
            <link>https://hackernoon.com/paranoia-as-a-design-choice-d978038cf3d4?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/d978038cf3d4</guid>
            <category><![CDATA[blockchain]]></category>
            <category><![CDATA[bitcoin]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 19 Jan 2016 17:19:30 GMT</pubDate>
            <atom:updated>2016-04-20T15:08:58.240Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p>A lot of people have been making a lot of noise about <a href="https://medium.com/@octskyward/the-resolution-of-the-bitcoin-experiment-dabb30201f7#.hwxfvg72z">this post about bitcoin</a>. Even before that, people were making noise about the bitcoin community being full of goldbugs. The thing is, bitcoin is a cryptocurrency whose primary design goal is paranoia, and all other factors are secondary. Nothing about the bitcoin design or the bitcoin community will make sense if you don’t recognize the intentional placement of paranoia in its design.</p><p>Bitcoin isn’t the only technological system built explicitly around paranoia. In the crypto and computer security communities, building systems around paranoia is normal, in the same way that it’s normal in a late-capitalist environment to build systems around profit maximization. SSH is designed around paranoia (and this is why you no longer can enable ‘cipher=none’ in SSH at compile time); the WWII-era ‘double-cross’ espionage structure that underlies cold-war spy thrillers is a social technology built around paranoia; the hospital policy surrounding disposal of drugs is based around paranoia.</p><p>Systems that are intended to be secure but are not designed around paranoia tend to become security theatre if they function at all — consider the HTTPS certificate system, the TSA, gun lock technology (and indeed much of regular lock technology), community policing, credit card and check based payment mechanisms, website password protection prior to widespread access to two-factor authentication, and highway toll stations. Security theatre is not entirely ineffective — after all, most people follow the rules most of the time and security theatre hints at the idea that the rules are important enough to be enforced — but it typically combines most of the inefficiencies of a truly secure system with most of the insecurities of a truly effective system.</p><p>When we’re talking about bitcoin, we’re talking about a conception of money wherein the government is the enemy. We’re also talking about a conception of money wherein banks and corporations are the enemy. We’re talking about a system where the assumption is that hours of clear time is a small price to pay for proof that double-spending is nearly impossible, and wherein the ideal community of users is a global network of wealthy individuals who never communicate except by exchanging money for goods or services and who have no friends or loyalties. Bitcoin is a currency designed for people who think of other people as potential enemies first.</p><p>There are circumstances where that view of the world is accurate.</p><p>This doesn’t really explain why large banks are investing in bitcoin, or why bitcoin startup companies exist. Even mining pools are too communal: the moment that the interactions of the bitcoin universe fail to consist solely of pristine blocks of pure value reeking of the scent of poorly-veiled animosity and apprehension, we are on the slippery slope to collusion-based attacks to debase the currency. Mining pools have gotten close to 51% before and have backed off out of the good in their hearts; however, whenever the good in people’s hearts matters, this represents a failure of any security model based around paranoia.</p><p>Of course, at least for the startups, we can look to the california ideology for why bitcoin was adopted by actual organizations. We can look to strange hybrids like ESR. The thing about the paranoid position is that it can be easily distracted from old threats by new threats; this is why libertarianism is a right-wing ideology now while it was a left-wing one fifty years ago. If you distrust the government because they are the one with all the guns and money, you’re right — they have both those things and they may or may not be on your side; but, if you support them wholeheartedly as soon as another party attacks, you’re gonna have a bad time. Bitcoin’s paranoia is against any kind of collaboration, but the bitcoin community’s mix of the generally paranoid and those paranoid only against the bugaboos of the moment (along with various collaborations, scams, and internal politics) have caused a mix of fracturing within the community and collusion with forces from without it. Bigotry is fractal, and as soon as the policy of paranoia in bitcoin became twisted, the community shattered.</p><p>This is a pretty common failure mode. Think of mole hunts in the CIA under James Jesus Angleton. Think of Jim Jones. Think of Ayn Rand’s last amphetamine-fueled years. A failure of appropriately applied paranoia cannot be remedied with an excess of poorly applied paranoia.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The bigger the bot hype grows, the more apparent it becomes that when it comes to bots, for now at…]]></title>
            <link>https://medium.com/@enkiv2/the-bigger-the-bot-hype-grows-the-more-apparent-it-becomes-that-when-it-comes-to-bots-for-now-at-313cfdcb72c6?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/313cfdcb72c6</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 14 Apr 2016 18:18:23 GMT</pubDate>
            <atom:updated>2016-04-14T18:18:23.943Z</atom:updated>
            <content:encoded><![CDATA[<p>The bigger the bot hype grows, the more apparent it becomes that when it comes to bots, for now at least, being interesting and making money are mutually exclusive. The bots that are being productized now are just special-purpose CLIs with none of the UX effort that goes into making CLIs actually useful.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Dear Recruiters,]]></title>
            <link>https://medium.com/@enkiv2/dear-recruiters-66532b7991e8?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/66532b7991e8</guid>
            <category><![CDATA[tech]]></category>
            <category><![CDATA[recruiting]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 08 Apr 2016 19:26:37 GMT</pubDate>
            <atom:updated>2016-04-08T19:26:37.359Z</atom:updated>
            <content:encoded><![CDATA[<p>Since you lot seem to be both very eager to spam me and pretty out of touch with reality, let me clarify a few things.</p><ol><li>I do not live in New York City. Yes, I know my LinkedIn profile says “greater New York City area”. That’s because the entirety of New England is considered part of the “greater New York City area” by LinkedIn. I am not going to commute to New York City. I am not going to move to New York City. There is no benefit to tripling my rent in order to live in a broom closet and work for a hedge fund.</li><li>Emailing me out of the blue is probably not going to work out very well for you. If I’ve heard of the company you represent, I probably either dislike them or suspect that you don’t actually represent them. If I haven’t, why would I care? I have a job right now, as you can see from my profile. Sending me more emails is also not going to help.</li><li>What the hell makes you think I want to work in finance? Nothing about my profile mentions it. No, I don’t want to work in web design or for a startup either.</li><li>If I receive an email from you, I figure odds are that you aren’t actually a recruiter, or aren’t actually representing whoever you claim to be representing. Why would a big company go trawling LinkedIn and emailing random junior developers who are already employed? If you want my attention, prove to me that you aren’t just a con artist. And do it in the subject line, because I’m not going to open your email.</li><li>On second thought, maybe just stop? You’re wasting minutes of your time and seconds of mine.</li></ol>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A quarter page of cliches about how bubble gum media is bad pitched at an imaginary audience who…]]></title>
            <link>https://medium.com/@enkiv2/a-quarter-page-of-cliches-about-how-bubble-gum-media-is-bad-pitched-at-an-imaginary-audience-who-896397b17c30?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/896397b17c30</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 08 Apr 2016 12:45:31 GMT</pubDate>
            <atom:updated>2016-04-08T12:45:31.128Z</atom:updated>
            <content:encoded><![CDATA[<p>A quarter page of cliches about how bubble gum media is bad pitched at an imaginary audience who has never heard the term “bubble gum media” is the pinnacle of bubble gum media, and exactly the trend in medium posts that I hate. If you’re going to write some unoriginal content, at least make your post thirty pages long and entertaining like Cuepoint and Backchannel do.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OK, OK, but a lot of these things are still toys.]]></title>
            <link>https://medium.com/@enkiv2/ok-ok-but-a-lot-of-these-things-are-still-toys-f0463803796c?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/f0463803796c</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 04 Apr 2016 12:41:19 GMT</pubDate>
            <atom:updated>2016-04-04T12:41:19.870Z</atom:updated>
            <content:encoded><![CDATA[<p>OK, OK, but a lot of these things are still toys. The mouse is still a toy, and the WIMP GUI is still a toy; the original mac was a toy for reasons related to hardware costs and hardware budget being eaten up by industrial design rather than by RAM, but the general policy that computers should be strictly limited to performing the tasks the designers thought of beforehand in the way the designers thought they should be done has continued to plague the line since 1982. Facebook was never intended to be more than a toy, and really isn’t: it’s a fun and profitable toy with very wide appeal, but it’s not as though anyone trusts it for genuinely important communications. Being profitable does not make something not toy-like, nor does becoming large in scale.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I’m going to have to point out that this survey will be biased.]]></title>
            <link>https://medium.com/@enkiv2/i-m-going-to-have-to-point-out-that-this-survey-will-be-biased-a435ce4c09fc?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/a435ce4c09fc</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 22 Mar 2016 15:10:06 GMT</pubDate>
            <atom:updated>2016-03-22T15:10:06.321Z</atom:updated>
            <content:encoded><![CDATA[<p>I’m going to have to point out that this survey will be biased. At least this is a Stack Overflow survey rather than a Y Combinator survey (which would be far worse), but even here — I use SO all the time but have never been asked to fill out this survey; many if not most people who use SO in the course of their jobs or for help with personal projects don’t even have accounts (because SO works better as a passive repository of historical good answers to common questions than as a means to have a novel question answered in a reasonable length of time — I’ve asked five or six questions and I’ve only ever gotten one response, months after I posted the question). In other words, only people who have an SO account and frequently ask or answer questions will be represented — and then, only those who feel like they have enough free time to fill out a survey.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I’m less concerned about actual scientists falling into this trap, because often they don’t (and…]]></title>
            <link>https://medium.com/@enkiv2/i-m-less-concerned-about-actual-scientists-falling-into-this-trap-because-often-they-don-t-and-3ba26cfd3dbd?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/3ba26cfd3dbd</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 21 Mar 2016 11:43:43 GMT</pubDate>
            <atom:updated>2016-03-21T11:43:43.752Z</atom:updated>
            <content:encoded><![CDATA[<p>I’m less concerned about actual scientists falling into this trap, because often they don’t (and those that do often don’t matter). However, science popularizers fairly frequently fail to adequately inspect their biases &amp; disregard the philosophy of science without understanding anything about it; science popularizers aren’t always even scientists (Bill Nye is a retired aeronautical engineer, and while Dawkins and Sagan were at one time research scientists they stopped their research in favor of writing for a general audience about science), yet they have a great deal of control over the popular view of science.</p><p>There’s a lot of variation here in terms of how reasonable they are, as well — Sagan almost certainly had heard of Karl Popper, and wrote about what one could reasonably consider to be the philosophy of science with a pro-science bias but with enough emotional distance not to completely disregard important limitations; meanwhile, Nye seems to think that philosophy is all about Plato’s Cave, and Dawkins doesn’t understand that the objective truth of scripture is a tiny and unimportant part of religion. I’m not quite sure where NDT falls here, but I feel like from what I’ve seen, he’s closer to Dawkins and Nye than to Sagan.</p><p>Ultimately, if actually active scientists have foolish beliefs about the philosophy of science, it doesn’t much matter: it doesn’t impact their ability to perform lab work and do reasonable analyses, generally. But, when you replace Bertrand Russel with Bill Nye, you’re going to have a bad time: suddenly, large chunks of humanity disregard important ideas and avoid using useful cognitive tools for, essentially, theological and tribal reasons. (And, to a certain extent, even Feynman is guilty of this: the macho arrogant physics-centrism he popularized has really screwed over a couple generations of otherwise promising people by giving them an easy way to dismiss important ideas.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[> But the reality is most people don’t want just a universal basic income.]]></title>
            <link>https://medium.com/@enkiv2/but-the-reality-is-most-people-don-t-want-just-a-universal-basic-income-2f587486478b?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/2f587486478b</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 17 Mar 2016 13:59:06 GMT</pubDate>
            <atom:updated>2016-03-17T13:59:06.840Z</atom:updated>
            <content:encoded><![CDATA[<p>&gt; <em>But the reality is most people don’t want just a universal basic income.</em></p><p>Source, please.</p><p>Certainly, I agree that SV is biased by extremes of wealth and privilege, and that their ‘solutions’ often don’t work outside of the context of rich white/asian males living in California and working in tech. However, a stopped clock is right twice a day: regardless of the reasoning used by one group of supporters, UBI is desirable to a number of very different groups for a variety of different reasons — not least by the precise opposite of SV, current minimum wage (or less) earners, many of whom would very much like a modicum of flexibility without the perverse incentive structures provided by current safety net systems.</p><p>The suggestion that people would reject UBI as charity is a delusion of people who understand neither UBI or actual want. After all, by definition, with UBI *everyone* would get the same income. This is not a matter of SV folks giving money to the poor; instead, this is a matter of everyone from billionaires to the homeless getting the same living wage.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[There’s a problem with people recommending ‘smart guns’: they clearly haven’t looked at the…]]></title>
            <link>https://medium.com/@enkiv2/there-s-a-problem-with-people-recommending-smart-guns-they-clearly-haven-t-looked-at-the-4bb02b16fa14?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/4bb02b16fa14</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 16 Mar 2016 15:35:31 GMT</pubDate>
            <atom:updated>2016-03-16T15:35:31.711Z</atom:updated>
            <content:encoded><![CDATA[<p>There’s a problem with people recommending ‘smart guns’: they clearly haven’t looked at the existing market for mechanical trigger locks, the best of which are still comically insecure enough that a six year old with a paper clip and two minutes can disable them. The market doesn’t have sufficient incentives to make gun locks as secure as bike locks, and it shows. Producing a more complex system for in-firearm locking, featuring electronics and biometrics, will not be profitable if people aren’t willing to pay a few dollars for a trigger lock that actually has tumblers.</p><p>There’s a system in place for gun owners who want to secure their firearms: gun safes. Gun owners who do not want to secure their firearms will not pay extra for an add-on or a special more secure gun, and people will quite reasonably resist any legislation that requires new firearms to have such features (Apple can’t keep its own products working reliably, and fingerprint readers aren’t very good at eliminating either false negatives or false positives — how could you expect Mossberg to do a better job, or for someone to want to add a battery pack to an object whose job it is to sit unused for its entire lifetime except in the rare situation that a home intruder appears?). Even if new firearms all had such a system, new firearms are not the majority of firearms on the market: unless the sale of older firearms was banned or older firearms were gathered and destroyed (two very unpopular ideas), the only result would be a sudden drop in firearm sales and a lot more import sales from overseas of older weapons; and, this is if we only account for legal sales.</p><p>One must also consider the culture of firearm owners. Firearm owners in the united states skew a bit to the right these days (although any group not firmly in the center and any group with legitimate concerns about the reliability of government-provided policing are more likely to own guns: consider the black power movement as an example of a decidedly leftist cohort with a pro-firearm stance based on a completely legitimate expectation that police would not protect their community), and are going to be suspicious of any mechanism that could get in the way of using a firearm when they decide they need to, particularly if that mechanism is coming out of a government they don’t trust. There’s also, at least within the subset of gun owners who are essentially functional, a culture of gun safety: children are taught how to be safe around firearms long before they are allowed to put their hands on them, and mistakes like poor trigger discipline or poor muzzle control are treated not merely as dangerous but as social faux pas that invite mockery (anyone who puts their finger inside the trigger guard is considered a buffoon from the hated out-group who doesn’t even know how to shoot a gun, and as a person whose presence is dangerous due to stupidity and incompetence). Legislation that interferes or duplicates the function of that acculturation comes off as tone-deaf and disconnected to people with that acculturation, even as it may protect the family of gun owners outside of gun-owning culture (who are at greater risk of accidental discharge because they are unaware of the kind of safety procedures that are drummed into infants in gun-owning culture); this legislation comes from the out-group and is for the out-group and thus seems unnecessary.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Talking about Dribble is undercutting exactly how stupidly static the western idea of ‘good design…]]></title>
            <link>https://medium.com/@enkiv2/talking-about-dribble-is-undercutting-exactly-how-stupidly-static-the-western-idea-of-good-design-db13391b7cc8?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/db13391b7cc8</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 11 Mar 2016 14:25:58 GMT</pubDate>
            <atom:updated>2016-03-11T14:25:58.137Z</atom:updated>
            <content:encoded><![CDATA[<p>Talking about Dribble is undercutting exactly how stupidly static the western idea of ‘good design’ is. Instead, we can look at how dominant themes in design go back to being influenced by Apple’s design standards from the early 1980s, which themselves are basically a simplified and dumbed-down version of late-1940s and early-1950s trends in modernist minimalism.</p><p>While there were plenty of interesting ideas in design from 1950 to 1980, because of Jobs’ reality distortion field we basically threw all of that out and have been increasingly influenced by this static throwback FrogDesign BS that was pretty questionable in 1979 (along with the underlying Jobsian ideology that consumers are too dumb to deal well with choices and must have decisions made for them — a necessary element in the application of extreme minimalism to ostensibly general-purpose machinery).</p><p>Today’s idea of good design is essentially: flat, spare, minimalist graphics with low information density and few user choices. Never use color if you can use white; never use two colors where you can use one; never use two buttons where you can use one and never use any buttons if you can get away with not having any; never give the consumer an option if you can please more than half of them by choosing first; if a user disagrees with a designer about usability then the user is wrong. These rules make some sense for a house or a toaster, and are defensible for a coffee machine or a toilet; they make no sense when applied to computers and even less sense when applied to computer software.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[MMOCs/MOOCs are probably the wrong match for the kind of learning technology presented in The…]]></title>
            <link>https://medium.com/@enkiv2/mmocs-moocs-are-probably-the-wrong-match-for-the-kind-of-learning-technology-presented-in-the-91fffca6e149?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/91fffca6e149</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 26 Feb 2016 13:44:52 GMT</pubDate>
            <atom:updated>2016-02-26T13:44:52.737Z</atom:updated>
            <content:encoded><![CDATA[<p>MMOCs/MOOCs are probably the wrong match for the kind of learning technology presented in The Diamond Age, which while fictionalized, was really a small extension of existing trends in *educational game technology* that existed in 1995. In other words, rather than fitting into trends related to the extension of traditional academic curricula with ed-tech (as MOOCs and video lectures do), it fits more closely with the Papert/Kay ‘mathland’ concept (and thus with things like LOGO, Croquet, MindStorms, and other systems built to encourage autodidacts to explore systems).</p><p>The middle ground — and a very useful and popular middle ground it is — between typical formal-instruction MOOCs and ‘mathland’-style environments is the new breed of quiz-focused gamified ed-tech services like Memrise and Duolinguo. Despite being truly useful for a fairly limited set of fields (i.e., those fields where the number of right answers tends to be limited and people can reasonably expect to learn from quick quizzes with immediate feedback in the absence of initial instruction — in this case, vocabulary, grammar, and lists of facts), they are very useful in these fields.</p><p>Both The Diamond Age and Ender’s Game reference and borrow from educational games from the 80s and early 90s, adding context-awareness and extra flexibility as their primary technical advancement; for the most part, the actual passages described from the educational video games in both of those books are cribbed from real games, and there’s no reason why such games could not still be made.</p><p>We have yet another very popular field of educational games: simulations (Sim City, Civilization) — we simulate a complex existing model of a system and the player is expected to become competent at understanding the behaviors of that model in order to execute his or her tasks. Closer to the Croquet model is Minecraft, which is educational insomuch as necessary tasks embed a great deal of fairly esoteric information about geology and about historical methods of producing common goods: Minecraft makes explicit the tech tree that Civilization uses as a progress bar, and requires players to demonstrate a familiarity with the general idea of what tools and materials are required for a given technology along with the previous technologies required to produce those tools and materials, at a much more granular level than Civilization.</p><p>Yes MOOCs rely too much on bad video. But, MOOCs are thirty years behind the curve on ed-tech and have never even attempted to be cutting-edge or maximally effective. If they had, they would at least focus on testing mechanisms rather than on methods for replacing books with AV presentations — because if engagement is sufficiently high, books are just fine.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I find this post significantly funnier than I should.]]></title>
            <link>https://medium.com/@enkiv2/i-find-this-post-significantly-funnier-than-i-should-3a01ef69837a?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/3a01ef69837a</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 11 Feb 2016 14:30:00 GMT</pubDate>
            <atom:updated>2016-02-11T14:30:00.707Z</atom:updated>
            <content:encoded><![CDATA[<p>I find this post significantly funnier than I should.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Read Intuition Pumps by Dan Dennett.]]></title>
            <link>https://medium.com/@enkiv2/read-intuition-pumps-by-dan-dennett-e95d3805685f?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/e95d3805685f</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 28 Jan 2016 15:10:48 GMT</pubDate>
            <atom:updated>2016-01-28T15:10:48.310Z</atom:updated>
            <content:encoded><![CDATA[<p>Read <em>Intuition Pumps</em> by Dan Dennett. It’s by far the best book on thinking tools I’ve read. (Compare directly to lesswrong’s “sequences”, which are similar in form but ultimately much inferior in both style and content.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I wonder if your experience is typical.]]></title>
            <link>https://medium.com/@enkiv2/i-wonder-if-your-experience-is-typical-99abad0595f6?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/99abad0595f6</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 25 Jan 2016 16:06:00 GMT</pubDate>
            <atom:updated>2016-01-25T16:06:00.603Z</atom:updated>
            <content:encoded><![CDATA[<p>I wonder if your experience is typical. I have a lot of projects on github (and have for some time), and I’ve gotten something along the lines of four issues/pull requests total. Having entitled trolls bothering you about your code doesn’t seem like it’s something common on github (although clearly they could be giving you the tools necessary to handle this better), and is (paradoxically) an indication that your project is extremely popular.</p><p>Part of the point of a system like github that makes forking projects easy is to eliminate pressure on upstream developers to implement features. In other words, while on an older project management system like sourceforge and google code having requests for features directed to the original authors of some code would be normal, github goes out of its way to shift the pattern such that people who want features are expected to create a fork and implement them themselves, before optionally issuing a pull request to submit the patch back to the source.</p><p>I wouldn’t blame github for this. Instead, somehow, you were targeted by a group of assholes who are too incompetent to implement the features they desire and too lacking in empathy to realize that you have more important things to do than to follow their whims. It’s absolutely appropriate to expect them to do their own homework, so to speak, and it’s a shame that they don’t seem inclined to do so (or to observe the basics of decorum).</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A cutup of Palin’s Trump endorsement speech]]></title>
            <link>https://extranewsfeed.com/a-cutup-of-palin-s-trump-endorsement-speech-51601c300478?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/51601c300478</guid>
            <category><![CDATA[2016-election]]></category>
            <category><![CDATA[politics]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 21 Jan 2016 17:56:09 GMT</pubDate>
            <atom:updated>2016-01-21T17:56:09.033Z</atom:updated>
            <content:encoded><![CDATA[<p>part why holy all more<br> and and around works but<br> they of Its youll The<br> theyve he the a well<br> for keep youre hero us<br> has ha to hard And<br> jobs as more Mr to<br> private conservative relax isnt was<br> go very Well Senate try<br> theyre Right other code day<br> who our they the all<br> infrastructure to the rogue for<br> are and multibillionaire they would<br> to to are Not of<br> theyre is we much them<br> to that hang changey going<br> We so the his the<br> known passionately tell our he<br> these racebaiting Heads division would<br> you proves vets Iowa sides<br> something ethic reform and hes<br> down him Donald busted quiet<br> a important they Theyre great<br> you brought with but than<br> or to then cooks and<br> are goodness you Its You<br> right team president why of<br> friends a you where gravy<br> He some told America America<br> a couple go and suck<br> others not for every spinning<br> sector am of and enemy<br> say fulltime from our I<br> tried to them Greek You<br> Well coming week debated political<br> their vest being tiny Parenthood<br> train part for bit and<br> to then to blank towns<br> to team multibillionaire When this<br> deserve horse so both ISIS<br> Ive voters to the private<br> unify selfiesticks to main Trump<br> the refreshing gonna things you<br> those So establishment let supporters<br> its and Trump contest fabric<br> and jobs would under look<br> see to keep to finally<br> and that Thank take titles<br> man of of Iowa to<br> of involved really is of<br> on machine on that able<br> of movement veil he values<br> issues packs ready the beautiful<br> to clingers and people be<br> they success the care on<br> even a with You hardhats<br> of but captors with were<br> a supporters again to overseas<br> passionate thats is teachers Trump<br> only was its attack were<br> and get of transformation year<br> teamsters helps we you watching<br> not deals his basic one<br> the break can out so<br> hands to as just for<br> until are new run command<br> going for so respect he<br> were it drill kick high<br> Democrat a I the hes<br> of eating enough and must<br> VP leader status off able<br> he out you know All<br> political to That needed and<br> thats knows tells in say<br> establishment promise too the that<br> whole over to dont is<br> to angry off and and<br> Look we on let ABCs<br> issues the its promised can<br> When ready me be families<br> media the and would let<br> share us is that beat<br> member up hopey Now Because<br> theres capture and they libertarian<br> more House Donald were exposed<br> our You actually folks races<br> been be trade is quit<br> And God the able States<br> this strict stage would there<br> putting Ill will not freedom<br> America stage because in Not<br> these that to his rest<br> for the No on other<br> table their tragic again to<br> Chicago havent Tru deals street<br> what tear that theyre in<br> this things community Doggone competitive<br> behind give of is proSecond<br> find worked we Fighters America<br> work your says again elitist<br> that very squirmishes borders and<br> to well for no troops<br> got America frontrunner great havent<br> budgets rollers thing to quo<br> I we Donald you nations<br> know to weaker it the<br> ass Ill And and to<br> had theyre A all other<br> betcha are this a this<br> up changes man remember commonsense</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Right on.]]></title>
            <link>https://medium.com/@enkiv2/right-on-dacb0120c54a?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/dacb0120c54a</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 21 Jan 2016 14:13:08 GMT</pubDate>
            <atom:updated>2016-01-21T14:13:08.356Z</atom:updated>
            <content:encoded><![CDATA[<p>Right on.</p><p>Basically, if you don’t need interactivity, there’s no excuse for having it. If the point of the website is to display text, it should just *display text* and neither javascript nor css is justified (let alone a CMS).</p><p>To be honest, your site isn’t quite minimal enough for my tastes. You could have gotten away with pure HTML and no formatting, and it would have been better. But, at least you’re on the right track.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The idea of a Bowie]]></title>
            <link>https://medium.com/@enkiv2/the-idea-of-a-bowie-56aaf62fc2eb?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/56aaf62fc2eb</guid>
            <category><![CDATA[music]]></category>
            <category><![CDATA[david-bowie]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 20 Jan 2016 13:57:21 GMT</pubDate>
            <atom:updated>2016-01-20T13:57:21.758Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p>I was surprised that I was affected so much by Bowie’s death. Despite being a fan, I don’t have a huge appreciation for the level of musical craft in Bowie’s music — I see him as an experimenter, and I appreciate him in the same way as I appreciate Steve Reich or Skinny Puppy: I liked the way that he wasn’t afraid to alienate his audience in pursuit of some pure expression. Nevertheless, I feel like a void has opened in the pit of my abdomen, slowly sucking my entrails out from the inside. I used to make fun of people for mourning celebrities, but I’ve been shown firsthand that the kind of connection between an artist and his audience is a real one, and the pain that occurs when it’s severed is real too.</p><p>The worst part is, Bowie isn’t even dead. David Jones is dead. Bowie was never alive in the first place.</p><p>This is not an idle distinction. David Bowie is a fiction-suit. David Bowie has no more to do with David Jones than Ziggy Stardust does, and we killed Ziggy a long time ago.</p><p>What David Bowie is, ultimately, is not a human being nor an icon but a set of patterns, practices, and behaviors. David Bowie is a way of life. Buried in the coverage of Jones’ death, clues about how to Bowie are being uncovered and re-aired: information about the creative process from old interviews, and some of the theory behind it.</p><p>I didn’t know David Jones. But, to a certain extent, I, like other fans, know Bowie, because Bowie is a construct made exclusively to be known by fans. Here is my attempt to put together the beginning of a list of things that made the Bowie fictionsuit interesting.</p><ol><li>Bowie is a container for other personalities. Even as Bowie is not Jones, Bowie also constructed and discarded other identities, acting as a buffer between these identities (who are ultimately the real rock stars) and Jones himself. Each of these identities is a mythic figure with an epic arc. Each of these identities has a different angle on both the world and Bowie. Ziggy Stardust and Halloween Jack are warped Christ-figures: in a gnostic manner, they become minor messiahs for a group of disaffected youth while corrupting themselves in the process, and in the end they are bodily destroyed by invisible powers greater than themselves whose bidding they were unknowingly doing and whose goals were ultimately selfish; Aladdin Sane and Cracked Actor were more meta: a window into the fracturing of personality. An album was a story of another Bowie fictionsuit, and albums iterated on previous albums, rewriting their story: Outside rewrote Scary Monsters, which rewrote Diamond Dogs, which rewrote The Rise and Fall of Ziggy Stardust, which itself rewrote sections of Space Oddity (consider Memory of a Free Festival). Every Bowie egregore is created, set on its path up the arc of the monomyth, and killed off and discarded at the peak of its cultural power. It is in this way that Bowie (and Jones himself) avoided the rock star’s mythical downfall.</li><li>Bowie took creativity very seriously, and availed himself of mechanical means to expand upon ideas and styles. He used cutups for twenty years, both to expand inspiration via juxtaposition and to create actual content. References to Thelema are indications that Bowie was familiar with the english cabala and with Tarot — which is to say, he is familiar with the history of using bibliomancy as a mechanical means of obfuscating existing patterns to generate new insights. When he said that the cutup method is “a very western Tarot”, this indicates the depth of his insight: after all, Tarot is not (historically) eastern — even the people who make dubious claims as to the long history of Tarot only put it as far east as Egypt, while actual historians would say that the game of trumps originated in fifteenth-century Italy and the use of Tarot in divination originated in nineteenth century England under the Golden Dawn — so what does it mean to be a “very western” Tarot? Geographically, the cutup method in its modern form was developed in the international zone of Tangiers in Morocco — so, west of Egypt and west of Italy but southeast of England — and its predecessors in the form of surrealist and dadaist writing games were european. Instead, we can say that the cutup is a culturally western Tarot: it is a purely mechanical means of symbolic rearrangement developed by an american heir to a calculator fortune, and it eschews the kind of monastic memorization of static correspondences that Tarot relies upon. It is a more culturally western (by which I mean empiricist-pragmatist-positivist) occult tradition than the Western Occult Tradition. By the time that Bowie was writing Outside, he had graduated to an even more mechanized and even more western form of cutups: a computer program developed in California for the Macintosh that chopped sentences into five-word columns before shuffling the columns.</li><li>Bowie wasn’t afraid to appropriate other people’s ideas and scramble them. In some sense, Bowie himself was like a cutup machine. At various points, in interviews, he eschews any sense of intended meaning behind his words and actions. To an older crowd, this is sometimes seen as the mark of a pretentious poseur; but, this postmodern attitude toward meaning and toward the function of media is in line with bibliomancy historically. Bowie was a catalyst for other people’s growth, because he put things out there that other people had to fit together, and because they fit those things together using pieces of themselves. Sometimes, this cabalistic attitude toward art merely affected the way identities were presented; other times, it had drastic effects on the media he was working in (such as Bowie’s outsized affect upon the glam, punk, and rivethead genres). Juxtaposition of genres creates new genres while expanding those genres that have been juxtaposed. Bowie did this as a habit.</li><li>Bowie didn’t stop. He didn’t have to. By sacrificing his fictionsuits, he saved himself and was able to work another day. As a result, he was able to release albums at a fairly steady pace from the mid-60s to 2016. Part of his legacy is the fact that he was so productive for so long, and part of his legacy is that he never stopped innovating.</li><li>When it was time for David Jones to leave, Bowie made a show of casting him off too. The body that had held the idea of Bowie is gone, but in addressing directly the same way he had with Ziggy, Bowie took control of this situation. One way of reading Blackstar and Lazarus together is to consider it a fight between Jones, who wants to keep being Bowie, and Bowie, who wants to cast off Jones in order to live on in another body. (I am treating Lazarus as being from the perspective of Jones and Blackstar as being from the perspective of Bowie.)</li></ol><p>Obviously, all of this was combined with a lot of talent, hard work, energy, and heaps of pure physical sex appeal. Invoking the Bowie godform is never going to be easy. But, neither is it impossible.</p><p>Bowie is dead. Long live Bowie.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[If you find the others on the road, kill them]]></title>
            <link>https://medium.com/@enkiv2/if-you-find-the-others-on-the-road-kill-them-575c645ff8aa?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/575c645ff8aa</guid>
            <category><![CDATA[social-media]]></category>
            <category><![CDATA[culture]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 19 Jan 2016 14:31:12 GMT</pubDate>
            <atom:updated>2016-01-19T14:31:12.565Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p>The last part of Tim Leary’s famous quote is often forgotten: “turn on, tune in, drop out, and find the others”. Leary claimed it was the most important part: after all, all of the outsider weirdo creativity goes to waste if it’s stuck in your skull. Unfortunately, <a href="https://archive.is/tYpHV">nothing has prepared us for the strange times</a>.</p><p>There is no counterculture anymore, because there is no mainstream culture anymore. (Maybe there is for you, if you live in a theocracy with state-regulated media and heavily limited internet access. If you are, congratulations on reading this post, and also why are you reading this post?) The spectacle has consumed and absorbed the early-90s utopian cultural pluralism of the John Perry Barlow set, just as it absorbed the culture/counterculture division of the 50s and 60s, which is why people like Stewart Brand are rich de-facto plutocrats now. And in the global village, no matter how freaky you are, you can surround yourself with precisely the same kind of freak and live in your little filter bubble. Finding the others, in this case, is a bad thing.</p><p>Don’t find the others. Find the Others. Stick apart. If you agree with someone, take that as a warning sign: do the two of you agree for good reasons, or are you just incidentally the same kind of freak?</p><p>The function of the lunatic fringe is not to become a comfortable space for you and your like-minded friends. There are other places for that. The function of the lunatic fringe is to thrust half-baked ideas into a violent orgy of death and copulation until they become more fully baked or die the death of warriors.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[To be sure, these hollywood formulations are male-centric.]]></title>
            <link>https://medium.com/@enkiv2/to-be-sure-these-hollywood-formulations-are-male-centric-5dd91873b89d?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/5dd91873b89d</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 19 Jan 2016 13:25:32 GMT</pubDate>
            <atom:updated>2016-01-19T13:25:32.682Z</atom:updated>
            <content:encoded><![CDATA[<p>To be sure, these hollywood formulations are male-centric. But, to suggest that those aspects will translate is to assume that it’ll even work. The requirements of hollywood UX are very different from real UX, and this is most extreme with conversational interfaces — to the point that the kinds of interfaces that work in films do not work IRL and vice versa.</p><p>After all, in a film, any computer interface must be immediately recognizable and understandable to people seeing it for between a few seconds and a few minutes. A real computer interface, on the other hand, can be initially a bit confusing if that makes it more usable in the long run. To be more concrete: a film’s UI must have bright colors and a giant font and only clearly show plot-relevant information (otherwise the viewers wouldn’t know where to look), while a real UI needs to show whatever information the user might find useful (life has no plot) and giant fonts and bright colors would annoy long-term users. This kind of problem extends out to conversational interfaces in films, which are driven by exposition and spectacle. People in films don’t even talk to each other the same way as they do in real life, because dialogue is optimized for showing off plot and character rather than engaging in the kind of social game-playing that dominates real dialogue.</p><p>A real conversational interface ideally resembles the interaction between two technical professionals: in other words, over time a shortened and optimized jargon is developed for more efficient communication, so that the kind of conversation that begins looking like an interaction between strangers eventually ends up resembling a command line interface.</p><p>A conversational interface based on mimicing conversational interfaces from movies won’t support the patriarchy, because it will be almost completely useless — worse in all ways than a simpler system based on individual commands. Anyone who uses such an interface is merely screwing themselves over.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Why you should care about generative text]]></title>
            <link>https://hackernoon.com/why-you-should-care-about-generative-text-52496cb74beb?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/52496cb74beb</guid>
            <category><![CDATA[tech]]></category>
            <category><![CDATA[journalism]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 13 Jan 2016 17:04:08 GMT</pubDate>
            <atom:updated>2016-01-13T17:04:08.582Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p>Generative text gets some press. Unfortunately, like many other technical fields that attract shallow coverage, generative text has been the subject of minor variations on the same article every few months since the mid-1950s.</p><p>The typical article on anything related to generative text (particularly generative fiction) has <a href="https://github.com/enkiv2/NaNoGenMo-2015/blob/master/clickbait.md">the following pattern</a>:</p><blockquote>“[Insert quote here].”</blockquote><blockquote>You would think that was written by a human, wouldn’t you? Well, reader, you are a dumbass, because that was written by a machine!</blockquote><blockquote>But don’t feel too bad, because here is an example of the machine writing something comically terrible and absurd: “[insert quote here]”.</blockquote><blockquote>“[Insert quote here],” says one of the three researchers in the field that we crib quotes from previous interviews from every six months.</blockquote><blockquote>In conclusion, I’d like to reassure you that computers won’t be writing all the novels soon. Or will they? Shock!</blockquote><p>If you haven’t read articles about generative fiction before, no matter; <a href="https://github.com/dariusk/NaNoGenMo-2015/issues/9">they’re all like that</a>. If you have, you know what I mean. This article is not that article. I’m going to tell you all of the interesting things about generative text that those articles didn’t cover.</p><p>You should care about generative text if you care about:</p><h4>Video games</h4><p>Video games have been trying to expand their clout as a narrative medium. While there are a lot of ways to do narrative in an interactive medium, one of the most obvious is to have interactive dialogue. After all, dialogue usually drives narrative in films, books, comics, and TV.</p><p>Unfortunately, dialogue trees don’t scale well: after all, they grow exponentially, and inconsistent or inadequately varied dialogue is extremely obvious. As a result, dialogue-driven interactive narrative is typically limited to big game studios, and truly complex dialogue trees are rare even in game genres that have that as their primary technical focus (such as VNs and adventure games).</p><p>The same way that, five years ago, indie game developers started looking toward procedural world generation as a way of creating large maps that allowed them to compete with large development houses’ sandbox games in terms of scale, <a href="http://forum.makega.me/t/procedural-narrative-dialogue/91">indie game developers now are beginning to look at the various ideas in the field of text generation</a> for ideas about automatically generating varied dialogue and dialogue trees from models of character and narrative. <a href="http://www.rockpapershotgun.com/2015/07/01/chris-crawford/">The next Minecraft might derive its scale from procedural expansion of NPC dialogue instead of procedural expansion of the map</a>.</p><h4>Journalism</h4><p>Right now, because of the use of advertising for monetization of content, a lot of internet ‘journalism’ is clickbait — in other words, content optimized for page view counts rather than for sustained attention. Clickbait is generated at low cost by content farms; it’s poor-quality because being high-quality is a net loss, and it’s short because that’s cheaper than being long. Clickbait optimizes for two things: number of ads on a page and number of people who will click a link. However, generative text is extremely promising for content farm owners: after all, even if you’re paying content farmers pennies an hour, you’re still paying more for these humans than you would for machines, who can generate far more content far more quickly with only slightly lower average quality. The kind of A/B testing that content farms use for optimizing their headlines is, furthermore, a perfect match for existing methods by which relatively simple AIs can use feedback to improve their headline generation — and AIs are already pretty good at generating clickbait headlines. In other words, machines might well easily replace the lowest end of internet journalism.</p><p>At the same time, text generation is already beginning to supplant the lowest end of traditional paper journalism, with various organizations automatically generating minor financial and sports stories. This frees up human writers to be put on more interesting stories, or to alternately be fired, depending upon the skill of the writer and the financial situation of the news agency.</p><p>Both of these effects are truly huge potential economic shifts in these industries. And, they have the potential to be truly positive, as well. Consider Buzzfeed, which makes its money off inane clickbait content and then turns around and funds wonderfully deep serious journalism by serious journalists about interesting subjects with all that shit-click money: if they automated their low-quality high-lucre content, they could shift more of their workforce toward high-quality journalism. Alternately, the slightly lower quality of machine-written articles versus content-farmed articles might accelerate the devaluation of clickbait and cause <a href="https://medium.com/@enkiv2/alternatives-to-advertising-7af0e32b8a8e#.r7943d2xy">alternatives to ad-based monetization</a> to become more popular more quickly.</p><h4>Psychology</h4><p>The effectiveness of generative text is the result of an interplay between the design of the generator and the human audience. The best generators lean heavily on the human element, using rich associations and loaded structures to convince the reader to project meaning onto the text, which itself is very often structurally simple. All of this is to say that a large part of the design of text generators is psychology. Invert this, and it’s not at all surprising that text generators are being used by experimental psychologists to probe the human mind.</p><p>Just recently, there’s been press coverage of <a href="http://journal.sjdm.org/15/15923a/jdm15923a.pdf">a study using a new-age BS generator to study personality traits associated with the projection of meaning</a>, as well as of <a href="http://www.wired.com/2014/04/underwire_0401_funnycomputer/">a</a> <a href="http://www.nytimes.com/2013/01/06/opinion/sunday/can-computers-be-funny.html">group </a><a href="https://www.abdn.ac.uk/ncs/departments/computing-science/standup-315.php">of</a> <a href="http://news.bbc.co.uk/1/hi/scotland/5276366.stm">older</a> <a href="http://www.aclweb.org/anthology/P/P11/P11-2016.pdf">studies</a> using joke generators to study the mechanics of humor. Text generation allows psychology experiments to scale up and to have extremely fine control over the material they use; when text generators used in psychology experiments have their source made available, later experimenters can tweak the generator in various ways in order to easily test variations on the original experiments, and text generators can be hooked up directly to systems like Mechanical Turk that allow experimenters to expand their studies outside the college campus.</p><h4>Spam</h4><p>The spam industry is the only segment of the tech world to really take text generation seriously. Spammers have been using techniques like<a href="http://alexking.org/blog/2013/12/22/spam-comment-generator-script"> text spinning</a> to trick both humans and AI filters for more than a decade. As technology improves, spam will get better. Any advances in text generation will probably be employed by spammers first.</p><h4>Ebooks</h4><p><a href="http://www.theguardian.com/technology/2011/jun/23/ebook-spam-problem-growing">A few years ago, Amazon had a problem with machine-generated reference books of poor quality</a>. These reference books would be produced based on search queries, which were fed into Wikipedia and the resulting pages combined, initially into a print-on-demand book but later into ebooks. It’s a little unclear to me how Amazon fixed this problem, but it doesn’t seem to be such a big deal anymore.</p><p>However, this is not the only con in Amazon’s ebook ecosystem. Today, the big money is in creating hyper-targeted erotica[<a href="http://thehustle.co/underground-world-of-kindle-ebooks">1</a>, <a href="http://thehustle.co/part-2-confessions-from-the-scammy-underground-world-of-kindle-ebooks">2</a>, <a href="http://thehustle.co/part-3-confessions-from-the-scammy-underground-world-of-kindle-ebooks">3</a>]. Consumers of erotic fiction often don’t care very much about prose quality, or are prevented by fear of social stigma from being vocal in their criticism of poor-quality prose in erotica. Erotic fiction is extremely popular, and hyper-specific subgenres have their own categories on Amazon, which means that it’s fairly easy to get to bestseller status in a single category (and thus have a boost in sales resulting from a listing on bestseller pages).</p><p>Again, text generation is a very good fit for erotica. <a href="https://github.com/enkiv2/NaNoGenMo-2015/blob/master/orgasmotron.gg">It is easy to generate </a><a href="https://github.com/enkiv2/NaNoGenMo-2015/blob/master/orgasmotron.md">arbitrary amounts of poor-quality erotica</a>. Erotica is either effective or comical: even bad erotica is good. While existing cons for Amazon erotica ebooks often involve taking public domain erotica and publishing it with a few easily automated changes, there’s no reason that brand new erotic fiction couldn’t be generated in various categories at the kind of rate that only machines can keep up with.</p><h4>UI design</h4><p>Partly because of the hype behind Slack and Siri, conversational UIs have become <a href="https://medium.com/@enkiv2/this-is-not-no-ui-it-s-text-based-ui-c4e5991b7edb#.cn9qgdc8u">trendy recently</a>. Those of us of my generation will recall the failure modes of conversational UIs. (Remember SmarterChild?) Understanding how to perform good text generation and take advantage of the Eliza Effect will help future conversational UIs feel less static and more lively.</p><p>Determining whether or not forming an emotional attachment to an AI-driven corporate mascot is a good thing is left as an exercise for the reader.</p><h4><a href="https://medium.com/@enkiv2/the-hidden-benefits-of-nanogenmo-dd91193bda6#.gej1q63qt">The arts</a></h4><p><a href="http://mathesonmarcault.com/index.php/2015/12/15/randomly-generated-title-goes-here/">There’s a long history</a> of musicians and authors employing ‘writing machines’ to help produce inspiration from old content. These ‘writing machines’ vary in details, from forms of traditional bibliomancy to dadaist or surrealist writing games to oulipo-style constrained writing to the use of computer programs for scrambling text. <a href="http://www.philipkdickfans.com/literary-criticism/frank-views-archive/vertex-interview-with-philip-k-dick/">Phillip K. Dick used the I Ching to determine the plot of his award-winning novel <em>The Man in the High Castle</em></a>; <a href="http://www.ubu.com/film/burroughs.html">William S. Burroughs</a>, <a href="http://radiohead1.tripod.com/songs/album/everything.htm">Thom Yorke</a>, and <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjpxs-roKfKAhUEJR4KHVpbDWMQqQIIHzAA&amp;url=http%3A%2F%2Fwww.bbc.com%2Fnews%2Fentertainment-arts-35281247&amp;usg=AFQjCNFYxGWyrcdjoq05de-xRTteiZS0Wg&amp;sig2=Vsc5K3OnLiucThMFM7KkvA&amp;bvm=bv.111396085,d.dmo">David Bowie</a> all used cutups to inspire their work (going so far as to sometimes use the text produced by cutups directly); Doctor Seuss’s unique style was largely determined by <a href="http://jamesclear.com/dr-seuss">heavy constraints on his vocabulary</a>.</p><p>Text generation technology presents a new set of ‘writing machines’ for authors, poets, and musicians to collaborate with and build upon. The difference is that, where previous mechanisms primarily created stylistic affectations or merely inspired narrative tangents, <a href="https://github.com/dariusk/NaNoGenMo-2015/issues/11">more recent text generation technologies are capable of producing a variety of engaging and interesting narratives by themselves</a>.</p><p>Outside of the more traditional forms, pure text generation has come into its own in the form of text generator driven twitter bots. <a href="https://twitter.com/marvelplots">A</a> <a href="https://twitter.com/nerdgarbagebot">variety</a> <a href="https://twitter.com/hotteststartups">of</a> <a href="https://twitter.com/likeuberbut">pitch</a> <a href="https://twitter.com/newmythologies">bots</a> use simple templates to produce amusing and evocative ‘pitches’ by <a href="https://twitter.com/restartthevoid">combining familiar forms</a> with <a href="https://twitter.com/TwoHeadlines">mismatched corpora</a>. Bots exist that <a href="https://twitter.com/thinkpiecebot">automatically generate biting satire</a> of overused, shallow, or damaging trends.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Absolutely in agreement with you, here. This is a major pet peeve.]]></title>
            <link>https://medium.com/@enkiv2/absolutely-in-agreement-with-you-here-this-is-a-major-pet-peeve-f95faa668356?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/f95faa668356</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 21 Dec 2015 17:23:08 GMT</pubDate>
            <atom:updated>2015-12-21T17:23:08.065Z</atom:updated>
            <content:encoded><![CDATA[<p>Absolutely in agreement with you, here. This is a major pet peeve.</p><p>The way I usually phrase this position is: “For any definition of creativity not formulated specifically to exclude them, computers are already capable of creativity, and have been since the 1950s at the latest.”</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Something not mentioned in the article is that OpenAI is in direct competition with several other…]]></title>
            <link>https://medium.com/@enkiv2/something-not-mentioned-in-the-article-is-that-openai-is-in-direct-competition-with-several-other-e3463032b2d?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/e3463032b2d</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 15 Dec 2015 15:08:02 GMT</pubDate>
            <atom:updated>2015-12-15T15:08:02.637Z</atom:updated>
            <content:encoded><![CDATA[<p>Something not mentioned in the article is that OpenAI is in direct competition with several other non-profits whose goals are (or include) to ensure provably friendly AI — MIRI being the obvious example. I’m a little worried that all of these seem to be run on the west coast of the US and funded by the same group of ‘california ideology’ folks — if there are any hardcore marxists around who want to ensure provably friendly AI, I recommend that they set up some competition too!</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[One peeve I have with this analysis is: even if you consider a dysfunctional government to be…]]></title>
            <link>https://medium.com/@enkiv2/one-peeve-i-have-with-this-analysis-is-even-if-you-consider-a-dysfunctional-government-to-be-c5ec437678ea?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/c5ec437678ea</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 17 Dec 2015 18:01:13 GMT</pubDate>
            <atom:updated>2015-12-17T18:01:13.022Z</atom:updated>
            <content:encoded><![CDATA[<p>One peeve I have with this analysis is: even if you consider a dysfunctional government to be similar to a dysfunctional corporation, Trump is not a skilled businessman: he just plays one on TV. For all her past failures, Florina has a better record in that regard.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I don’t buy the idea that these kinds of restrictions will ever become universally (or even nearly…]]></title>
            <link>https://medium.com/@enkiv2/i-don-t-buy-the-idea-that-these-kinds-of-restrictions-will-ever-become-universally-or-even-nearly-69c835ea083e?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/69c835ea083e</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 15 Dec 2015 13:58:23 GMT</pubDate>
            <atom:updated>2015-12-15T13:58:23.034Z</atom:updated>
            <content:encoded><![CDATA[<p>I don’t buy the idea that these kinds of restrictions will ever become universally (or even nearly universally) enforced.</p><p>Why?</p><ol><li>Because advertising, like many other forms of capitalism, is a race to the bottom that subverts any attempts to ensure quality. Advertising optimizes for metrics because it is paid based on metrics, and the least-effort means to provide comparable metrics will be used. Bad ads can risk being totally ineffective because it’s a safe bet that the people paying for them won’t realize they’re ineffective until the bad ads have already made enough money to justify the effort.</li><li>Because the largest ad providers in the world (Google’s Adsense and Doubleclick) already enforce quality standards for ads and already enforce many of the constraints you’ve suggested (to the extent that they can). By doing so, they yield part of their potential market to middle-men who specialize in low-quality scammy ads. As long as we have ads, we’ll have scammy, grey-legal ads, and the attempt by the largest providers to improve general quality has led to a bifurcation in the ad market between up-market ads and explicitly crap ads. Some ad-blockers allow up-market ads (those approved by Adsense) to be shown with some constraints; this just means that the scammy ads get shown exclusively to the less-savvy users who were more likely to click them anyhow.</li><li>Ads don’t really work particularly well in the best of cases. Having an ad-based economy on the web is, essentially, a bubble. Any ad is inherently an annoyance, so getting rid of the absolute worst ads won’t keep people from using ad blockers. The widespread use of ad blockers will just make it clear to companies formerly using advertising that the utility of advertising (particularly on the web and particularly through media that are clearly ads) is minimal. Already, there are plenty of ways in which the traditional web-based ad ecosystem is being circumvented: patreon and similar crowd-funding mechanisms are supplementing or replacing ad-driven content because ads don’t pay without enormous volume; large companies are sponsoring high-quality content that is largely unrelated to them (GM sponsoring Backchannel &amp; the Cracked Podcast, for instance); Google Contributor uses the existing Adsense infrastructure to directly pay ad hosts with money uploaded by users without involving the advertisers at all; while that standalone bitcoin-mining machine intended to pay for content passively doesn’t have its economics straight yet, a similar system is perfectly feasible in theory; various attempts at automating the music royalty system seem likely to yield or inspire a general-purpose transcopyright-style micropayment infrastructure for derivative works &amp; content reuse. Some or all of these things will eat up enough of the web ad ecosystem to make the changes you propose pointless long before enforcing them becomes practical.</li></ol>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[How to become Steve Ballmer: implement stack ranking, throw chairs at people during meetings, yell…]]></title>
            <link>https://medium.com/@enkiv2/how-to-become-steve-ballmer-implement-stack-ranking-throw-chairs-at-people-during-meetings-yell-42a241041926?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/42a241041926</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 03 Dec 2015 19:38:24 GMT</pubDate>
            <atom:updated>2015-12-03T19:38:24.477Z</atom:updated>
            <content:encoded><![CDATA[<p>How to become Steve Ballmer: implement stack ranking, throw chairs at people during meetings, yell a lot.</p><p>How to become Steve Jobs: make fun of your employees until they cry and/or become suicidal, and then later take credit for their work.</p><p>Why do so many people want to emulate famous assholes from industry?</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I keep on being reminded of “Sirius Cybernetic Corporation” — the company in the Hitchhiker’s Guide…]]></title>
            <link>https://medium.com/@enkiv2/i-keep-on-being-reminded-of-sirius-cybernetic-corporation-the-company-in-the-hitchhiker-s-guide-ca19a1498aa7?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/ca19a1498aa7</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 07 Dec 2015 16:04:30 GMT</pubDate>
            <atom:updated>2015-12-07T16:04:30.066Z</atom:updated>
            <content:encoded><![CDATA[<p>I keep on being reminded of “Sirius Cybernetic Corporation” — the company in the Hitchhiker’s Guide series that keeps producing robots who are irritating because they are too human. To a certain extent, it makes sense to treat corporations and media properties more like machinery — not insomuch as you kick them when they’re not working (to be honest I wouldn’t trust anybody who hurts a machine on purpose) but insomuch as your transactions with them are expected to be limited in scope. You don’t need to smile and say “good morning” to a vending machine but you are expected to do so to a cashier, which is not desirable for you *or* the cashier (because you’re both put in a situation where potentially both parties are supposed to feign happiness and friendliness); media entities on the internet are worse when they break out of the transactional mold, because they benefit less from thousands of people sending them cheerful messages (or, you know, hate mail). Ultimately, we want our robots to work like robots, and we want our computer-mediated commercial interactions to hide the human being behind the screen and just show us the robotic interface.</p><p>I see why this trend exists, of course. Intimacy means replacing a dunbar slot. If some very lonely person has 150 of their slots filled by corporations and the rest by actual family, those corporations have a very good defense against competition for that particular customer: because to the customer, Coca Cola is a best friend and Pepsi is a creepy stranger. Of course, this polarizes the effect when everybody tries to do this, and it polarizes the effect even moreso for people who have rich social lives and have most of their slots filled by human beings: suddenly every celebrity and corporate entity is a creepy stranger trying to con you out of money by being overly familiar.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[There are a couple of models for self-directed learning resources that are useful to look at…]]></title>
            <link>https://medium.com/@enkiv2/there-are-a-couple-of-models-for-self-directed-learning-resources-that-are-useful-to-look-at-2db71666ac7b?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/2db71666ac7b</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 07 Dec 2015 15:26:39 GMT</pubDate>
            <atom:updated>2015-12-07T15:26:39.559Z</atom:updated>
            <content:encoded><![CDATA[<p>There are a couple of models for self-directed learning resources that are useful to look at, because historically they’ve been extremely effective.</p><p>One is the reference-material model. Its extreme end is a system like wikipedia: few things are more self-directed than a huge set of extremely detailed articles all hyperlinked together. If you have a goal in mind, you can search and probably find what you’re looking for if you know the right keywords; if you have no goal, you can idly wiki-walk and sate your curiosity indefinitely. (For media, tvtropes may be better than wikipedia, but tvtropes also has elements of the next model I’m discussing — the collegiate model — and may fit better into that category for various reasons. However, for very particular domains there are better resources than wikipedia: memory alpha, for instance, has better coverage of star trek trivia than wikipedia does.)</p><p>Another is the collegiate model. I call it that because this is the kind of thing that universities try to produce in both students and research faculty, and it’s also one of the arguments for think-taks and open-plan offices. I would argue that the most extreme form of it is in collaborative open question-answering communities like Quora and Stack Overflow, with comment-centric news sites with voting mechanisms (reddit, hacker news) and any other discussion system with large numbers of extremely active members (imageboards like 4chan for instance) coming in second. The point of a collegiate model is that you have people from different fields of interest interacting with each other in a dynamic way. Everybody learns, everybody takes the role of both teacher and student, and often the community itself produces new ideas and names them. A reference-material model is extremely effective at allowing a motivated learner to access existing well-documented ideas, but a collegiate model produces new ideas and allows motivated learners (even if they are beginners) to participate in the process of producing those ideas. That said, the reference-material model imposes some rigor on ideas (mostly by transplanting the rigor of existing established systems like peer review, academic publishing, canonicity, and journalistic standards), while the collegiate model’s flaws and benefits come from its flexibility. A collegiate model system will produce many ideas, and only a few of them will be good; furthermore, any bias in membership is likely to perpetuate itself (male-heavy communities often over time become misogynistic and then become even more male-heavy as they shut out women; the same is true of sample biases in terms of economic situation, race, religion, and even otherwise innocuous differences like tendencies toward logical positivism versus epistemic agnosticism or belief in free will versus determinism. For extreme examples, look at 4chan’s various boards, many of which are incredibly creative and have had a huge impact on the culture of the internet but each of which have consistent and absurdly biased cultures and habits that often don’t translate well between boards).</p><p>Attempts to automate self-directed learning have historically relied upon sticking a layer of gamification on top of the reference-material model — everything from hand-held trivia games to twenty questions to duolinguo do this (and memrise does this while sticking a tiny bit of collegiate model in a bag on the side by allowing people to create and vote on mnemonic devices).</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Yes, but not all of us physically assault our employees and then are lionized for it.]]></title>
            <link>https://medium.com/@enkiv2/yes-but-not-all-of-us-physically-assault-our-employees-and-then-are-lionized-for-it-54ca378e8a34?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/54ca378e8a34</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 04 Dec 2015 16:13:13 GMT</pubDate>
            <atom:updated>2015-12-04T16:13:13.153Z</atom:updated>
            <content:encoded><![CDATA[<p>Yes, but not all of us physically assault our employees and then are lionized for it. That’s reserved for a special class of people whose luck has ruled them immune to criticism.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Jobs is interesting insomuch as he’s a figure who is inextricably associated with industries that…]]></title>
            <link>https://medium.com/@enkiv2/jobs-is-interesting-insomuch-as-he-s-a-figure-who-is-inextricably-associated-with-industries-that-23bd31eef9fa?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/23bd31eef9fa</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 03 Dec 2015 17:05:22 GMT</pubDate>
            <atom:updated>2015-12-03T17:05:22.818Z</atom:updated>
            <content:encoded><![CDATA[<p>Jobs is interesting insomuch as he’s a figure who is inextricably associated with industries that, on the technical level, he had no particular familiarity with, and on the management level, he was not particularly successful with. I can’t help but imagine that, for the most part, Jobs is famous for a combination of charisma and luck: he was willing to present himself as a figurehead and invite the suggestion that he had a greater hand in the products he is selling than he really does, but he would be forgotten if it wasn’t that his post-1997 decisions for Apple were largely just as profitable as his 1980–1985 decisions were unprofitable.</p><p>In this sense, he’s similar to other larger-than-life figures particularly in the financial industry: a professional gambler in a sense whose personality and convictions about skill borne from luck have led him to become interesting as a character.</p><p>After all, many of Jobs’ positive contributions were minor and aesthetic (the beveled corners of early Macs) or were positive only due to a series of clearly unpredictable accidents, while others were unambiguously terrible ideas both at the time and in retrospect (avoiding any expansion ports on the mac ostensibly to save cost, despite the mac still being double the price and half the performance of the Amiga 1000 and comparing even worse price-and-performance-wise to the Atari ST, both of which had plenty). Any attempt to suggest that Jobs was skilled relies upon attributing psychic powers to him.</p><p>Of course, this is a wonderful story to tell a tech industry in the midst of a bubble. Elevate a non-technical guy in management for a tech company to a godlike status and claim that all his good choices were the result of skill and all his bad choices were good choices, thereby suggesting that the universe is orderly and that charismatic people have magic powers that allow them to excel in business without trying. It’s no wonder that the Jobs Hagiography is so popular: like the Prosperity Gospel, it promises monetary success and public adulation and moral justification to the masses while justifying itself by claiming that those who succeed were destined to do so while those who fail have only themselves to blame.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The thing about cultural niches is that they are created by and for ‘mass media’ as a novelty…]]></title>
            <link>https://medium.com/@enkiv2/the-thing-about-cultural-niches-is-that-they-are-created-by-and-for-mass-media-as-a-novelty-4e5853196ee3?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/4e5853196ee3</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 01 Dec 2015 14:39:40 GMT</pubDate>
            <atom:updated>2015-12-01T14:59:45.516Z</atom:updated>
            <content:encoded><![CDATA[<p>The thing about cultural niches is that they are created by and for ‘mass media’ as a novelty generator. Having an isolated group of people experimenting on the fringes of culture without the necessity of appealing to large numbers of people or dealing with expensive equipment means creating an alternate media universe with new and interesting ideas and techniques each with its own associated small audience, and cultural niches can have their ideas and parts of their audiences imported into the mainstream on a temporary basis in order to keep the perception of the mainstream ‘new’: whenever something gets imported, it seems alien and novel to mainstream viewers precisely because they have historically been unaware of or isolated from the cultural niche in which it is considered an inevitable and incremental step. By importing proven ideas from fringe groups, mainstream media creators get the best of both worlds: they can seem creative while ultimately being extremely conservative with investor money.</p><p>This particular way of looking at niche media isn’t new; at the latest, it dates back to the french situationist movement of the 50s and 60s (and specifically to The Society of the Spectacle, in which it is a central theme), although it’s probably older. I’m going to suggest that — at least since the 60s but probably starting earlier — this has been an explicit part of planning, rather than (as Debord suggests) a fully autonomous process inherent in appropriative capitalist media structures.</p><p>Niches come in a hierarchy of sizes, and these sizes are related to cost and audience — two factors that were a lot more closely correlated before widespread internet access made the marginal cost of expanded distribution drop precipitously. Nevertheless, distribution is not wholly free: distribution on ‘mainstream’ scales is expensive even on the internet, and while it’s cheaper than television and newspapers, it still justifies (for instance) the internet advertising ecosystem. Furthermore, there are often production costs that are essentially ultimately scaling costs: more professional-looking things often are considered more accessible or desirable by a larger audience, and professional things at minimum take more time and/or experience to create even when they don’t produce greater material costs (and this is the problem that people who create media for youtube run into: youtube isn’t charging them to upload videos, but at a certain point they feel like in order to expand their audience they need better quality cameras and microphones, makeup, lighting, and eventually professional actors and makeup artists and animation teams, which is how the Vlogbrothers video ecosystem became an insanely conventional-looking media establishment despite zero distribution costs).</p><p>Art-house films and experimental music, despite hipster cred, are great examples of niche media ecosystems. And, if you have familiarity with either, you can trace the influences of the niche forms into mainstream, as happens over and over. But, both of these are explicit niches. They aren’t so much ‘long tail’, particularly historically: film production was, until the advent of inexpensive high-capacity digital video cameras and video editing software, absurdly expensive even in its cheapest forms, and the same is true of both conventional acoustic instruments and pre-PC synthesizers of both analog and digital variety. You might instead cast experimental film and music as a kind of skunk-works, like Xerox PARC: get the smartest and most creative people together to make things, throw money at them, and never try to actually market the results because the real value is in which ideas and techniques you can appropriate later when they’ve become mature enough to be safe bets. There are similar kinds of skunk-works situations on different levels of niche-ness: the BBC radiophonic workshop was fundamental in the genesis of electronic music and was essentially a government-funded audio special effects studio; low-budget BBC TV shows in the 60s and 70s like Doctor Who and The Avengers were as influential as they were eclectic and despite being popular and having national or even international distribution their low budget nature made them less conservative: the cost of mistakes was low. Television in general was, once upon a time, a skunkworks for film, and public access television continues to be a testing ground for people looking to get into producing film or television. As an example of another level in this hierarchy, comic-book-based and SF-based films have become mainstream while westerns have become fringe — a complete reversal since the mid-70s, and one that allows time for the rich loam of gunslinger mythos to lie fallow and compost itself into a more fertile genre while formerly ignored and ridiculed genre fiction in the SF sphere injects its hard-won fruits and seeds into the mainstream, which, vampire-like, returns from the dead by sustaining itself on the blood of living subcultures.</p><p>The particular economic shift of internet distribution — wherein even if scaling up distribution has minimal marginal cost, scaling *out* distribution geographically has truly zero marginal cost barring the extra steps of translation — has meant that each culture operates as though it’s a media niche. Really, this isn’t very accurate in the scheme of things. Gangam Style was never niche: the South Korean music industry is huge and profitable and represents its own mainstream, and both the jpop and kpop industries are considered overly commercial and conservative to people who are in those countries, the same way that bubblegum pop is considered commercial and conservative in the united states. What’s happening is a greater-scale version of what often happens when import barriers are lifted: a niche group in one culture defines itself in part by bits and pieces of another culture’s mainstream. Just as the influx of american gangster movies into post-second-world-war France was the antithesis (and french identity the thesis) creating the synthesis of the french new wave movement in cinema and the influx of american science fiction films into post-war Japan was a major influence for japanese tokatsu/SFX fandom (and as how, earlier, the import of Disney cartoons spawned anime), americans latching onto jpop and british tv imports has created new subcultures. Gangam Style’s widespread familiarity outside South Korea is a slightly more extreme form of the same phenomenon that made Yellow Rose of Texas a huge hit in China, Frank Sinatra’s My Way a huge hit in Japan, Blueberry Hill big in Russia, Jerry Lewis in France, David Hasselhoff in Germany, and pretty much any other unexpectedly popular import. “Big in Japan” is literally a stock phrase in the music industry because the combination of good media relations between Japan and the english-speaking world with a boatload of subtle but complex cultural differences makes for a huge set of english-speaking acts who undergo unexpected success once exported to Japan. But, today, anywhere with widespread high-speed internet access has the same relationship to anywhere else with it that the United States and Japan had in the 1980s. Every piece of mainstream media has the capability of being exported and recontextualized and becoming “big in japan” in some unexpected place.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Novel UI systems have a lot of the same problems as other novel pieces of media.]]></title>
            <link>https://medium.com/@enkiv2/novel-ui-systems-have-a-lot-of-the-same-problems-as-other-novel-pieces-of-media-7d9e45ffa2c9?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/7d9e45ffa2c9</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 30 Nov 2015 16:26:47 GMT</pubDate>
            <atom:updated>2015-11-30T16:26:47.976Z</atom:updated>
            <content:encoded><![CDATA[<p>Novel UI systems have a lot of the same problems as other novel pieces of media. The existing widgets, even when they are objectively terrible, represent a familiar visual language to users — in the same way that samey blockbusters combine familiar franchises with familiar special effects, familiar story structures, familiar characterization cliches, and familiar forms of cinematography for an ultimately conservative work that is unlikely to lose money, and in the same way that bubblegum pop combines familiar artists with familiar rhythms and familiar harmonies to produce minor variations on a familiar style that is unlikely to be rejected for being too extreme. When a UI is big business and lots of money rides on it being usable for a wide audience, that UI will be conservative, and in the rare exceptions to that rule often we end up with something universally reviled (Windows 8, the MS Word ‘ribbon’ interface, Microsoft Bob, the Macintosh finder’s ‘galaxy mode’ from the early 90s, Google Wave, literally every UI change on Facebook or Tumblr). Because UI is a form of creative media that people have to use every day — an experimental UI for an important and widespread product is like having Steve Reich and Daphne Oram compose the soundtrack for a large supermarket chain.</p><p>However, since the situation is comparable to more traditional forms of media, we can borrow a bit of media’s solution. The solution to Hollywood sequelitis and horrible blockbusters is the slow and careful importing of ideas, techniques, and talents from experimental film, just as visually striking import giallo and the rise of auteur directors in the 60s and 70s revived the 50s slump in creative moviemaking (along with big names like Hitchcock grabbing talent and ideas from other fields like experimental animation — compare North By Northwest’s cinematography with that of Vertigo), and just as the constrained compositional environment of punk revived stagnant arena-rock (itself descended from blues- and folk-derived attempts to use experimental electronic hardware to inject vitality into overly commercial 50s rock/r&amp;b, itself an attempt to bring in new influences to revive a stagnant crooner-centric ecosystem, etc., going back long before Mozart). And, we certainly used to do this: PARC was so influential because they were an isolated group of geniuses quickly iterating on UI design. To some extent, we still do this: video games often have unusual UI ideas, most of which don’t work, and Alan Kay is still playing with UI innovation with Squeak. The thing is, for the most part, fringe UI designs haven’t gotten pulled into the mainstream since the early 80s, when “GUI” became synonymous with “Alto clone UI” and anything that didn’t use a mouse began to be considered as not ultimately related to UI.</p><p>Some UI experimentation continues, here and there. The biggest example of UI experimentation being pulled into the mainstream in the past five years or so is, shockingly, in text-based UIs, wherein conversational user interfaces based around messaging systems have begun approximating the kinds of features and nuances that command line interfaces in the UNIX world have shipped with since the late 70s. SIRI is a cross between Eliza and Autocorrect, trying blindly to approximate a cross between ZSH and Google while remaining fixated upon being accessible to new users, and it’s an interesting enough experiment; special-purpose slack and twitter bots are more innovative because the cost of failure is low.</p><p>My recommendation: release smart people in the UX field into a situation where they can iterate quickly on interesting projects of their choosing, none of which will ever be marketed. Then, get a couple canny con-artist types like Steve Jobs to drop in, take a look at the end result of five or ten years of iteration, and distribute a simplified version to the mainstream.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[You’re complaining that a free VR device came with your newspaper, even though by no means do you…]]></title>
            <link>https://medium.com/@enkiv2/you-re-complaining-that-a-free-vr-device-came-with-your-newspaper-even-though-by-no-means-do-you-6e0338be351e?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/6e0338be351e</guid>
            <category><![CDATA[virtual-reality]]></category>
            <category><![CDATA[google]]></category>
            <category><![CDATA[journalism]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 10 Nov 2015 13:14:56 GMT</pubDate>
            <atom:updated>2015-11-10T13:14:56.421Z</atom:updated>
            <content:encoded><![CDATA[<p>You’re complaining that a free VR device came with your newspaper, even though by no means do you need to use it in order to gain the same enjoyment you usually do out of your newspaper, because it reminded you that computers exist? I hate to think of what will happen when you discover that the New York Times has had a tech section for thirty years.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I’m not sure that decision anxiety is the sole or even primary source of ‘prestige television’.]]></title>
            <link>https://medium.com/@enkiv2/i-m-not-sure-that-decision-anxiety-is-the-sole-or-even-primary-source-of-prestige-television-e9d4d7632422?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/e9d4d7632422</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 19 Nov 2015 22:27:26 GMT</pubDate>
            <atom:updated>2015-11-19T22:27:26.056Z</atom:updated>
            <content:encoded><![CDATA[<p>I’m not sure that decision anxiety is the sole or even primary source of ‘prestige television’. After all, a shift toward a preference for binge-watching (and the type of show that gets better when marathonned rather than getting worse) dates to the first instances of widespread time-shifted home viewing. Buffy replaced Kolchak in the public consciousness because Kolchak was too formulaic to watch in season-long chunks and networks wanted to hype new seasons with marathon reruns of previous seasons — and because Buffy was getting released on DVD. Netflix and other streaming services upped the ante in a UI way, but not via poor UI design: Netflix doesn’t update their catalog every time an episode comes out but instead every time a season comes out (sometimes with a multi-year delay), so binge-watching is the only way to watch that doesn’t involve either using another service that updates faster or forcing yourself to keep to a weekly schedule; however, unlike buying a DVD boxed set, queuing up a series on Netflix doesn’t cost any more than not doing so. Thus, a mainstream audience learned what the anime bootleg fansub community learned ten years earlier: when you can watch a whole season of a show in one sitting with no penalty for dropping it in the middle, doing so is for a large subset of shows — those shows that gain rewatch value by focusing on complex, intricate, and detailed plots and character arcs rather than going for a casual prime-time-TV audience with formulaic structures, running gags, and ripped-from-the-headlines topicality — will be far more enjoyable than watching an episode a week.</p><p>You’re absolutely right about Netflix’s UI, though. It’s awful.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[This is not ‘no UI’ — it’s ‘text-based UI’.]]></title>
            <link>https://medium.com/@enkiv2/this-is-not-no-ui-it-s-text-based-ui-c4e5991b7edb?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/c4e5991b7edb</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 19 Nov 2015 14:06:13 GMT</pubDate>
            <atom:updated>2015-11-19T14:06:13.109Z</atom:updated>
            <content:encoded><![CDATA[<p>This is not ‘no UI’ — it’s ‘text-based UI’. Human written language is a set of technologies that have been under active, heavy development for four thousand years — compared to GUIs, which were under active and heavy development at Xerox PARC for about five years and have barely changed since. I agree that text-based UIs are the future — the competent ones among us never switched away from them in the first place, because they have features and nuances that GUIs would not be able to compete with even had they been truly under active development for the forty years of their existence.</p><p>However, this doesn’t mean that traditional UI concerns are irrelevant to text-based UIs, or that there are no special UI concerns to consider. It’s very easy to screw up a text-based UI — compare the MS-DOS command shell with a modern UNIX shell like zsh, and the vast gulfs of difference are obvious; even so, MS-DOS is by far not the least competent text-based UI in existence.</p><p>Conversational interfaces, by catering almost exclusively to new users and eschewing efficiency, nuance, and a rich feature set in favor of a shallow learning curve, are almost universally unusable for genuinely complex real-world tasks and gain their popularity from the novelty element of a computer behaving like a person. A well-designed conversational interface would eventually, in the hands of a habitual user who has become comfortable with it, resemble a traditional command-line interface: it would efficiently execute unambiguous and richly expressive queries while making use of shortened mnemonic forms of those queries. However, the novelty of a conversational interface to a new user depends upon a cynical assumption about that user’s willingness and ability to learn new skills: the conversational interface must accommodate a user who knows nothing and has made no effort to learn, and to interpret ambiguous requests as their simplest possible evaluation — to complain about the ambiguity or request it to be resolved would be to suggest the user learn a <em>programming language</em> and to interpret any resolution other than the simplest would be to suggest that the system is either unreliable (like a human) or sensitive to subtle details (like a programming language). Assuming users are stupid and unwilling to learn how to perform simple tasks is part of good UI design in GUIs, but it works against you even moreso in text-based interfaces; conversational interfaces that do not take advantages of UI advances in command line interface design can never become any more than toys.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The hidden benefits of NaNoGenMo]]></title>
            <link>https://medium.com/@enkiv2/the-hidden-benefits-of-nanogenmo-dd91193bda6?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/dd91193bda6</guid>
            <category><![CDATA[writing]]></category>
            <category><![CDATA[journalism]]></category>
            <category><![CDATA[tech]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 08 Oct 2015 17:11:53 GMT</pubDate>
            <atom:updated>2015-10-08T17:11:53.566Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p>On November 1st of 2015, NaNoGenMo begins its third year. It’ll be the third year that I’ve participated, and the third year that it’s spawned articles in legitimate paper magazines and newspapers, none of which are, unfortunately, particularly distinct from the coverage of the story generator Brutus in 1999 in the New York Times or similar projects from years prior.</p><p>Media coverage seems to circle around the spectre of wholesale automation of authorship the way that hapless space-ships circle around a black hole. (Because we, as a community, have an interest in corpora — the ability to access and analyse data makes inserting variety into generative writing convenient — <a href="https://github.com/dariusk/NaNoGenMo-2014/issues/92">we have kept track of these articles</a>.) Perhaps, being written by journalists, these articles are justified in having a bit of a hysterical bias. After all, certain classes of news stories are already being written mostly by software, and fear-mongering about automation has been a lucrative staple of the press since the invention of the automatic loom.</p><p>However, despite its universality, the narrative of automation of authorship is a poor lens with which to look at the current state of generative text. Some forms of journalism are trivially automated, and these are precisely the kinds that are automated. However, the variety of journalism that journalists are increasingly reaching for (beautiful, literary longform nonfiction, which thrives on the web because of the comparatively low cost of distribution and which stands out heavily from the landscape of low-quality under-considered short posts) is both far from the grasp of the current generation of text generators and far from the aim of NaNoGenMo in specific.</p><p>NaNoGenMo produces, quite consistency, a flurry of extreme creativity and a wide variety of aims, styles, and implementation techniques; many people start several entries with extremely different approaches and goals, and many people do not end up producing a novel-length text despite the utterly trivial requirements, because their amazingly creative techniques were unable to produce a novel whose originality they could be proud of. In its first year, we had (among other entries) a novel composed of a supercut of similar tweets, a novel composed of a supercut of Homeric fight scenes, and a mystery novel composed of the belabored meanderings of Alice and Bob in a labyrinthine house; in its second year, we got a deeply atmospheric comic book composed by pulling images from flickr, post-processing them, and superimposing thematically related lines from detective novels, as well as a wonderful book-length piece of asemic writing. This year — who knows?</p><p>Explicitly experimental techniques appear to produce the best results. This makes sense — experimental techniques tend to be very well-defined, and the results of experimental techniques in literature as executed by human beings tend to be dominated by the attributes of the techniques themselves (meaning that, were a machine to execute those same techniques, the results would be superficially very similar). We haven’t progressed to a level of understanding of the craft of writing that allows us to automate good, readable, page-turning fiction — and I doubt that even an author of best-selling potboilers has such an explicit model. As a result, our community is less Clairion and more Oulipo. Nevertheless, each year, we produce works that inch closer and closer to readable. We produce vast novelty with the (eventual) aim of mundane novelty.</p><p>As a result, it may be most sensible to consider NaNoGenMo to be an amateur expedition into the greater control and quantification of literature.</p><p>The Royal Society of London in the 17th and 18th centuries independently rediscovered many of the things already known to professional craftsmen of the physical sciences like doctors, midwives, miners, and sailors; nevertheless, by aiming to measure and control their experiments, they became the vanguard of systematic knowledge of the physical world, which made later developments easier to isolate and demonstrate. NaNoGenMo can be seen as doing the same for the craft of literature: by producing machinery that consistently executes particular literary techniques, we can produce large amounts of stylistically consistent text; we can perform systematic mutations of text; we can isolate important elements by seeing how text affects people with a level of purity and consistency and volume not possible with human-written text.</p><p><a href="https://groups.google.com/forum/#!topic/generativetext/hMy90EyKVrA">We are also holding engineering discussions about things like plot and style.</a> We’re determining whether, given some N major plot events, any ordering of those N events can be made sensible via transitions. We’re determining whether macro-level plot beats produce a greater impression of novelty than sentence- and paragraph-level variation in structure, and whether either of them produce a greater impression of novelty in human readers than variation in word frequency. We’re trying to figure out how much novelty is not enough and how much is too much in the context of texts of different lengths. We’re talking about how to engineer the eliza effect in readers. We’re figuring out whether or not readers can identify descriptive fluff, and whether or not they care — and whether or not Ray Chandler was lying about how he structured detective novels, whether the Hero’s Journey really is too vague, and whether the beats in Save the Cat can truly produce compelling stories with minute-by-minute granularity at a feature-film scale.</p><p>You can make the argument that this will eventually lead to the possibility of fully automated journalism. But, being possible is not a particularly compelling argument for it to be likely. Even relatively crappy chess computers can now completely outclass chess grand-masters — and so we have augmented chess, wherein a human grand-master works hand in hand with a chess-playing machine to play against another grand-master-and-machine tag-team. Items like furniture are much better manufactured by machine (in terms of quality, price, and environmental impact), and yet we pay much more for artisanal furniture made by obsolete and wasteful processes because we value the idea of a human being doing something that doesn’t need to be done and doing it the hard way.</p><p>In the same way that there is a market for artisanal wicker chairs and artisanal bread, there will probably continue to be a market for artisanal journalism — and for the rest of us, human journalists may become symbiotes joined at the hip with machines that automate the less interesting parts of the job. We already have some such mechanisms — spell check, grammar check, layout tools, note-taking and mind-mapping and automatic summarization tools. Tools for augmenting creativity in authors aren’t new either — cut-ups pre-date digital computers, as do markov chains and bibliomancy, and oblique strategies are now half a century old. Cutups and markov chains actually produce text for you, to which you must act as editor; but all these ‘writing machines’ that augment creativity do so by acting as a source of semantic randomness, much as mind-warping drugs do. We accept the use of all these mechanisms already — we don’t criticize Thom Yorke or William S. Burroughs for using cut-ups any moreso than we criticize John Lennon or Hunter S. Thomson for using LSD. Automatic methods for the production of text will, if they gain acceptance among writers, gain as much acceptance among readers as spell check and LSD.</p><p>NaNoGenMo probably won’t produce the future journalism-symbiote I describe, in the same way that NaNoWriMo has never produced the great american novel; but, just as NaNoWriMo produces novelists (and published novels), NaNoGenMo will produce some of the figures and technologies and domains of collective knowledge and culture that will inform text generation in creative fiction in the near future.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A second issue with the ‘uber for…’ model is that it’s a tax evasion scheme that also, in the minds…]]></title>
            <link>https://medium.com/@enkiv2/a-second-issue-with-the-uber-for-model-is-that-it-s-a-tax-evasion-scheme-that-also-in-the-minds-f0e49937cdad?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/f0e49937cdad</guid>
            <category><![CDATA[work]]></category>
            <category><![CDATA[uber]]></category>
            <category><![CDATA[taxi]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 21 Oct 2015 13:35:59 GMT</pubDate>
            <atom:updated>2015-10-21T13:35:59.143Z</atom:updated>
            <content:encoded><![CDATA[<p>A second issue with the ‘uber for…’ model is that it’s a tax evasion scheme that also, in the minds of investors and credulous media people, transforms a service company into a tech company. (Nevermind that there have been taxi services with Uber-style smartphone apps for hailing cabs since before Uber came around who, of course, got comparatively little out of that because they quite sensibly didn’t consider themselves to be a tech company.)</p><p>The formula is stupid, simple, and thus far pretty reliably successful as far as literally anything in the domain of startups goes: take an existing service, fire all the employees and replace them with untrained contract workers, spend an afternoon on a smartphone app or mobile site, and call yourself a tech company. Since the tech involved is extremely simple — your fourteen year old nephew can do it after school — this is sort of a brave re-branding. But, non-tech companies in the valley don’t get ten billion dollar valuations, do they? And if you have a ten billion dollar valuation, who cares if you make a profit?</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[But, again, what reason do we have to believe that other humans have interiority if we ignore the…]]></title>
            <link>https://medium.com/@enkiv2/but-again-what-reason-do-we-have-to-believe-that-other-humans-have-interiority-if-we-ignore-the-14858c27d7b5?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/14858c27d7b5</guid>
            <category><![CDATA[dogs]]></category>
            <category><![CDATA[anthropomorphism]]></category>
            <category><![CDATA[psychology]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 09 Nov 2015 13:43:42 GMT</pubDate>
            <atom:updated>2015-11-09T13:43:42.902Z</atom:updated>
            <content:encoded><![CDATA[<p>But, again, what reason do we have to believe that other humans have interiority if we ignore the indications of interior life that dogs share with humans? Humans produce more complex communications, but those communications are not necessarily better explained by interiority than by mere generative complexity.</p><p>This is not to say that I don’t believe humans feel pain, but instead, to say that if *you* believe that humans other than yourself feel pain then you should probably also believe that dogs feel pain, since there is roughly equal evidence; likewise, with intentionality, we can estimate it by looking at planning effectiveness. The closer a set of behaviors is to being the ideal path toward some goal, the more likely it is that those behaviors were planned by a goal-persuing system. Proving intentionality with a 100% success rate is not possible, just as proving interiority with a 100% success rate isn’t possible: a system with strong intentionality that is working off flawed axioms or flawed data or that is very limited in how many steps it can plan ahead will be almost indistiguishable from a system that performs behaviors semi-randomly based on simple rules without memory. But, communication is neither necessary nor sufficient to prove either interiority or intentionality: after all, limping and yelping are, effectively, communication insomuch as they are behaviors that provide information to humans and other animals about how likely the dog is to be in pain, and yet we can ignore those signals based on the assumption that all attribution of inner state to non-human animals is pure anthropomorphism.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The origin of many of our most elaborate models of corporatism, advertising, and how these things…]]></title>
            <link>https://medium.com/@enkiv2/the-origin-of-many-of-our-most-elaborate-models-of-corporatism-advertising-and-how-these-things-393e461e5996?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/393e461e5996</guid>
            <category><![CDATA[dismaland]]></category>
            <category><![CDATA[disney]]></category>
            <category><![CDATA[big-stories-matter]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 15 Sep 2015 15:06:05 GMT</pubDate>
            <atom:updated>2015-09-15T15:06:05.570Z</atom:updated>
            <content:encoded><![CDATA[<p>The origin of many of our most elaborate models of corporatism, advertising, and how these things infiltrate culture is — ironically enough — also the proximate origin of the very practices that theme parks embody: the situationist movement in Paris. They were equally concerned with modeling advertising and its subversion and with imagining a future urbanism where a post-scarcity city would see its primary goal as providing citizens with interesting and entertaining experiences.</p><p>The situationists would say that we can only ever win temporarily: the spectacle sees those things that subvert it, consumes them, and allows the defanged and sanitized symbols of that very subversion to become a part of itself. Just as punk was stripped of its ethos, just as Apple took an anti-consumerist minimalism and turned it into a reason to buy more things, Disney and its cohorts will find anything that opposes them and wear its skin. Nevertheless, we can continue to subvert. The situationists were marxists — they believed that capitalism would collapse under its own weight, and (presaging accelerationism) believed that constant subversion would quicken the fall of the spectacle by bloating it.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[To be honest, the closest thing to an interest feed as you describe it is tumblr — not because it…]]></title>
            <link>https://medium.com/@enkiv2/to-be-honest-the-closest-thing-to-an-interest-feed-as-you-describe-it-is-tumblr-not-because-it-ebb37f4e4cc6?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/ebb37f4e4cc6</guid>
            <category><![CDATA[instagram]]></category>
            <category><![CDATA[social-media]]></category>
            <category><![CDATA[life-hacking]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 09 Oct 2015 12:55:42 GMT</pubDate>
            <atom:updated>2015-10-09T12:55:42.288Z</atom:updated>
            <content:encoded><![CDATA[<p>To be honest, the closest thing to an interest feed as you describe it is tumblr — not because it doesn’t try to be a ‘social network’ but because it fails so hard at being a bidirectional communication medium.</p><p>Like twitter, tumblr has asymmetric following and a reblogging feature that constitutes most of the content. Unlike twitter, most active users keep separate accounts for separate topics. While you are still *following* *accounts*, it’s more like following one person or group’s curation of a topic than it is like following a person, and some portion of the network actually only pays attention to tags (meaning that they don’t follow anyone and don’t look at their feed, but instead watch a topic-centered feed via the search function). So it’s twitter without character limits.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Gelman’s characterization of his opposition is more than a little reductive.]]></title>
            <link>https://medium.com/@enkiv2/gelman-s-characterization-of-his-opposition-is-more-than-a-little-reductive-f72b30d77350?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/f72b30d77350</guid>
            <category><![CDATA[pubic-policy]]></category>
            <category><![CDATA[social-science]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 06 Oct 2015 12:58:40 GMT</pubDate>
            <atom:updated>2015-10-06T12:58:40.820Z</atom:updated>
            <content:encoded><![CDATA[<p>Gelman’s characterization of his opposition is more than a little reductive. In brownian motion, the particles are wholly passive. However, the varieties of stimuli that are being studied with respect to their effect on human behavior are, in fact, primarily human-produced and can be modeled as a form of communication wherein ideas are spread subtly without analysis. It’s not controversial that this kind of communication (and this kind of spread) occurs within media, wherein we have dated archives showing various elements (arguably without rational basis) growing and shrinking in popularity in accordance with power laws; why should we believe that people do not communicate this way when they are not being recorded, or when they are outside the silos of media production?</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A big problem here is that advertising — particularly advertising on the internet (by which I mean…]]></title>
            <link>https://medium.com/@enkiv2/a-big-problem-here-is-that-advertising-particularly-advertising-on-the-internet-by-which-i-mean-3c0e12a5fccb?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/3c0e12a5fccb</guid>
            <category><![CDATA[media]]></category>
            <category><![CDATA[advertising]]></category>
            <category><![CDATA[journalism]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 29 Sep 2015 13:04:15 GMT</pubDate>
            <atom:updated>2015-09-29T13:04:15.586Z</atom:updated>
            <content:encoded><![CDATA[<p>A big problem here is that advertising — particularly advertising on the internet (by which I mean both web advertising and email advertising) — has already poisoned the well. The ideas you propose about vetting ads, about keeping up quality standards for types of ads, and about trying to ensure appropriate targeting are old ideas and already widely adopted — but each of them, over time, has been subverted and worn down, because advertising (since its effectiveness per impression is exceedingly low in the best of cases and almost nil in the average case) almost always becomes a race to the bottom.</p><p>Google’s entire core business model is the automatic targeting of ads along with strong quality restrictions; adsense is the biggest web ad provider in the world, and doesn’t allow advertising with any of the qualities you mentioned under a metric for bad ads. Nevertheless, outside of AdBlockPlus having an option to avoid blocking only google-hosted plain-text ads, most ad blockers still block everything coming out of adsense.</p><p>The suggestion that users will interact with a piece of advertising to indicate its quality and relevance is also pretty questionable. After all, all adsense-served ads have a button for reporting low-quality or non-relevant ads. But, years of dealing with ads that claim to have such buttons but who actually use them to steal metrics and redirect users to different ads have trained users not to trust anything put onto a page by a third party.</p><p>Even if large advertising organizations were to sign on for the kinds of restrictions you propose (and recall that Google already essentially implements all of them), that won’t really discourage ad blocking. Well-behaved ads aren’t a problem, and people who host ill-behaved ads are doing so knowingly and intentionally, because they don’t care about user experience. You can’t police them, because they’re already too shady to care about what you think and aren’t afraid to ruin advertising for everyone; they are the people hosting fake versions of the facebook login page and redirecting you to twelve different ‘around the web’ links in frames whenever you click ‘sign in’. They’re the people who are buying zero days from the russian mafia and selling them to the NSA at a 700% markup. They’re the reason that you can’t use just one ad blocker; in order to block enough ads to matter, you need to run three different ones plus an anti-tracking extension, and maintain separate whitelists for each. When advertising as a revenue model is dead, they won’t care because they will have moved on to killing kittens and selling their pelts as synthetic wool.</p><p>The biggest issue with this article is not the argument that advertising can be saved; after all, a lot of smart people have thought that in the past, and the things you propose to save it have been proposed and implemented at scale by people who knew what they were doing. Instead, the biggest issue is the false dichotomy between advertising and paywalls. Paywalls are one of maybe ten or twelve different alternative monetization strategies, and they have a bad reputation for a good reason. I recommend you do a little bit of research into the variety of alternatives. Ad hosting and paywalls are old models and remain dominant because of inertia, but they are poor solutions in terms of effectiveness, returns, and increasing customer confidence.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I’d be interested in seeing how ebook sales trends match up with the shift from epaper to OLED/LCD…]]></title>
            <link>https://medium.com/@enkiv2/i-d-be-interested-in-seeing-how-ebook-sales-trends-match-up-with-the-shift-from-epaper-to-oled-lcd-3b4e0849bec5?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/3b4e0849bec5</guid>
            <category><![CDATA[ebooks]]></category>
            <category><![CDATA[books]]></category>
            <category><![CDATA[publishing]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Mon, 28 Sep 2015 14:01:20 GMT</pubDate>
            <atom:updated>2015-09-28T14:01:20.309Z</atom:updated>
            <content:encoded><![CDATA[<p>I’d be interested in seeing how ebook sales trends match up with the shift from epaper to OLED/LCD displays on ebook readers. After all, the first few generations of Kindles and Nooks had epaper display — which in addition to having good battery life, mimics the properties of a paper book quite well; current generations (particularly post-ipad) have luminescent displays with color and faster refresh rates and are essentially just tablets. E-paper displays, because they lack back-lighting, are ideal for before-bed reading; because of their slow refresh rate, they aren’t ideal for anything *other* than reading full pages of text. By introducing tablet-style backlit displays, the new dedicated e-readers may be driving people who would otherwise use them for before-bed reading back to paper, while pushing the rest of their users toward non-book content.</p><p>(I’m also wondering if these trends you’ve mentioned extend outside of the Amazon-and-BN for-profit-ebook universe. Do the same trends exist in, say, download rates for epub files on Project Gutenberg? What about archive.org, or the pirate bay? It may be that prices or circumstances are lowering the rates at which people download ebooks that they need to pay for — and a variety of things could cause this, ranging from DRM policies to perceived reliability of the devices. After all, if you own a Kindle and all the books you own exist only on it with no capacity for backup, then bricking it would mean losing your entire library; it then makes more sense to buy the books on paper or to pirate them, since in the former circumstance it’s more difficult to lose all of them and in the latter circumstance it’s not difficult to back them up or get them again later.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I’m not sure I buy that this is the result of increased usability.]]></title>
            <link>https://medium.com/@enkiv2/i-m-not-sure-i-buy-that-this-is-the-result-of-increased-usability-a9a1f9eab97d?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/a9a1f9eab97d</guid>
            <category><![CDATA[mobile]]></category>
            <category><![CDATA[user-experience]]></category>
            <category><![CDATA[africa]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 09 Sep 2015 13:16:24 GMT</pubDate>
            <atom:updated>2015-09-09T13:16:24.958Z</atom:updated>
            <content:encoded><![CDATA[<p>I’m not sure I buy that this is the result of increased usability. Kids learned BASIC by trial and error without consulting the manuals on 80s home computers. The learning curve is lower if literacy is not a prerequisite, which makes the rate at which motivated children learn seem more striking.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Peter Watts and p-zombies]]></title>
            <link>https://medium.com/@enkiv2/peter-watts-and-p-zombies-bbe750aaca8c?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/bbe750aaca8c</guid>
            <category><![CDATA[artificial-intelligence]]></category>
            <category><![CDATA[philosophy]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 20 Aug 2015 16:15:12 GMT</pubDate>
            <atom:updated>2015-08-20T16:15:12.783Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p>I was surprised, upon listening to a <a href="http://auticulture.com/liminalist-25-a-micro-organism-of-meaning-with-peter-watts/">two</a> <a href="http://auticulture.com/peterwatts2/">part</a> interview with Peter Watts, to find him tentatively supporting Chalmer’s positions on qualia and the hard problem. Part of the reason is that Watts is a(n ex-) scientist with a background in biology and neuroscience, and also both very intelligent and spectacularly good at not avoiding unpleasant trains of thought. The other reason I was surprised is that I read <a href="http://www.rifters.com/real/Blindsight.htm">Blindsight</a>, and interpreted it as an amazingly good takedown of the <a href="http://rationalwiki.org/wiki/Philosophical_zombie">Chalmers philosophical zombie idea</a> along the same lines as <a href="https://ase.tufts.edu/cogstud/dennett/papers/unzombie.htm">Dennett’s</a>.</p><p>This essay will contain spoilers for Blindsight, probably. Also, spoilers for the epistemology of Chalmers and Dennett. If you don’t like to learn things in orders not officially sanctioned by the establishment, I recommend you at least read Blindsight — it’s a great read, and Watts has been nice enough to put it online for free.</p><p>Chalmers presents the idea of consciousness as indicated by qualia — a representation of the subjective feeling of the outside world. His position, in my understanding, is that subjective feeling is a more difficult thing to model than other properties of the world. While I’m not sure about Chalmers himself, other people have used this idea that qualia is a “hard problem” as an excuse for reintroducing cartesian dualism into the world of epistemology — by claiming that qualia is so difficult to model that not even straight-up neurons can model it, and thus we need to bring in <a href="http://rationalwiki.org/wiki/Quantum_consciousness#Roger_Penrose">quantum nanotubules</a> or some other structure as a stand-in for the soul.</p><p>A lot of people have been suspicious of the idea of qualia. After all, isn’t a representation a representation? Isn’t a subjective representation just a second-order representation? I agree with Dennett when he argues that it’s an unnecessary complication, with no evidence for it. I would furthermore argue that it’s a matter of preferring a mysterious answer to a mysterious question: complex behavior can be difficult to predict not because it’s irreducible — not because each piece is complex — but because lots of simple pieces combine in a complex way, but there’s a general tendency among people to try to keep emotional parity with explanations (mysterious things need to be explained in a way that retains the mystery or else you’ve lost the mystery; negative events can’t be explained as an interaction between purely positive intentions, or else where did the negative essence come from?) but ultimately reality doesn’t deal in emotional valences and so feelings of mystery do not need to be conserved.</p><p>Chalmers came up with a fascinating thought experiment in order to “prove” the existence of qualia. He suggested the idea of a ‘philosophical zombie’: a person indistinguishable from a regular person, but without qualia. Because qualia cannot be tested for, this person would be completely indistinguishable from a regular person.</p><p>Somehow, a lot of otherwise intelligent people thought that this was a good argument. I can’t see the invisible dragon in my garage, and therefore it must exist.</p><p>In Blindsight, Watts plays with a few variations on the philosophical zombie idea. He puts forth the idea of vampires being said to lack qualia — along with other cognitive anomalies that are of benefit to a humanoid with a very different position in the food chain. Certain optical illusions and cognitive biases don’t work on them. They have some differences in social behavior. They are largely lacking in empathy, without having the problems with impulse control that tend to be comorbid with lack of empathy in human sociopaths. A vampire, along with a split-brain patient, a personality collective, a person with extreme sensory modifications, and some other various neurodivergents take a space trip to meet a colony of intelligent starfish/squid-like aliens that are determined to have no qualia either and no sense of identity.</p><p>But, the ideas about qualia don’t line up here. I assumed it was on purpose.</p><p>Rather than ‘qualia’, each of these neurodivergent characters has some facility or attribute missing or strongly modified that is very clearly defined and very clearly not the same as qualia. And furthermore, each of these characters has very different behaviors based on their divergence from the norm. (This is along the same lines as the Rifters trilogy, particularly <a href="http://www.rifters.com/real/STARFISH.htm">Starfish</a> — we’re basically talking about circumstances where people who are psychologically and neurologically maladapted to normal life in a normal society end up being very well adapted to a fundamentally different environment.)</p><p>In other words, it’s a strong argument against philosophical zombies.</p><p>In the end of Blindsight, our protagonist gets back within radio range of Earth and can tell it’s been taken over by the vampires. Because Earth had stopped broadcasting music and entertainment, in favor of utilitarian communications. The vampires aren’t philosophical zombies, because they can be distinguished from humans. Because the particular kinds of things that they don’t experience lead them to live in a more utilitarian manner.</p><p>Indeed, no novel could deal with philosophical zombies. Because, by definition, philosophical zombies could not be distinguished from normal people. A novel about philosophical zombies could not be distinguished from a novel with no philosophical zombies in it.</p><p>Now, the argument for qualia is that, while human beings can experience something through their senses (like the color green), that experience cannot be identified in the brain itself. There is no neuron for ‘green’, and even if there was, the neuron itself wouldn’t be ‘green’ or contain the concept of ‘green’.</p><p>This argument has a handful of big flaws, some of which have been dissected elsewhere, so I’m going to dispatch it as efficiently as possible. First off, while some things do seem to have dedicated neurons (this is the ‘Grandmother Neuron’ model), most things don’t — however, this is not terribly unusual; we are very accustomed to another system for modeling the world where some configurations of state have single symbols and others have sets of meaningfully interconnected symbols: language. The word ‘green’ is not necessarily green — in fact, it might be red — and does not contain the concept of green, but instead gains its meaning from its relationship to other things. Ultimately, we can say that it gains real meaning by being in a relationship with other symbols in a manner that represents some configuration of the outside world as perceived through some people’s sensory apparatus, and gains utility insomuch as it allows us to communicate and make predictions. However, we can have syntactically meaningful configurations of symbols that could not have any semantic meaning — the colorless green ideas sleep furiously — or syntactically and semantically meaningful configurations of symbols that could not represent our universe — maxwell’s demon mounted the pink unicorn’s dragon-skin saddle and rode off at six times the speed of light in order to find some anti-entropic material and transmogrify it into orgone. Since language does this, there’s no reason for the brain to be incapable of it; since the brain makes language, the brain <em>must</em> be capable of doing it. It’s also not mysterious — even toy languages with heavily simplified grammars designed for computers to manipulate can do thing kind of thing (think RDF, or PROLOG).</p><p>As someone who has a background in biology and neurology, who works with words and language professionally, and who thinks deeply and clearly about most things, I would expect Watts to make these same judgments. If he has a counterargument in favor of qualia, I’d like to hear it. But, my general position is that to the extent that something that behaves similar to qualia exists, it is symbol manipulation, and to the degree that something like consciousness exists, it is something like self-simulation.</p><p>(Originally posted <a href="http://firstchurchofspacejesus.blogspot.com/2015/08/peter-watts-p-zombies.html">here</a>)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Interacting with Fiction]]></title>
            <link>https://medium.com/@enkiv2/interacting-with-fiction-160350399934?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/160350399934</guid>
            <category><![CDATA[fiction]]></category>
            <category><![CDATA[interactive-fiction]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 12 Aug 2015 22:22:00 GMT</pubDate>
            <atom:updated>2015-08-12T22:22:31.796Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p><em>This essay may be disorganized. Treat it as a brain dump on the material, rather than a serious analysis.</em></p><p>I’d like to discuss a few different kinds of interactive fiction, coming from different traditions and with different attributes. I’d like to discuss how the forms themselves play with ideas about constraint and agency, and how treating them seriously might change the way we think about fiction and fictional worlds. I’d also like to discuss how each of these subverts certain ideas about interactive fiction taken from non-interactive fiction, and make connections between these forms and other related forms that I haven’t seen made due to accidents of history and geneology.</p><h4>Dramatis Personae</h4><p>I’d like to introduce our fictional forms, along with their attributes, an exemplar of each form, and a few other forms that bear similarities.</p><p><strong>Classic IF</strong>: Also called the ‘text adventure’ genre, Classic IF (which I will use interchangably with ‘IF’ in this essay) is written fiction in the form of a computer program that can be interacted with via free-form text input. The exemplar I choose is Collosal Cave Adventure. Usually, when people talk about ‘interactive fiction’, they mean this. Most of the attributes of classic IF carry over into the ‘point and click adventure’ genre, because historically, most creators of point and click adventures started out in text adventures; I am treating the ability to click on any object in a crowded scene to be of the same class of player agency as free-form text input for the purposes of this essay and using IF to refer to both forms, for reasons that will become clear in the next section. Genre conventions in classic IF include difficult puzzles and a stance of habitual contempt for the player. Player habits developed by this form include exhaustive searches of possibility space (picking up all objects, trying all verbs, clicking everywhere on the screen).</p><p><strong>Visual Novels</strong>: Also called ‘VNs’, visual novels consist of sequences of scenes interspersed with player choices. Visual novels differ from classic IF in that player choices are strictly limited — typically no more than four options are ever given, these options are clearly presented to the user (no free-form text input), and the options chosen almost always cause meaningful narrative changes. If classic IF has a maze structure, VNs have a tree structure. I’ve chosen as an exemplar of the form <a href="http://store.steampowered.com/app/331470/">Everlasting Summer</a>, because it’s free &amp; contains many of the genre-typical attributes and features. Genre conventions include plotted routes based on romantic pairings (being associated romantically with a particular character will give you a very different sequence of choices and events than with another character) and framing devices involving time travel. Player habits include re-playing in order to play through all possible routes (or at least, get all possible endings). Many recent twine games are similar in structure to visual novels, and so I would classify them the same way; while some <a href="https://en.wikipedia.org/wiki/Full_motion_video">FMV games</a> are best classified as part of the point and click adventure genre, many are better grouped with VNs.</p><p><strong>Wiki-based Choose Your Own Adventure stories</strong>: While these are not typically considered in essays like this, I think they add several interesting dimensions of possibility. My chosen exemplar is the <a href="http://infictive.com/Wiki_Adventure">Infictive Research Wiki Adventure</a>. Wiki adventures have a primary method of play similar to visual novels, but differ in that players can modify scenes and options.</p><p><strong>Fan work</strong>: Here is where we get a bit meta. Fan work, also called doujinshi, is the blanket term for any creative work related to a franchise not made by the franchise license holders. If we include fanon in this definition, we can classify it as a genuine interaction with a static fictional world that can result in apparent mutations to that fictional world. My exemplar is the <a href="http://reddit.com/r/fantheories">fan theories subreddit</a>.</p><p><em>A note on our characters</em>: I have avoided classifying the behemoth of triple-a games as part of interactive fiction because in modern high-budget games, gameplay mechanics and visual sophistication often take priority over storytelling, and to the extent that storytelling is done it is entirely non-interactive. Unless the player character can meaningfully change the story being told (in a more complex way than winning or losing) and the story being told takes a prominent role in the experience, I would not classify it as interactive fiction. As far as I’m aware, the only recent triple-a game franchise to meet these criteria as well as the least suitable VN has been Mass Effect; however, that franchise also struggled with a percieved betrayal of the fanbase’s expectation for meaningful interaction with the fictional world during the end of the final game. Because our focus is on agency and constraint in interactive storytelling, my position is that games that allow the player character free and detailed movement in 3d space (or indeed 2d space) are, generally speaking, providing levels of agency superfluous to the goal of storytelling and potentially directly counter to it. The fact that these games often mimic the styles of non-interactive forms of storytelling like film for their storytelling elements while having primary gameplay mechanics be of no use during designated storytelling portions indicates that storytelling and gameplay are considered to be separate domains potentially at odds in this kind of game, while <em>the genres I am focusing on have gameplay elements that directly interact with the structure of narrative</em>.</p><h4>Agency and meta-agency</h4><p>In classic IF, the player is in control of a player character. His control is, genrally speaking, limited to physics — he can control the player character’s geographical location in the game world, pick up and manipulate objects, and have limited interaction with characters, based on the limits of the command parser and the variety of interactions planned by the game designer. I call this physical and limited-conversational agency: the player can manipulate the physical state of the game and initiate pre-scripted entire conversations.</p><p>In a VN, the player is also in control of a player character. However, the player’s decisions are much more limited. Rather than being able to try whatever obscure sequence of words he can imagine, the set of possible options is laid out. The responsibility for enumerating the possibilities of the world has moved from player to developer, which makes for easier play — no rules are hidden. Classic IF will appear more mysterious than a VN of similar complexity, and it is possible to have options in a VN that in classic IF would make it unplayable because the player could not reasonably be expected to guess them. In both IF and VNs, the world is crystallized and all possible narrative paths through the world have been predetermined; however, in a VN, because of the requirement that these options be enumerated, we have limited the player’s agency to actions that have meaningful narrative effects. I call this narrative agency: the player’s actions directly select which path to take through the story tree.</p><p>In a wiki adventure, we have both narrative agency and meta-agency. A player can take whatever choices he likes, but can also create new narrative paths. The story is crystallized until the user decides to change it. Furthermore, there is a social element: stories are being mutated by a group, and feedback loops cause strange attractors in the group’s psychology to manifest in the fiction.</p><p>Finally, in fan work, we have only meta-agency. Fan work itself has no protagonist; the player navigates his own mental model of a narrative and creates new narratives from it. Once these narratives are released into the world they are crystallized; but, their mutability is ensured because new versions can be created by other fans. Occasionally, fan work creates a culture significantly divorced from the original and invents <a href="http://knowyourmeme.com/memes/subcultures/superwholock">a very independent narrative universe</a>, based more on trends and patterns in the fanbase than on any genuine attributes of the supposed source material — an extreme form of the feedback loops found in wiki adventure, generating narrative simulacra.</p><h4>Completeness</h4><p>A common habit of VN players is to get 100% completion — to visit all routes and view all possible outcomes. On one hand, this is a show of dedication, and an in-group signaling mechanism: VNs can be extremely long, so getting 100% completion is often time-consuming in addition to requiring some careful note-taking and book-keeping. Some VN engines include features to aid in keeping track of options and routes already taken, or features useful only on re-play (such as skipping over already-seen content). On the other hand, this kind of completionism is a godlike ability to model the entire work completely — akin to viewing every alternate timeline in a Burroughs-Wheeler MWI universe. This completionism is made possible by the enumeration of responses. It is not possible in classic IF, which can have a structure of similar complexity and choices of similar granularity, unless the player determines the set of all possible options and uses them at all possible points — and while engines that can recognize only expressions of the form &lt;verb&gt;&lt;noun&gt; can be iterated over using all possible combinations of recognized verbs and nouns, some engines support more elaborate language constructs including embedding, which makes enumeration of all possible recognizable strings impossible.</p><p>However, our mutable forms (fan work and wiki adventures) are incompletable on yet another order of magnitude. They change along the axis of real time as well as fictional time. While you can take a snapshot of a wiki adventure at any given time and play it to 100% completion, it can be modified the next time you play it — at any point along its timeline. Fan work is even more extreme; by its nature it forks, so any given fanwork is at any given time geneologically connected to several others that differ and are themselves mutable in real time. Fan work is the most amorpous — combining the flexibility of language with mutation along time and geographic axes, yet still operating directly upon narrative without the use of a player-character intermediary. Nevertheless, fan work is a game — a game with no author and no end, created entirely by the players.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[While I’ve seen lots of snappy, short, intelligent, and witty pieces of academic writing, I feel…]]></title>
            <link>https://medium.com/@enkiv2/while-i-ve-seen-lots-of-snappy-short-intelligent-and-witty-pieces-of-academic-writing-i-feel-8861ad83db19?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/8861ad83db19</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Tue, 09 Jun 2015 14:11:41 GMT</pubDate>
            <atom:updated>2015-06-09T14:11:41.117Z</atom:updated>
            <content:encoded><![CDATA[<p>While I’ve seen lots of snappy, short, intelligent, and witty pieces of academic writing, I feel like people who criticize academic writing are really complaining about several different tendencies that rarely occur in the same piece of writing, all of which occur more often in academic writing than in most other kinds.</p><p>One tendency is to use specialized jargon. This makes perfect sense — terminology is invented in order to quickly reference a nuanced idea, at the cost of being impenetrable to people unfamiliar with the nuanced idea (and thus unfamiliar with the term). Using jargon as a shibboleth is also not without merit — explaining the meaning of these terms requires explaining the ideas behind them, which takes time and energy &amp; is a waste of effort when the readership is already familiar with them; excluding readers without the prerequisite background to understand nuanced points is perfectly reasonable, particularly when good resources exist to bring a general audience up to speed on the ideas and terms. People working in the depths are not necessarily the best popularizers, and they don’t need to be.</p><p>Another tendency is to draw arguments out, making explanations overly long. I feel like this comes out of either avoiding jargon or not having access to the appropriate jargon.</p><p>A third tendency bears superficial resemblance to the first two, and is genuine obscurantism. This is a lot less common in academic writing than a lot of people think; it’s pretty common in business.</p><p>A fourth tendency, related to tendency number one, is to mimic the formal structures common in one’s field even when they are inappropriate for the task at hand. I don’t think that extreme examples of this are very common — academics are human beings, too, and can tell when something really isn’t working. But, how egregious examples of this appear depends heavily upon how familiar with the common structures the reader is — even something almost universal, like the format of a scientific paper with its list of references at the end and its abstract, can seem strange and awkward to someone who has never read one before. Again, the skill-set for communicating with a general audience is different from the skill-set for communicating with academics in the same field, and while some people have both skill-sets, they do not necessarily write a single document for both audiences.</p><p>(It’s also useful to note that some of the most entertaining academic work plays with the jargon and the structure in use in the field in a playful and perverse way. Single-line published papers and theorems, for instance, do this and are sometimes extremely influential. But, these things are even less accessible to a general audience.)</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Another great music podcast (which may or may not be still running) is Solipsistic Nation.]]></title>
            <link>https://medium.com/@enkiv2/another-great-music-podcast-which-may-or-may-not-be-still-running-is-solipsistic-nation-it-734efbe8e76c?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/734efbe8e76c</guid>
            <category><![CDATA[podcasts]]></category>
            <category><![CDATA[hidden-gems]]></category>
            <category><![CDATA[music]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 03 Jun 2015 15:20:12 GMT</pubDate>
            <atom:updated>2015-06-03T15:20:12.336Z</atom:updated>
            <content:encoded><![CDATA[<p>Another great music podcast (which may or may not be still running) is <a href="http://sisticnation.com">Solipsistic Nation</a>. It focuses on electronic music, and occasionally does shows focusing on particular labels or particular artists (for instance, it did a show with Black Moth Super Rainbow), but it also does nice theme shows (one theme show that I particularly liked was the “science fiction film soundtrack” show — wherein the host chose a playlist he felt would make an appropriate soundtrack for a Blade Runner-like cyberpunk film; but, he’s also had a mashup show and other more generic themes).</p><p>If your tastes run more to the obscure, I’d also recommend <a href="http://eldiabolik.com/">El Diabolik’s World of Psychotronic Soundtracks</a> — a show focusing on music made for 60s and 70s european grindhouse films. A lot of really interesting stuff was being done by professional musicians in the 60s and 70s essentially as library music — in other words, these musicians would make tracks and shelve them, and then film-makers would buy a license to use them in films. There were some very interesting and influential acts that only ever worked in psychotronic music for films — for example, Goblin, a prog rock band who only ever made music for horror movies and whose music you will recognize if you’ve ever seen a Dario Argento film.</p><p>If your tastes run even more obscure, I’d recommend <a href="https://www.mixcloud.com/pnarco/">National Cynical Network </a>— essentially a mashup/theme show that’s an offshoot of the Church of the Subgenius (the same joke religion slash cult that gave us Devo, Pee Wee’s Funhouse, and the Slackware linux distribution). A typical episode will be somewhere between a Negativland-style sound collage and one of the more eclectic mashup artists (think Illuminoids or Niel Cicierega), and themes include “Teeth”, “Star Trek”, and “Songs about Mary”, in addition to having cover shows (the “Not Devo Show” consists entirely of Devo covers, grouped by original songs; the Pink Floyd episode has a mashup of covers of Dark Side of the Moon).</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[It’s a mistake to call Uber a tech company.]]></title>
            <link>https://medium.com/@enkiv2/it-s-a-mistake-to-call-uber-a-tech-company-uber-is-a-taxi-service-that-uses-legal-loopholes-to-19e9f39963fa?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/19e9f39963fa</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 29 May 2015 18:29:16 GMT</pubDate>
            <atom:updated>2015-05-29T18:29:16.031Z</atom:updated>
            <content:encoded><![CDATA[<p>It’s a mistake to call Uber a tech company. Uber is a taxi service that uses legal loopholes to avoid having to give its employees the various benefits legally granted to employees. As a result, democrats and leftists in general are against it, because the core of its business model is circumventing labor laws.</p><p>When Wal-Mart cleverly circumvents labor laws in order to deny rights to its employees, nobody claims that it’s justified by the technical leaps that Wal-Mart makes, but why? Wal-Mart has developed more new tech than Uber has. The answer is PR — Uber has decided to call itself a tech company, and thus, it has recieved the protection of tech company boosters.</p><p>When a genuinely innovative idea is put forth, there is no problem with regulation because regulation in that area doesn’t exist — the area doesn’t exist, so it’s a non-issue. Drones don’t meet this criteron — drones are an old technology, with early versions existing as far back as the 1940s, and they operate in a regulatory space that is largely well-developed. Uber doesn’t meet this critereon, because as we mentioned, it’s a taxi service.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Myths of competence and specialization]]></title>
            <link>https://medium.com/@enkiv2/myths-of-competence-and-specialization-c5d27506c2bf?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/c5d27506c2bf</guid>
            <category><![CDATA[writing]]></category>
            <category><![CDATA[science-fiction]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Fri, 29 May 2015 12:29:47 GMT</pubDate>
            <atom:updated>2015-05-29T12:29:47.709Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p>An idea has been going around for a while that science fiction, more than anything, is a literature of competence — the protagonists of science fiction are competent people who can be trusted to do the right things under the circumstances (given their knowledge of the situation), and their mistakes can generally be traced back to withheld information or the effects of external forces that manipulate their mental state (like drugs or mind control). This is true of a lot of golden age science fiction (wherein, generally speaking, the protagonists were also respectable, if not amiable — think Asimov &amp; Heinlein), and is generally less true of new wave science fiction (think of Ellison, wherein occasionally our protagonists are mad or naive or belong to a culture with alien values) and first-generation cyberpunk (think of Neuromancer, wherein every character who isn’t mad is varying degrees of self-loathing and self-destructive). But, a fiction of competence is also the lens through which many people see the real world — and some of them are probably drawn to golden-age science fiction for this reason.</p><p>I have a friend who is, like me, a software engineer. He clearly sees the world through this lens. He sees people as, generally speaking, professionals; what I consider to be design errors he considers to be some unfortunate but inevitable product of circumstance that must have very good and acceptable reasons behind it. He acknowledges the occasional genuinely poor decision, when it’s undeniable that there’s no good excuse for it, but he considers such things rare and rarely acknowledges poor decisions made by people he respects. When faced with a problem, he prefers to theorize about it rather than probe it experimentally, and is willing to spend more time generating an elaborate mental model of a problem than experimentally discovering its contours. In other words, he has confidence in the integrity of his mind and the minds of others, and considers the production of mental models to be a generally foolproof method for exploring the world.</p><p>Although I respect him a great deal, and although I admit that his knowledge of many fields is deeper than mine, I consider his attitude naively optimistic.</p><p>My model of the world is compatible with the rule of the blind idiot god. The universe is complex enough that few elements can be modeled perfectly by human beings. Because competence is difficult to achieve, few people achieve it — incompetence and poor decisions are the rule, rather than the exception. Furthermore, even competent people have little reason to exercise their competence — the illusion of competence is rewarded moreso than actual competence, and exercising one’s competence takes time and energy that pretending to exercise one’s competence does not — and society rewards behaviors that are incompatible with the production and maintenance of genuine competence.</p><p>Human beings tend to value confidence in themselves. I consider this a major failure. Because the world cannot be perfectly modeled, all models are by definition imperfect — and confidence is faith in the predictive success of one’s mental model for situations upon which it has not yet been tested. Confidence is valued in oneself in part because confidence (i.e., lack of hesitation) is valuable in genuine emergencies — if you are being chased by a bear, spending mental effort determining whether the bear genuinely exists or is an illusion produced by a trickster god is detrimental to your expected lifespan. Genuine emergencies are more rare now than they were when the adrenal and peripheral nervous system first developed in our distant forebears, and they are less important to the survival of our genetic line — we are more likely to fail to reproduce out of a bias against children or financial instability or a lack of attraction to the opposite sex than out of actually being killed by something we could run away from (like a bicycle, an enemy, or a wild animal); as a result, in today’s world, it is generally more risky to be sure than to be unsure. The same confidence in the correctness of your mental model of the world that will save you from a wild animal will get you run over by a truck, because change blindness is part of the same set of energy-saving heuristics that allow human beings to do things faster and with less effort by introducing errors into our models of the world; the same confidence that would allow a human being in a nomadic-band-of-hunter-gatherers situation to fight effectively against another band trying to use the same resources will lead a modern person to fight and die in a religious war.</p><p>Human beings also value confidence in leaders. This is for a similar reason — if you are in a nomadic band of fewer than 150 other people, and you are being attacked by another group of approximately the same size, your odds are about even so long as your hesitation level is about even, but lack of hesitation gives you a tiny advantage. Your leader, because he is in charge of coordinating tactics, is the bottleneck — his hesitation is your hesitation. This is the context where leaders are useful — when discounting planning time your odds are 50/50, but when every second of hesitation counts against you, fortune favors fools who rush in over the ones who consider the situation carefully. But, few genuinely important situations today depend upon split-second decision-making. Unless you’re in the military, your ability to make poor decisions quickly will never be more important to your lifespan than your ability to make good decisions (although the ability to make good decisions quickly is beneficial in a wide variety of situations, it’s not really practical to develop), and unless you play professional sports the same is true of your livelihood. A good leader in typical modern circumstances is someone who takes minutes or hours to think a decision through, and who knows when to back off and reconsider a decision that has proven to be flawed — in other words, exactly the kind of person who appears unconfident to the point of neurosis. Because our heuristics are stuck in the stone age, to become a leader you must appear confident, but in order to be a good leader your apparent confidence must be an illusion.</p><p>This is not to say that I don’t believe in competence. In fact, I think competence is undervalued and under-sold. Take, for instance, the polymath.</p><p>A lot of people these days say that polymaths can no longer exist — that the world has gotten too complex. Bullshit. Our models of the world have gotten better — which means that our ability to predict the world has gotten better. It’s easier to be a polymath today than ever before, because being a polymath means being competent in a variety of fields, and great strides have been made in every field with regard to our ability to learn to become competent in them. The world has not gotten more complex, but instead, through human endevours, it has gotten slightly simpler — not because we have changed the world but because we have changed our minds, developing mental tools for organizing the massive clusterfuck that is reality into more and more useful predictive models, wherein the complexity of the model grows slower than its predictive utility.</p><p>The same narrative that claims that there can be no more polymaths tells us that specialization is desirable, or at worst an unfortunate necessity. If we can’t learn a variety of mental models because the models have gotten more complex, then we need to stick to our lane and go deep into one silo, solving the problems that fit into that domain.</p><p>But, all problems are in reality multidisciplinary. Disciplines and problem domains are inventions of human beings, and reality has no interest in them. The specialist is blind to this. The specialist sees the portions of the problem that fall into his domain, and perhaps slightly foggily sees the portions that fall into neighbouring domains; the remainder is some vast undifferentiated miasma that must be left to other people to figure out. As a result, the specialist can be very confident about his results — because he has chopped off everything in the universe that he doesn’t know how to model, and has applied a model to the tiny portion that has been left over. His model may not yield useful results, because he has ignored most of the universe, and he really can’t effectively isolate his subject that way.</p><p>The generalist, on the other hand, sees the universe and applies several different models that apply to different aspects of the subject (as well as sections of the world immediately surrounding it). The polymath, who is a generalist upgraded with the knowledge of several specialists, does the same thing with better results because he has a wider variety of useful models and the experience to determine which models are appropriate. The polymath can do this because he realises that each specialized field is a pattern recognition machine, and because some patterns can be found in the world wherever you look, many disciplines have independently reinvented the same or very similar models with different terminology. He can combine the similar models to form superior hybrid models, and when the models are exactly the same he can learn the new terminology or use the shared model to synthesize its sister models across domains. And, since models build upon each other based on shared patterns, he can use models from one discipline to more efficiently learn models from another, unrelated discipline because they essentially accidentally share patterns. Because of the polymath’s wider scope, he also is aware of common failures in various forms of various models — he is aware that the failures can compound, and so despite having better predictive results at a lower cost, he also has lower confidence; he has eliminated the artificially inflated confidence of the specialist and is left with a level of confidence more appropriate to the actual situation.</p><p>I feel like this myth of competence and confidence — the Captain Kirk character voyaging into the unknown and believing that he already knows it, confidently applying human biases to non-human situations and considering himself to be morally superior to cultures that don’t share his values — is not merely naive and optimistic, but actually regressive and dangerous. Any confident leader and man of action can be percieved, with a minor shift of perspective, as an arrogant fool who acts without thinking; any crusade against evil people doing evil things can be reframed as an intolerant bigot battling a system of values he doesn’t understand. This kind of literature transplants into the space age the kind of leader who hasn’t really been appropriate for a leadership role since the dawn of agriculture.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The key thing here is not that this time is different than the 60s, or that the people writing…]]></title>
            <link>https://medium.com/@enkiv2/the-key-thing-here-is-not-that-this-time-is-different-than-the-60s-or-that-the-people-writing-a44c7f62430e?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/a44c7f62430e</guid>
            <category><![CDATA[automation]]></category>
            <category><![CDATA[basic-income]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Wed, 27 May 2015 13:16:51 GMT</pubDate>
            <atom:updated>2015-05-27T13:16:51.097Z</atom:updated>
            <content:encoded><![CDATA[<p>The key thing here is not that this time is different than the 60s, or that the people writing about this problem in the 60s were wrong. The state of technological optimism about AI has fluctuated over the years, but has almost never corresponded well with the reality of AI advancement. The people talking about this in the 60s were right, aside from the timeframe — because what everyone in 1959 thought would be normal in 1965 actually happened in 1995 and became normal in 2005.</p><p>Labor upsets related to technological changes do occur. There’s no rule saying that employment rates *need* to return to normal, but at least in a capitalist society, there are forces that encourage it (and capitalism is all about this kind cybernetic feedback). When a job is genuinely completely automated in such a way that, outside of the novelty or nostalgia factor of having a human make it (artisanal production), automated production is always preferable in terms of both price and quality, we can consider that a ‘functional singularity’ of that job — the machine has taken over that job, and humans aren’t going to take it back. Functional singularities happen all the time, and aren’t new. The first industrial revolution spawned luddites in part because a lot of cottage industries were undergoing functional singularities — machines can weave ornately patterned textiles better than humans, so jaquard looms really did take over the extremely specialized and skilled job of expert weavers in that context. Functional singularities happen at a smaller scale all the time, as well — think of the invention of sliced bread — and they are often viewed in a positive light as labor-saving devices, because they often take over tasks that had already been shouldered by the consumer (or by the housewife, or by servants — think sliced bread again, and the dishwasher, the washing machine, and the microwave). Indeed, the very first computers represented a functional singularity of the job of the ‘computer’ — a single computing machine took over the jobs of twenty or thirty young women with mechanical desk calculators; electromechanical telephone exchanges did the same for operators (again typically young women).</p><p>Historically, a functional singularity has been considered a labor-saving advancement by people who value the labor in question moreso than the livelihood of the people performing the labor. This is purely a market-related concern — if these people could fall back on a living wage once their tasks were replaced, it wouldn’t really be a concern that their task had been automated (because if they were doing it for some reason other than the money — say, because they got satisfaction from the work — they could continue doing it despite it no longer being profitable).</p><p>It takes time for new types of labor to appear in the wake of a functional singularity. To the extent that the ability to perform a task is specialized and full of non-transferrable skills, retraining time is time when the people who were doing the tasks are unemployed. And, even if we assume that such a thing always does happen, the rate at which it happens is clearly not strongly associated with the rate at which jobs are fully automated or the amount of skill displaced. The industrial revolution is so-called because of the vast amount of labor that was displaced, much of it skilled labor — and the various labor movements and luddite-style anti-automation movements of the era are the kind of thing that happen when so much labor is displaced. It’s important to note that the labor movements spawned by the industrial revolution took about a hundred years to get to the point where they are today, and mostly haven’t progressed since — we’re talking about a time scale wherein, historically, most of the displaced people who were the impetus for reforms did not live long enough to benefit from them, and remained displaced or operating in a diminished capacity (say, formerly highly-skilled weavers operating in the unskilled and less lucrative position of pulling a lever) for the remainder of their lives. Neither comparable new fields of labor nor reforms for improving their quality of life caught up to them in time to make any difference — theirs is a story of a lost livelihood.</p><p>We really need to be putting these measures in place preemptively, because doing so in a reactionary way will doom another generation to that generation’s equivalent of shit jobs — if even that. Many skilled jobs are on the cusp of replacement, and the unskilled jobs of today (retail, fast food) are already beginning to be replaced. Just as lever-pulling unskilled jobs were not numerous enough to replace the influx of displaced skilled cottage industry workers during the industrial revolution, there simply isn’t room to make every laid-off knowledge worker into a fry cook or grocery bagger — so, without improving the social safety net, expect a large increase in the homeless-and-hungry population. In the end, it doesn’t much matter when exactly the day fully comes, because progress toward total automation is happening, and displacement rates are already higher than reskilling rates.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Failure modes of science fiction]]></title>
            <link>https://medium.com/@enkiv2/failure-modes-of-science-fiction-c2fa86ad465e?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/c2fa86ad465e</guid>
            <category><![CDATA[sad-puppies]]></category>
            <category><![CDATA[science-fiction]]></category>
            <category><![CDATA[writing]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Sun, 24 May 2015 02:58:53 GMT</pubDate>
            <atom:updated>2015-05-24T02:58:53.927Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p>There are several popular ways to look at science fiction as a genre. I have <a href="http://firstchurchofspacejesus.blogspot.com/2010/11/nobody-likes-golden-age.html">my</a> <a href="http://firstchurchofspacejesus.blogspot.com/2011/09/redefining-scifi-again.html">own</a> <a href="http://firstchurchofspacejesus.blogspot.com/2012/09/speculative-fiction-and-novelty.html">preference</a><a href="http://firstchurchofspacejesus.blogspot.com/2012/05/another-rant-about-science-fiction.html">s</a>. That said, the major opposing perspective — what I’d term the ‘machine-lit’ school of thought — has its merits, insomuch as it highlights a set of common tendencies in science fiction. I’d like to take this space to highlight the basic premise of machine-lit, the tendencies it breeds, and why I find most machine-lit to be relatively uninteresting.</p><p>(The third major perspective, what I call the spaceship-on-the-cover style, I find wholly uninteresting and is the subject of other essays; however, this perspective is becoming historically important lately because of some drama surrounding the Hugo awards being gamed by groups who prefer this style, so it’s worth mentioning in passing.)</p><p>Machine-lit is, in a general sense, the construction of a narrative around a concept invented by the author, as a capsule intended to introduce the reader to the concept. Lots of early science fiction is machine-lit for actual machines (<a href="https://en.wikipedia.org/wiki/Ralph_124C_41%2B">Ralph 124C41+</a> being an ideal example of how this can go wrong yet still be very influential). The works of Ayn Rand are machine-lit for the Objectivist philosophy. Big-idea science fiction novels tend to be machine-lit for the ideas they represent.</p><p>One failure mode of machine-lit is that, because the narrative is intended as a delivery mechanism for the concepts, the narrative can itself be weak or nearly nonexistent if the author thinks the ideas themselves are interesting enough. (Ayn Rand, again, and Gernsback, again — but also major dystopian novels like Zamatayin’s We and 1984). Likewise, style can be a major issue in machine-lit, with The Unincorporated Man’s borderline-fanfic-quality-prose depending upon its intended audience of libertarians to forgive lack of technical skill in writing because the ideas are sufficiently in-line with the ideology, and PKD’s writing so heavily leaning on the ideas (not to mention the amphetamines) to pull it through (outside of rare stylistically-polished books like A Scanner Darkly).</p><p>There are definitely instances where books intended as machine-lit end up having well-developed plot and characters and a coherent and polished writing style (pretty much every Neal Stephenson book meets these criteria, as does Brave New World), but to some extent, doing so depends upon a kind of imagination and intellectual honesty that brings the book into the middle-ground between machine-lit and the world-building-based style of science fiction that I tend to champion, whose most extreme and visible example is seen in the post-Neuromancer works of William Gibson.</p><p>Another major failure mode of machine-lit is that, because of the dependence upon the central conceit of the book, if that conceit is uninteresting or unoriginal, the book as a whole fails along with it. With big-idea novels related to politics (Rand again) or philosophy (a handful of PKD books that lean too heavily on solipsism or philosophical zombies, and nearly every film adaptation of a PKD work), interest in these works falls evenly along either political-ideological or philosophical-education lines — a communist is, largely, going to find The Fountainhead or Anthem uninteresting; someone who is familiarenough with the idea of solipsism to find it fairly uninteresting will likewise find The Matrix uninteresting, while someone who rejects Serle’s Chinese Room paradox and the idea of philosophical zombies as based on an erroneous deification of consciousness will find the host of films about robots being incapable of emotion or of morality to be uninteresting. When the same idea is recycled into dozens of machine-lit works, the popularity of the idea itself can suffer, because while no longer wholly novel it will often be framed in similar ways, with similar changes based on the needs of the story or premise, by nearly identical stories (The Matrix has more in common with Simula-3 and its major film adaptations, World on a Wire and The Thirteenth Floor, than it does with Plato’s Allegory of the Cave, from which all of them were derived). Today, talking about solipsism will make people think of The Matrix rather than, say, Descartes’ “evil genius” — and despite my general feeling that The Meditations failed to be adequately convincing, we as a society are favoring an action franchise with major and obvious plotholes over a fairly heavily considered work by a brilliant philosopher.</p><p>Again, if a text develops its characters and plot adequately, the central conceit can essentially be ignored — a good ghost story is good even to people who don’t believe in ghosts, while a bad ghost story will fail to entertain enough to motivate people to suspend their disbelief.</p><p>Machine-lit shares with the rest of speculative fiction a basis in a counterfactual model of the world. That is to say, we start our world-building by setting some axioms that, in our world, are not true, and work from there. The difference is that machine-lit, by definition, performs the basic world building then immediately jumps to narrative, then stops as soon as something resembling a completed text is produced. Within world-building-based science fiction, a much more complex world is built, and the narrative and characters stem from that world organically.</p><p>This requires a dedication to completeness and intellectual honesty, in part because genuinely following the logical progression of the central mechanism of a counterfactual world can point out flaws in its structure.</p><p>In cryptography, the first and most important rule is never to roll your own crypto — always use a well-known and well-tested algorithm, at the very least, and ideally also use a well-known and well-tested implementation. The reason is that flaws are never intentionally introduced into crypto by people who want the crypto to succeed, and thus fatal flaws can only be identified by other people — and the more people there are looking for flaws in an algorithm, the faster such flaws are found (and the longer it takes to find fatal flaws in an algorithm, the more likely it is that such flaws are difficult to find). Everyone who designs crypto professionally is also skilled in trying to break crypto: you learn to avoid the flaws that you have discovered how to exploit. Likewise in computer security — the research arm of the computer security community consists of people who figure out how to break security and then figure out how to patch those holes.</p><p>In fact, this is a common pattern in legitimately serious enterprises. The scientific method is exactly this: suggest a model of the world, and then recruit people to attack it. The adversarial justice system is based on two groups of people presenting different models of the world and attacking each others’ models. Even in philosophy, philosophers engage in critiques of the ideas of other philosophers, rather than ignoring any idea they don’t agree with.</p><p>Any functional member of any of these communities will attempt, before putting their ideas out into the world, to stress-test them personally — formulate simple attacks, determine which portions of the idea are weak and whether they can be strengthened without complete restructuring.</p><p>Machine-lit, by and large, fails to perform these sanity checks. Machine-lit is the domain of people who are so in love with their ideas that they cannot bear to test their mettle before pushing them out into the world.</p><p>An ideology at the core of machine-lit, if properly investigated, would collapse upon itself or mutate such that it fails to be an ideology. A utopia at the core of machine lit would, upon close inspection, become a dystopia; a dystopia, upon close inspection, would yield some happy and fulfilled people, making the message of the book ambiguous. An actual machine at the core of machine-lit, if properly and rigorously tested, would become at worst a patent application but possibly an actual invention.</p><p>I’m perfectly in favor of optimism in science fiction. Nothing is to be gained from keeping the genre grimdark as a rule, in the same way that nothing is to be gained from keeping superhero movies grimdark. However, utopian science fiction represents a failure to take the medium seriously — and a shallow dystopia or cozy apocalypse is no better. Science fiction should be a genre of ideas, but there’s no point if we allow our ideological biases and our love of shiny toys to turn it into a genre of shallow ideas shielded from unforgiving reality. The real world has problems, and while escapism is fine, a work cannot simultaneously be an escapist fantasy and a serious analysis presenting a serious solution to the problems it fantasizes about escaping from.</p><p>Science fiction always starts as machine-lit. But, machine-lit is a larval stage that adult science fiction works outgrow.</p><p>This article was originally published at <a href="http://firstchurchofspacejesus.blogspot.com">First Church of Space Jesus</a> under the title “<a href="http://firstchurchofspacejesus.blogspot.com/2015/05/utopianism-and-sci-fi-as-machine-lit.html">Utopianism and sci-fi as machine-lit</a>”.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Against certain naive varieties of transhumanist sentiment]]></title>
            <link>https://medium.com/@enkiv2/against-certain-naive-varieties-of-transhumanist-sentiment-3535eec7e5fd?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/3535eec7e5fd</guid>
            <category><![CDATA[internet-of-things]]></category>
            <category><![CDATA[wearables]]></category>
            <category><![CDATA[transhumanism]]></category>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Sun, 24 May 2015 02:51:11 GMT</pubDate>
            <atom:updated>2015-05-24T02:52:23.859Z</atom:updated>
            <cc:license>http://creativecommons.org/publicdomain/zero/1.0/</cc:license>
            <content:encoded><![CDATA[<p>A frequent idea that I run across when speaking to technophiles with transhumanist leanings these days is the superiority of tech over biology. People will say, “I’ll upload my brain and live forever”, or “I’ll replace my arm so that I can be stronger”, or “I’ll get a wetwire to the internet so I can read faster”. This isn’t a new idea; I said variations on the same thing when I was fifteen. But, it’s absolutely stupid.</p><p>We have never built a machine with a lifespan and resilience comparable to a human being. Machine failure rates fall along a bathtub curve, but while an expected human lifespan is betweenseventy and eighty years these days, it’s the rare freak of a machine that still functions after ten or twenty years — let along thirty, let alone continuously. Biological systems have insanely complex self-repair and self-maintenance systems, and the reason we live for eighty yearsis that our parts are continuously being maintained, rather than undergoing routine maintenance on a human scale of weekly-monthly-yearly. The very first programmable electromechanical computers were built in the 30s (depending on who you ask and how you define it, you can push it forward or back about ten years), meaning that a human being living an average lifetime that was born at the same moment as the very first programmable computer in the modern sense would be dying *right now*; drum and disk storage is twenty years younger(along with transistors, ram that’s not based on relays/mercury tubes/CRTs, programming languages other than machine code, and interactive terminals), and the internet is about fifteen years younger than *that* (along with email, pipes, directories, and asymmetric key cryptography). Someone born at the moment the first packet was sent over the internet would be middle-aged. Nevertheless, all these systems have changed drastically many times over the course of their lifetime, in incompatible ways. All of the component parts have been replaced many times over. At various points in the past, all these systems have had *complete* failures (yes, including the internet). These systems are not at the point where they could be expected to safeguard the lifetime of a rat, let alone extend the lifetime of a human being.</p><p>Likewise, with prosthetic arms. Prosthetic arms are great — for people who are missing their arms. Cochlear implants aren’t competing with people’s real ears; they’re competing with being deaf. The prosthetic eyes that have finally gotten FDA approval have approximately the same resolution as a <a href="https://en.wikipedia.org/wiki/TRS-80_Model_100#/media/File:Radio_Shack_TRS-80_Model_100.jpg">TRS-80 Model 100</a> — they aren’t competing with real eyes, but with total blindness.</p><p>Wetwires are in an even worse position. The current state of the art in brain implants can, with incredibly invasive and dangerous brain surgery, temporarily hook your brain up to 200 I/O lines, each of which neurons *might* decide to grow on. Wetwires are competing with reading: a four thousand year old technology that’s constantly being improved upon, that takes advantage of the human eye and optic nerve — a pipe so fat that the eye is considered to be a part of the brain, a pipe so fat that the eye does complex processing independently of the visual cortex and can independently trigger signals to the amygdala about emotionally striking scenes before the visual cortex can even receive the image data. Furthermore, reading is a technology that the government of every developed nation spends huge amounts of money on installing into its citizens! Wetwires can’t compete with that.</p><p>That said, this isn’t the end of transhumanism, or even of grinding. Implants aren’t going to go away. It’s just that we aren’t looking at them correctly.</p><p>Implants are a *long* way away from replacing the things that human beings already do well, like living and thinking and reading and moving. Generally speaking, to the extent that it’s trivial to do so, when there’s a problem with scale, we invent an external technology to handle it — when we need to turn bolts, we build wrenches that fit in our hands instead of hacking our arms off and replacing them with wrenches. If we depend upon implant tech (and other varieties of transhuman tech) to fund itself by being an improvement over what humans already are capable of doing, then the whole field will go bankrupt. But, there aretwo fields in which this kind of tech can excel. One is performing aworse job at than the human body at tasks that the human body already does — prosthetics for people with missing limbs, and replacement parts for people whose parts are faulty or missing. The other is allowing human beings to do things they’ve never done before — not by increasing scale, but by qualitative change.</p><p>The cochlear implant kind of sucks. When it’s installed, wires are stuck to the cochlea — a snail-shaped fluid-filled organ in the inner ear that does the heavy lifting in hearing (the rest of the ear is basically involved in amplification and protection). In normal hearing, vibrations from outside the ear are amplified by a set of bones that operate like a cam assembly, before pressing on a flexible membrane on the big end of the cochlea, and the movement of tiny hairs inside the cochlea produces the perception of sound, with the position of the hairs that are most stimulated determined by the frequency of the sound. In a cochlear implant, the wires cause the hairs to be stimulated directly, with galvanism, and so the number of wires installed corresponds to the resolution of sound available. We do not have the technology to produce CD-quality sound. We don’t even have the technology to produce speak-and-spell-quality sound. People with cochlear implants are stuck trying to decode speech based on fewer distinct frequencies than there are bars on a child’s xylophone. But the cochlear implant, as an accident of its nature, has one improvement over the ear — it has a built-in headphone jack. Cochlear implant-like technologies are far from being an improvement over ears, but when combined with throat mics or other mechanisms for producing the fundamental elements of speech from subvocalizations, they might be an improvement over the walkie-talkie. At the point at which this technology has enough demand to make people voluntarily submit to brain surgery, I expect that this is exactly how it will be used (and I expect the first market to be military or paramilitary — people who, on a life or death basis, need to communicate without using their hands and without being heard by other people nearby).</p><p>There’s another trend going on, as well. Just as desktops became laptops and laptops became smartphones, smartphones are on the cusp of becoming wearables, and wearables will become implants.</p><p>However, this change-over is very rarely quick, and even more rarely complete. Before desktops, we had minicomputers, and before minicomputers, mainframes; however, minicomputers are not quite gone (IBM still sells machines running z/OS, although most of the market is dying), and desktops are hardly going anywhere.</p><p>We haven’t yet reached the point where it’s reasonable to develop software on a smartphone — which means that smartphones are about where personal computers were in 1979, but beyond where laptops were in 1989 (when the now-famous New York Times article suggesting that the age of the laptop had come and gone was written, but also, paradoxically, when the HP-95 palmtop was released — which, as it so happens, was perfectly capable of having software developed on it if you could get along with a calculator-style chiclet keyboard). Smartphones are currently being used for light-duty applications while the heavy-duty applications like video editing, compiling, and triple-A gaming are being done on laptops and desktops — a mirror of about ten years ago, when laptops were being used for lighter-duty applications. Meanwhile, wearables are at the same stage that smartphones were in the Palm Treo era, or that PDAs were in the Newton era — in other words, just close enough to seem potentially commercially viable, but not quite far enough along yet to be useful as anything more than an expensive toy. Expensive toys can be industry-changing, if they’re popular enough, but to do that you need to pull a Sony and sell under cost at scale. (Sony is the only company I can think of that has pulled off making its new technologies ubiquitous and cheap by selling under cost at scale multiple times — it did it with 3 1/4 inch floppy disks by supplying Apple with them under cost in the mid-80s, again a few years later with CDs, and again by shipping every PS3 with a blu-ray drive. But, it’s also failed multiple times with that technique — with mini-discs, with the cell processor…)</p><p>Every few years, the entire tech industry pulls out twenty-year-old project from the MIT Media Lab or CMU or PARC or somewhere and collectively decides to shit its pants over it. Recently, we’ve been hitting a quadruple-whammy: wearable computers, the Internet of Things, 3d printing, and virtual reality.</p><p>The current wearable computer boom started with Google Glass taking pretty much equally from the work that Thad Starner and Steve Mann were doing in the early 90s; appropriately, Starner was brought onto the Glass project, while Mann was completely uncredited despite the fact that they took the name from him. And, despite the fact that Glass was a complete PR disaster, Google definitely decided what parts of Starner’s work to borrow with an eye toward PR — Starner’s most interesting idea, subliminal reminders, was omitted from Glass and the Glass UI standards and Glass UI frameworks were written in such away that subliminal reminders should be completely impossible. Now, in an almost hilariously ironic turn of events, Microsoft has taken essentially exactly the same technology, made it steroscopic, reframed it in terms of geolocation-centric AR (something Glass was never going to be capable of doing, by design), and turned it into a massive PR success.</p><p>In comparison, the current Internet of Things boom seems to be driven entirely by industry-wide amnesia. That’s not entirely unfair, since the industry has, until now, had a very hard time figuring out what to call it. The current term of art is the Internet of Things, but from around 1995 to around 2005, everybody was calling it Ubiquitous Computing. The IoT is hitting a lot of the same media roadblocks as VR did in the early90s, which makes me think that it’s probably around the same point in the hype cycle, although technologically, it’s definitely further along.</p><p>Ten years ago, when I was an unemployed teenager, I had two big projects that were lighting up my eyes. One of them was a wearable computer project. The other was a UbiComp project — what you’d now call the Internet of Things. At the time, the wearable computer project was by far less feasible; displays were expensive, cpus were expensive, making either run off a battery and getting the thing small enough and light enough to fit on your body meant lowering its capabilities to an extreme. I designed several prototype wearable computers around the AT90S8515 — an 8-bit microcontroller that cost$10 and had 127 bytes of ram — and various LED-based displays, but it was clear that unless I was willing to either buy thousand-dollar equipment or strap a laptop to my back and make due with The First Church of Space JesusThe First Church of Space Jesusaudio cues as an interface, wearable computers were really infeasible. (I ended up strapping a laptop to my back and using audio cues, in the end.) The UbiComp project, on the other hand, was completely within the realm of possibility — I had a working prototype for a system for communal cooperative use of a single computer, based on identifier tokens stored on a cheap wiimote knockoff that doubled as an input device; the cost of the system was the cost of a random desktop computer, a projector, and a $20 wiimote knockoff. If I had had steady disposable income, I could have formed a corporation and finished my prototype and become yet another failed IoT startup — the technology was there, solid, and absolutely trivial.</p><p>Today, IoT is even easier. My potentially-$300 [≈ cost of PS3 gaming system, 2011] computer could be replaced with a $20 raspberry pi. Wiimote knockoffs don’t even cost $20 anymore. The projector costs more than the rest of the system in total, and my homebrewed account-sharing system could be replaced with the kind of cloud-based thing that newbies whip up in minutes and brag about on hacker news. A couple years ago,<a href="http://firstchurchofspacejesus.blogspot.com/2014/01/off-topic-wearable-computer-project.html"> I did a wearable computer, too — with about $350worth of parts (a raspberry pi, a twiddler, a $100 head mounted display, and a USB battery pack)</a>, I built something that, while not comparable in usability to a laptop, beat the pants off the absolute best I could do with that kind of money in 2005 — mostly because of economies of scale provided by the popularity of smartphones. PDAs manufactured in 2005 couldn’t really run 800x600 color VGA, or even 300x200 color VGA — too slow. (Maybe you could do it if you were especially clever. I wasn’t clever enough to make up for my lack of riches — wagering the cost of disassembling an expensive PDA on my ability to make it drive a display was too rich for my blood.) A single-board computer capable of running Linux in 2005 was a fucking high-end single-board computer. But, the iPhone came out — a single board computer running BSD shoved into a PDA — then the Android phones started appearing a couple years later — cheaper single board computers running Linux and Java shoved into PDAs. Now the chips that run Linux in smartphones are cheap enough that Texas Instruments will give away a handful of free samples to anybody with a university-affiliated email address, complete with specialized circuitry for fast video decoding. <a href="https://en.wikipedia.org/wiki/Raspberry_Pi_Foundation">Single board computers running Linux can be sold for $20 and make enoughmoney to prop-up a non-profit organization</a>. Meanwhile,<a href="http://www.esp8266.com/"> some nerds figured out that a series of cheap wifi chips could be reflashed</a>, and<a href="https://learn.adafruit.com/adafruit-huzzah-esp8266-breakout/using-nodemcu-lua">now you can buy complete postage-stamp-sized wifi-enabled systems that can run Lua for $5</a>.</p><p>So, we’re at the point now where you can <a href="https://en.wikipedia.org/wiki/Google_Glass">stick the guts of a smartphone on the side of your head and have a head-mounted smartphone with a battery life of about two hours</a>, or you can <a href="https://en.wikipedia.org/wiki/Apple_Watch">stick the guts of your smartphone on your wrist and have a smartphone with a battery life of about a day if you barely ever have the screen on</a>. Or, you can <a href="http://firstchurchofspacejesus.blogspot.com/2014/01/off-topic-wearable-computer-project.html">stick the guts of a smartphone in your pocket and stick a screen on your head, and actually have a reasonable battery life with reasonable usage</a>. We aren’t at the point where we can start making fully wearable never-take-em-off computers with reasonable battery life and reasonable capability, although I think that if we take a page out of the MIT Media Lab book and combine this with IoT, we might be able to make due with what we have for a little longer. This has problems — centralized IoT is the domain of natural monopolies, with most of them fated to go the way of AppleTalk (although centralized IoT is all the rage now, with every consortium of manufacturers competing to make their own incompatible standards on the off chance that theirs will be the one to take off); meanwhile, decentralized IoT is the stuff of IT nightmares, where failures in logistics and/or security can lead to <a href="http://fusion.net/story/55026/this-guys-light-bulb-ddosed-his-entire-smart-house/">a lightbulb DDoSing your house and/or the white house</a>. My own design, which was based on a federated model with an open protocol and a market for competing vendors, has unfortunately been obviated by time — it was based on the assumption that the normal use would be an evolution of the cyber-cafe, and it probably would have worked in 2005, but no longer makes sense in the same universe as widespread smartphone ownership and devices like chromecast. Offloading computing from wearables onto IoT nodes will require an extreme of either security or naivete — and because security is complicated, I fully expect a future hellworld of incredibly insecure wearable/IoT mesh networking comparable to the amazing terror of running Windows 9x on the internet in the 90s. Welcome back to an era where anybody with a modicum of knowledge can remote control your computer and nobody can patch it for five years; except this time, the computer is strapped to your face.</p><p>This is a problem that *must* be solved before the wearables become implantables. Implants need to be smaller than wearables. Right now, the state of medical device security is pretty low — while medical device software, along with airplane control software and nuclear power plant software, has higher quality standards under normal operating conditions, it’s largely no better than normal consumer-grade software when it comes to resisting actual planned attacks, and sometimes worse. We already have computers in all sorts of things — horrible, insecure computers; our airplanes can be hijacked through the in-flight wifi network, our cars can be hijacked through the CD player, our pacemakers can be remote-controlled over wifi, and our routers are already sustaining self-replicating botnets. When these devices are on our bodies, the threats become more visible; when they are in our bodies, they become potentially fatal — not necessarily because of malice (it takes a special kind of person to actually shut down somebody’s heart by exploiting their pacemaker) but because of incompetence (it doesn’t particularly take a special kind of person to try to make a botnet out of every exploitable wifi-enabled device, including pacemakers, and then not check available memory and crash the pacemakers because he’s just written to an address that doesn’t exist).</p><p>Implants are coming, and wearables are coming first. Implants will come both faster and slower than we expect, because they won’t be used how we expect. They won’t make us live longer or read faster, but instead will let us do things we haven’t imagined yet. Let’s fix our shit before we’ve got buffer overflow vulnerabilities that’ll take actual brain surgery to patch.</p><p>This article was originally published at <a href="http://firstchurchofspacejesus.blogspot.com/2015/05/against-certain-naive-varieties-of.html">The First Church of Space Jesus</a>.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Initially, my machines were named after classical philosophers and mathematicians (starting with…]]></title>
            <link>https://medium.com/@enkiv2/initially-my-machines-were-named-after-classical-philosophers-and-mathematicians-starting-with-3d26b9fc9468?source=rss-43a4cf6aa464------2</link>
            <guid isPermaLink="false">https://medium.com/p/3d26b9fc9468</guid>
            <dc:creator><![CDATA[John Ohno]]></dc:creator>
            <pubDate>Thu, 21 May 2015 13:56:53 GMT</pubDate>
            <atom:updated>2015-05-21T13:56:53.030Z</atom:updated>
            <content:encoded><![CDATA[<p>Initially, my machines were named after classical philosophers and mathematicians (starting with Euclid, after the computer in Pi, but then proceeding to Plato, Aristotle, and Archimedes). However, Plato &amp; Aristotle died almost simultaneously, and I switched to a non-classical schema focusing on mathematicians with Descartes, Liebniz, and Hume. Currently, my network consists of: Vonneumann (the server), Erdos (my work machine), Hilbert (my smartphone — because Hilbert is associated with both infinite hotels and space-filling curves), and Agrippa (the chromecast). Retired names include Godel (the PDA), Cantor (a now-dead server), and Conway (a laptop, named after John Conway of Game of Life fame).</p><p>My girlfriend used to name her machines after historical figures she was indirectly related to (Isaac for Isaac Newton, Tesla for Nikola Tesla — both of whom died virgins but who are great^n uncles). She now names devices in her network after characters from Ghost in the Shell (Motoko, Bateau…)</p>]]></content:encoded>
        </item>
    </channel>
</rss>